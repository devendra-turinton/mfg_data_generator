{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b84bff4",
   "metadata": {},
   "source": [
    "Level 1: Sensing & Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f5d3ad",
   "metadata": {},
   "source": [
    "Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb41e4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 100 sensor records...\n",
      "Saved CSV data to data/sensors_data.csv\n",
      "\n",
      "Sample data (first 5 records):\n",
      "      sensor_id equipment_id sensor_type    manufacturer model_number  \\\n",
      "0  SEN-0C25D1C0  EQ-5C402C11   proximity  ifm electronic    M4036-C78   \n",
      "1  SEN-A2AC3EED  EQ-099F97DE         co2            WIKA    M8217-C98   \n",
      "2  SEN-B64619D4  EQ-D47D244B       level         Sick AG    M3938-D65   \n",
      "3  SEN-D4672B5C  EQ-9F6621AF       speed  Endress+Hauser    M5972-D82   \n",
      "4  SEN-41DA410B  EQ-F3D6BF0F      torque             ABB    M6491-B75   \n",
      "\n",
      "  installation_date calibration_due_date  location_x  location_y  location_z  \\\n",
      "0        2022-05-21           2025-12-26       79.42       64.60        5.19   \n",
      "1        2023-08-08           2026-05-30       41.01       74.17        4.04   \n",
      "2        2024-05-04           2026-05-16       92.61       14.66        1.63   \n",
      "3        2023-01-14           2026-04-28       48.76       49.52        4.88   \n",
      "4        2023-06-19           2025-09-11       60.75       76.42        0.36   \n",
      "\n",
      "  measurement_unit  measurement_range_min  measurement_range_max  accuracy  \\\n",
      "0               mm                      0                  55.95      0.14   \n",
      "1              ppm                      0                5094.61      0.27   \n",
      "2                %                      0                 109.73      0.31   \n",
      "3              rpm                      0                3543.90      1.41   \n",
      "4               Nm                      0                 551.18      0.60   \n",
      "\n",
      "        status  \n",
      "0  Maintenance  \n",
      "1  Maintenance  \n",
      "2      Offline  \n",
      "3  Maintenance  \n",
      "4       Active  \n",
      "\n",
      "Basic statistics:\n",
      "Total sensors: 100\n",
      "Unique equipment IDs: 20\n",
      "Sensor type distribution:\n",
      "sensor_type\n",
      "co2          10\n",
      "speed         8\n",
      "proximity     7\n",
      "oxygen        7\n",
      "flow          7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "\n",
    "def generate_sensors_data(num_records=100, output_file=\"sensors_data.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic data for the Sensors table from ISA-95 Level 1.\n",
    "    \n",
    "    Parameters:\n",
    "    - num_records: Number of sensor records to generate\n",
    "    - output_file: CSV file to save the data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the generated sensor data\n",
    "    \"\"\"\n",
    "    # Define possible values for categorical fields\n",
    "    sensor_types = [\"temperature\", \"pressure\", \"flow\", \"level\", \"ph\", \"conductivity\", \n",
    "                   \"vibration\", \"speed\", \"torque\", \"current\", \"voltage\", \"weight\", \n",
    "                   \"humidity\", \"oxygen\", \"co2\", \"position\", \"proximity\", \"rpm\"]\n",
    "    \n",
    "    manufacturers = [\"Siemens\", \"ABB\", \"Emerson\", \"Honeywell\", \"Endress+Hauser\", \n",
    "                    \"Yokogawa\", \"Schneider Electric\", \"Omron\", \"Rockwell Automation\", \n",
    "                    \"WIKA\", \"Vega\", \"ifm electronic\", \"Pepperl+Fuchs\", \"Sick AG\"]\n",
    "    \n",
    "    statuses = [\"Active\", \"Maintenance\", \"Calibration Due\", \"Fault\", \"Standby\", \"Offline\"]\n",
    "    \n",
    "    # Generate unique IDs for equipment (to be used as foreign keys)\n",
    "    # In a real system, these would come from the Equipment table\n",
    "    equipment_ids = [f\"EQ-{uuid.uuid4().hex[:8].upper()}\" for _ in range(int(num_records/5))]\n",
    "    \n",
    "    # Generate sensor data\n",
    "    data = {\n",
    "        \"sensor_id\": [f\"SEN-{uuid.uuid4().hex[:8].upper()}\" for _ in range(num_records)],\n",
    "        \"equipment_id\": [random.choice(equipment_ids) for _ in range(num_records)],\n",
    "        \"sensor_type\": [random.choice(sensor_types) for _ in range(num_records)],\n",
    "        \"manufacturer\": [random.choice(manufacturers) for _ in range(num_records)],\n",
    "        \"model_number\": [f\"M{random.randint(1000, 9999)}-{random.choice(['A', 'B', 'C', 'D', 'E'])}{random.randint(10, 99)}\" for _ in range(num_records)],\n",
    "        \"installation_date\": [(datetime.now() - timedelta(days=random.randint(30, 1825))).strftime(\"%Y-%m-%d\") for _ in range(num_records)],\n",
    "        \"calibration_due_date\": [(datetime.now() + timedelta(days=random.randint(-30, 365))).strftime(\"%Y-%m-%d\") for _ in range(num_records)],\n",
    "        \"location_x\": [round(random.uniform(0, 100), 2) for _ in range(num_records)],\n",
    "        \"location_y\": [round(random.uniform(0, 100), 2) for _ in range(num_records)],\n",
    "        \"location_z\": [round(random.uniform(0, 10), 2) for _ in range(num_records)],\n",
    "    }\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Add measurement units based on sensor type\n",
    "    def get_measurement_unit(sensor_type):\n",
    "        units = {\n",
    "            \"temperature\": \"°C\",\n",
    "            \"pressure\": \"bar\",\n",
    "            \"flow\": \"m³/h\",\n",
    "            \"level\": \"%\",\n",
    "            \"ph\": \"pH\",\n",
    "            \"conductivity\": \"µS/cm\",\n",
    "            \"vibration\": \"mm/s\",\n",
    "            \"speed\": \"rpm\",\n",
    "            \"torque\": \"Nm\",\n",
    "            \"current\": \"A\",\n",
    "            \"voltage\": \"V\",\n",
    "            \"weight\": \"kg\",\n",
    "            \"humidity\": \"%RH\",\n",
    "            \"oxygen\": \"%\",\n",
    "            \"co2\": \"ppm\",\n",
    "            \"position\": \"mm\",\n",
    "            \"proximity\": \"mm\",\n",
    "            \"rpm\": \"rpm\"\n",
    "        }\n",
    "        return units.get(sensor_type, \"unit\")\n",
    "    \n",
    "    df[\"measurement_unit\"] = df[\"sensor_type\"].apply(get_measurement_unit)\n",
    "    \n",
    "    # Generate measurement ranges based on sensor type\n",
    "    def get_measurement_range(row):\n",
    "        ranges = {\n",
    "            \"temperature\": (0, 150),\n",
    "            \"pressure\": (0, 25),\n",
    "            \"flow\": (0, 100),\n",
    "            \"level\": (0, 100),\n",
    "            \"ph\": (0, 14),\n",
    "            \"conductivity\": (0, 2000),\n",
    "            \"vibration\": (0, 50),\n",
    "            \"speed\": (0, 3000),\n",
    "            \"torque\": (0, 500),\n",
    "            \"current\": (0, 100),\n",
    "            \"voltage\": (0, 440),\n",
    "            \"weight\": (0, 2000),\n",
    "            \"humidity\": (0, 100),\n",
    "            \"oxygen\": (0, 25),\n",
    "            \"co2\": (0, 5000),\n",
    "            \"position\": (0, 1000),\n",
    "            \"proximity\": (0, 50),\n",
    "            \"rpm\": (0, 5000)\n",
    "        }\n",
    "        \n",
    "        default_range = (0, 100)\n",
    "        min_val, max_val = ranges.get(row[\"sensor_type\"], default_range)\n",
    "        \n",
    "        # Add some variation to ranges\n",
    "        min_val = max(0, min_val - random.uniform(0, min_val/5))\n",
    "        max_val = max_val + random.uniform(0, max_val/5)\n",
    "        \n",
    "        return min_val, max_val\n",
    "    \n",
    "    # Apply the function to each row and create range min/max columns\n",
    "    df[\"temp_ranges\"] = df.apply(get_measurement_range, axis=1)\n",
    "    df[\"measurement_range_min\"] = df[\"temp_ranges\"].apply(lambda x: round(x[0], 2))\n",
    "    df[\"measurement_range_max\"] = df[\"temp_ranges\"].apply(lambda x: round(x[1], 2))\n",
    "    df.drop(\"temp_ranges\", axis=1, inplace=True)\n",
    "    \n",
    "    # Add accuracy based on sensor type and a bit of randomness\n",
    "    df[\"accuracy\"] = df[\"sensor_type\"].apply(\n",
    "        lambda x: round(random.uniform(0.1, 2.0), 2)\n",
    "    )\n",
    "    \n",
    "    # Add status\n",
    "    df[\"status\"] = [random.choice(statuses) for _ in range(num_records)]\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Also return the DataFrame for further processing\n",
    "    return df\n",
    "\n",
    "def generate_and_save_sample(num_records=100, csv_file=\"data/sensors_data.csv\", json_file=\"data/sensors_data.json\"):\n",
    "    \"\"\"\n",
    "    Generate sample data and save to both CSV and JSON formats.\n",
    "    \n",
    "    Parameters:\n",
    "    - num_records: Number of sensor records to generate\n",
    "    - csv_file: CSV file to save the data\n",
    "    - json_file: JSON file to save the data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the generated sensor data\n",
    "    \"\"\"\n",
    "    print(f\"Generating {num_records} sensor records...\")\n",
    "    df = generate_sensors_data(num_records, csv_file)\n",
    "    print(f\"Saved CSV data to {csv_file}\")\n",
    "    \n",
    "    \n",
    "    # Display a sample of the data\n",
    "    print(\"\\nSample data (first 5 records):\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Show basic statistics\n",
    "    print(\"\\nBasic statistics:\")\n",
    "    print(f\"Total sensors: {len(df)}\")\n",
    "    print(f\"Unique equipment IDs: {df['equipment_id'].nunique()}\")\n",
    "    print(f\"Sensor type distribution:\\n{df['sensor_type'].value_counts()[:5]}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Generate and save sample data\n",
    "    df = generate_and_save_sample(\n",
    "        num_records=100, \n",
    "        csv_file=\"data/sensors_data.csv\", \n",
    "        json_file=\"data/sensors_data.json\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438bef65",
   "metadata": {},
   "source": [
    "SensorReadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "445e1ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 100000 sensor readings...\n",
      "Generated 10000 readings so far...\n",
      "Generated 20000 readings so far...\n",
      "Generated 30000 readings so far...\n",
      "Generated 40000 readings so far...\n",
      "Generated 50000 readings so far...\n",
      "Generated 60000 readings so far...\n",
      "Generated 70000 readings so far...\n",
      "Generated 80000 readings so far...\n",
      "Generated 90000 readings so far...\n",
      "Generated 100000 readings so far...\n",
      "Successfully generated 100000 sensor readings.\n",
      "Data saved to data/sensor_readings.csv\n",
      "\n",
      "Sample data (first 5 records):\n",
      "          reading_id     sensor_id                timestamp  value  \\\n",
      "0  READ-D3482C00B685  SEN-0C25D1C0  2025-07-08 19:12:07.601  22.18   \n",
      "1  READ-199809D38D09  SEN-0C25D1C0  2025-07-08 19:22:12.401  30.55   \n",
      "2  READ-BB78FDC49B66  SEN-0C25D1C0  2025-07-08 19:32:17.201  23.36   \n",
      "3  READ-2922724C0A3C  SEN-0C25D1C0  2025-07-08 19:42:22.001  31.57   \n",
      "4  READ-C753F315886C  SEN-0C25D1C0  2025-07-08 19:52:26.801  35.32   \n",
      "\n",
      "   quality_indicator  status_code        batch_id equipment_state_id  \n",
      "0               99.0            0  BATCH-4321C384     STATE-11D7C0A2  \n",
      "1               89.9            0  BATCH-7F1E8BAE     STATE-34741180  \n",
      "2               86.4            0  BATCH-E8A1DDF5     STATE-67A78BBE  \n",
      "3               97.3            0  BATCH-F2911FC8     STATE-B141443D  \n",
      "4               95.1            0  BATCH-BFFD03C9     STATE-B2A33407  \n",
      "\n",
      "Data Statistics:\n",
      "Total readings: 100000\n",
      "Unique sensors: 100\n",
      "Unique batches: 21\n",
      "Unique equipment states: 51\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def load_sensors_data(sensors_file=\"data/sensors_data.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated sensors data\n",
    "    \n",
    "    Parameters:\n",
    "    - sensors_file: CSV file containing sensor data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the sensors data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(sensors_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Sensors data file {sensors_file} not found.\")\n",
    "        print(\"Please run the sensors data generation script first.\")\n",
    "        return None\n",
    "\n",
    "def generate_sensor_readings(sensors_df, num_readings_per_sensor=100, \n",
    "                            start_time=None, end_time=None, output_file=\"data/sensor_readings.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic sensor readings data based on the sensors table\n",
    "    \n",
    "    Parameters:\n",
    "    - sensors_df: DataFrame containing sensor data\n",
    "    - num_readings_per_sensor: Number of readings to generate per sensor\n",
    "    - start_time: Start time for readings (defaults to 7 days ago)\n",
    "    - end_time: End time for readings (defaults to now)\n",
    "    - output_file: CSV file to save the readings data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the generated readings data\n",
    "    \"\"\"\n",
    "    if sensors_df is None or len(sensors_df) == 0:\n",
    "        print(\"Error: No sensor data available.\")\n",
    "        return None\n",
    "    \n",
    "    # Set default time range if not provided\n",
    "    if start_time is None:\n",
    "        start_time = datetime.now() - timedelta(days=7)\n",
    "    if end_time is None:\n",
    "        end_time = datetime.now()\n",
    "    \n",
    "    # Prepare the output file with CSV writer for memory efficiency\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    # Create a set of batch IDs and equipment state IDs to simulate relationships\n",
    "    batch_ids = [f\"BATCH-{uuid.uuid4().hex[:8].upper()}\" for _ in range(20)]\n",
    "    equipment_state_ids = [f\"STATE-{uuid.uuid4().hex[:8].upper()}\" for _ in range(50)]\n",
    "    \n",
    "    # Calculate total number of readings\n",
    "    total_readings = len(sensors_df) * num_readings_per_sensor\n",
    "    \n",
    "    # Use CSV writer for memory efficiency with large datasets\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        fieldnames = [\n",
    "            'reading_id', 'sensor_id', 'timestamp', 'value', \n",
    "            'quality_indicator', 'status_code', 'batch_id', 'equipment_state_id'\n",
    "        ]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        print(f\"Generating {total_readings} sensor readings...\")\n",
    "        readings_count = 0\n",
    "        \n",
    "        # Process each sensor\n",
    "        for _, sensor in sensors_df.iterrows():\n",
    "            # Get the sensor's measurement range\n",
    "            min_val = sensor['measurement_range_min']\n",
    "            max_val = sensor['measurement_range_max']\n",
    "            \n",
    "            # Generate timestamps within the specified range\n",
    "            time_points = [\n",
    "                start_time + (end_time - start_time) * (i / num_readings_per_sensor)\n",
    "                for i in range(num_readings_per_sensor)\n",
    "            ]\n",
    "            \n",
    "            # Sort timestamps to ensure chronological order\n",
    "            time_points.sort()\n",
    "            \n",
    "            # Generate base trend for this sensor (smooth curve + noise)\n",
    "            # This creates more realistic data than pure random values\n",
    "            base_trend = np.sin(np.linspace(0, random.randint(3, 8) * np.pi, num_readings_per_sensor))\n",
    "            \n",
    "            # Add noise and scaling to make it look realistic\n",
    "            noise_level = (max_val - min_val) * random.uniform(0.05, 0.15)  # 5-15% noise\n",
    "            \n",
    "            # Generate realistic values for this sensor\n",
    "            for i in range(num_readings_per_sensor):\n",
    "                # Create a unique reading ID\n",
    "                reading_id = f\"READ-{uuid.uuid4().hex[:12].upper()}\"\n",
    "                \n",
    "                # Format timestamp\n",
    "                timestamp = time_points[i].strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "                \n",
    "                # Generate a somewhat realistic value with trend and noise\n",
    "                # Scale the base trend to fit within the sensor's range\n",
    "                scaled_value = min_val + (base_trend[i] + 1) / 2 * (max_val - min_val)\n",
    "                \n",
    "                # Add noise to the value\n",
    "                value = scaled_value + random.uniform(-noise_level, noise_level)\n",
    "                value = max(min_val, min(max_val, value))  # Clip to range\n",
    "                value = round(value, 2)\n",
    "                \n",
    "                # Quality indicator (higher is better, occasional low quality)\n",
    "                if random.random() < 0.05:  # 5% chance of lower quality\n",
    "                    quality_indicator = round(random.uniform(50, 85), 1)\n",
    "                else:\n",
    "                    quality_indicator = round(random.uniform(85, 100), 1)\n",
    "                \n",
    "                # Status code (mostly 0 = normal, occasional other values)\n",
    "                if random.random() < 0.03:  # 3% chance of abnormal status\n",
    "                    status_code = random.choice([1, 2, 3, 4])  # Different error/warning codes\n",
    "                else:\n",
    "                    status_code = 0  # Normal operation\n",
    "                \n",
    "                # Batch ID (some readings may not be associated with a batch)\n",
    "                if random.random() < 0.8:  # 80% chance of having a batch\n",
    "                    batch_id = random.choice(batch_ids)\n",
    "                else:\n",
    "                    batch_id = \"\"\n",
    "                \n",
    "                # Equipment state (some readings may not have an equipment state)\n",
    "                if random.random() < 0.9:  # 90% chance of having an equipment state\n",
    "                    equipment_state_id = random.choice(equipment_state_ids)\n",
    "                else:\n",
    "                    equipment_state_id = \"\"\n",
    "                \n",
    "                # Write the reading to the CSV\n",
    "                writer.writerow({\n",
    "                    'reading_id': reading_id,\n",
    "                    'sensor_id': sensor['sensor_id'],\n",
    "                    'timestamp': timestamp,\n",
    "                    'value': value,\n",
    "                    'quality_indicator': quality_indicator,\n",
    "                    'status_code': status_code,\n",
    "                    'batch_id': batch_id,\n",
    "                    'equipment_state_id': equipment_state_id\n",
    "                })\n",
    "                \n",
    "                readings_count += 1\n",
    "                if readings_count % 10000 == 0:\n",
    "                    print(f\"Generated {readings_count} readings so far...\")\n",
    "    \n",
    "    print(f\"Successfully generated {readings_count} sensor readings.\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    # Return a sample of the data (first 1000 rows) for preview\n",
    "    # This avoids loading the entire file back into memory\n",
    "    return pd.read_csv(output_file, nrows=1000)\n",
    "\n",
    "def get_sample_statistics(output_file):\n",
    "    \"\"\"\n",
    "    Get basic statistics about the generated data without loading the entire file\n",
    "    \n",
    "    Parameters:\n",
    "    - output_file: CSV file containing the readings data\n",
    "    \"\"\"\n",
    "    # Sample statistics on chunks to avoid memory issues\n",
    "    num_rows = 0\n",
    "    sensor_ids = set()\n",
    "    batch_ids = set()\n",
    "    equipment_state_ids = set()\n",
    "    \n",
    "    # Process in chunks\n",
    "    for chunk in pd.read_csv(output_file, chunksize=10000):\n",
    "        num_rows += len(chunk)\n",
    "        sensor_ids.update(chunk['sensor_id'].unique())\n",
    "        batch_ids.update([bid for bid in chunk['batch_id'].unique() if bid])\n",
    "        equipment_state_ids.update([eid for eid in chunk['equipment_state_id'].unique() if eid])\n",
    "    \n",
    "    print(\"\\nData Statistics:\")\n",
    "    print(f\"Total readings: {num_rows}\")\n",
    "    print(f\"Unique sensors: {len(sensor_ids)}\")\n",
    "    print(f\"Unique batches: {len(batch_ids)}\")\n",
    "    print(f\"Unique equipment states: {len(equipment_state_ids)}\")\n",
    "    \n",
    "    # Get time range safely\n",
    "    try:\n",
    "        first_row = pd.read_csv(output_file, nrows=1)\n",
    "        last_row = pd.read_csv(output_file, skiprows=max(0, num_rows-1), nrows=1)\n",
    "        \n",
    "        if not first_row.empty and not last_row.empty and 'timestamp' in first_row.columns and 'timestamp' in last_row.columns:\n",
    "            first_time = first_row['timestamp'].iloc[0]\n",
    "            last_time = last_row['timestamp'].iloc[0]\n",
    "            print(f\"Time range: {first_time} to {last_time}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not determine time range: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the sensors data\n",
    "    sensors_df = load_sensors_data()\n",
    "    \n",
    "    if sensors_df is not None:\n",
    "        # Define the time range (past 7 days)\n",
    "        end_time = datetime.now()\n",
    "        start_time = end_time - timedelta(days=7)\n",
    "        \n",
    "        # Generate readings with 1000 data points per sensor\n",
    "        # This creates a high-frequency time series typical of manufacturing data\n",
    "        sample_df = generate_sensor_readings(\n",
    "            sensors_df, \n",
    "            num_readings_per_sensor=1000,\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            output_file=\"data/sensor_readings.csv\"\n",
    "        )\n",
    "        \n",
    "        # Display a sample of the data\n",
    "        if sample_df is not None:\n",
    "            print(\"\\nSample data (first 5 records):\")\n",
    "            print(sample_df.head())\n",
    "            \n",
    "            # Get statistics\n",
    "            get_sample_statistics(\"data/sensor_readings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f3d750",
   "metadata": {},
   "source": [
    "Actuators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fafdae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 100 actuator records...\n",
      "Saved CSV data to data/actuators_data.csv\n",
      "\n",
      "Sample data (first 5 records):\n",
      "    actuator_id equipment_id actuator_type   manufacturer model_number  \\\n",
      "0  ACT-EF54959F  EQ-8953C760        switch            WEG    A3880-S83   \n",
      "1  ACT-9B4081FB  EQ-F3D6BF0F      cylinder  Allen-Bradley    A8717-Y78   \n",
      "2  ACT-5BEB536A  EQ-38DD265D        switch          Festo    A2688-Y94   \n",
      "3  ACT-AC6E4A22  EQ-F4696348    positioner           Auma    A3981-X78   \n",
      "4  ACT-0FB6FE15  EQ-9A644928         motor        Danfoss    A9798-Y21   \n",
      "\n",
      "  installation_date  location_x  location_y  location_z  control_range_min  \\\n",
      "0        2022-08-15       55.20       42.07        8.34                  0   \n",
      "1        2023-05-16        9.98       79.25        0.93                  0   \n",
      "2        2023-05-02       88.33       73.43        5.67                  0   \n",
      "3        2024-07-02        7.20        4.39        5.87                  0   \n",
      "4        2023-02-07       59.23       37.31        5.11                  0   \n",
      "\n",
      "   control_range_max control_unit    status  \n",
      "0               1.00       binary   Standby  \n",
      "1            1084.08           mm  Reserved  \n",
      "2               1.10       binary  Reserved  \n",
      "3             377.90            °     Fault  \n",
      "4            3277.16          rpm   Standby  \n",
      "\n",
      "Basic statistics:\n",
      "Total actuators: 100\n",
      "Unique equipment IDs: 20\n",
      "Actuator type distribution:\n",
      "actuator_type\n",
      "fan           11\n",
      "motor         10\n",
      "positioner     9\n",
      "pump           9\n",
      "blower         9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "\n",
    "def generate_actuators_data(num_records=100, equipment_ids=None, output_file=\"data/actuators_data.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic data for the Actuators table from ISA-95 Level 1.\n",
    "    \n",
    "    Parameters:\n",
    "    - num_records: Number of actuator records to generate\n",
    "    - equipment_ids: Optional list of equipment IDs to use (if None, new ones will be generated)\n",
    "    - output_file: CSV file to save the data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the generated actuator data\n",
    "    \"\"\"\n",
    "    # Define possible values for categorical fields\n",
    "    actuator_types = [\"valve\", \"motor\", \"pump\", \"heater\", \"fan\", \"agitator\", \"conveyor\", \n",
    "                      \"damper\", \"cylinder\", \"positioner\", \"relay\", \"switch\", \"mixer\", \n",
    "                      \"doser\", \"compressor\", \"blower\"]\n",
    "    \n",
    "    manufacturers = [\"Siemens\", \"ABB\", \"Emerson\", \"Honeywell\", \"Schneider Electric\", \n",
    "                    \"Festo\", \"SMC\", \"Bürkert\", \"Danfoss\", \"Asco\", \"Parker\", \"Rotork\", \n",
    "                    \"Auma\", \"Allen-Bradley\", \"SEW-Eurodrive\", \"WEG\"]\n",
    "    \n",
    "    statuses = [\"Active\", \"Maintenance\", \"Fault\", \"Standby\", \"Offline\", \"Reserved\"]\n",
    "    \n",
    "    # Generate unique IDs for equipment (to be used as foreign keys) if not provided\n",
    "    if equipment_ids is None or len(equipment_ids) == 0:\n",
    "        equipment_ids = [f\"EQ-{uuid.uuid4().hex[:8].upper()}\" for _ in range(int(num_records/5))]\n",
    "    \n",
    "    # Generate actuator data\n",
    "    data = {\n",
    "        \"actuator_id\": [f\"ACT-{uuid.uuid4().hex[:8].upper()}\" for _ in range(num_records)],\n",
    "        \"equipment_id\": [random.choice(equipment_ids) for _ in range(num_records)],\n",
    "        \"actuator_type\": [random.choice(actuator_types) for _ in range(num_records)],\n",
    "        \"manufacturer\": [random.choice(manufacturers) for _ in range(num_records)],\n",
    "        \"model_number\": [f\"A{random.randint(1000, 9999)}-{random.choice(['X', 'Y', 'Z', 'S', 'P'])}{random.randint(10, 99)}\" for _ in range(num_records)],\n",
    "        \"installation_date\": [(datetime.now() - timedelta(days=random.randint(30, 1825))).strftime(\"%Y-%m-%d\") for _ in range(num_records)],\n",
    "        \"location_x\": [round(random.uniform(0, 100), 2) for _ in range(num_records)],\n",
    "        \"location_y\": [round(random.uniform(0, 100), 2) for _ in range(num_records)],\n",
    "        \"location_z\": [round(random.uniform(0, 10), 2) for _ in range(num_records)],\n",
    "    }\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Generate control ranges based on actuator type\n",
    "    def get_control_range(row):\n",
    "        ranges = {\n",
    "            \"valve\": (0, 100),             # Percent open\n",
    "            \"motor\": (0, 3000),            # RPM\n",
    "            \"pump\": (0, 500),              # Flow rate\n",
    "            \"heater\": (0, 500),            # Temperature\n",
    "            \"fan\": (0, 100),               # Percent speed\n",
    "            \"agitator\": (0, 100),          # Percent speed\n",
    "            \"conveyor\": (0, 10),           # m/s\n",
    "            \"damper\": (0, 100),            # Percent open\n",
    "            \"cylinder\": (0, 1000),         # mm extension\n",
    "            \"positioner\": (0, 360),        # Degrees\n",
    "            \"relay\": (0, 1),               # On/Off\n",
    "            \"switch\": (0, 1),              # On/Off\n",
    "            \"mixer\": (0, 100),             # Percent speed\n",
    "            \"doser\": (0, 50),              # L/min\n",
    "            \"compressor\": (0, 200),        # Bar\n",
    "            \"blower\": (0, 100),            # Percent speed\n",
    "        }\n",
    "        \n",
    "        default_range = (0, 100)\n",
    "        min_val, max_val = ranges.get(row[\"actuator_type\"], default_range)\n",
    "        \n",
    "        # Add some variation to ranges\n",
    "        min_val = max(0, min_val)\n",
    "        max_val = max_val + random.uniform(0, max_val/10)\n",
    "        \n",
    "        return min_val, max_val\n",
    "    \n",
    "    # Apply the function to each row and create range min/max columns\n",
    "    df[\"temp_ranges\"] = df.apply(get_control_range, axis=1)\n",
    "    df[\"control_range_min\"] = df[\"temp_ranges\"].apply(lambda x: round(x[0], 2))\n",
    "    df[\"control_range_max\"] = df[\"temp_ranges\"].apply(lambda x: round(x[1], 2))\n",
    "    df.drop(\"temp_ranges\", axis=1, inplace=True)\n",
    "    \n",
    "    # Add control units based on actuator type\n",
    "    def get_control_unit(actuator_type):\n",
    "        units = {\n",
    "            \"valve\": \"%\",\n",
    "            \"motor\": \"rpm\",\n",
    "            \"pump\": \"m³/h\",\n",
    "            \"heater\": \"°C\",\n",
    "            \"fan\": \"%\",\n",
    "            \"agitator\": \"%\",\n",
    "            \"conveyor\": \"m/s\",\n",
    "            \"damper\": \"%\",\n",
    "            \"cylinder\": \"mm\",\n",
    "            \"positioner\": \"°\",\n",
    "            \"relay\": \"binary\",\n",
    "            \"switch\": \"binary\",\n",
    "            \"mixer\": \"%\",\n",
    "            \"doser\": \"L/min\",\n",
    "            \"compressor\": \"bar\",\n",
    "            \"blower\": \"%\"\n",
    "        }\n",
    "        return units.get(actuator_type, \"unit\")\n",
    "    \n",
    "    df[\"control_unit\"] = df[\"actuator_type\"].apply(get_control_unit)\n",
    "    \n",
    "    # Add status\n",
    "    df[\"status\"] = [random.choice(statuses) for _ in range(num_records)]\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Also return the DataFrame for further processing\n",
    "    return df\n",
    "\n",
    "def load_sensors_data(sensors_file=\"data/sensors_data.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated sensors data to extract equipment IDs\n",
    "    \n",
    "    Parameters:\n",
    "    - sensors_file: CSV file containing sensor data\n",
    "    \n",
    "    Returns:\n",
    "    - List of equipment IDs from the sensors data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sensors_df = pd.read_csv(sensors_file)\n",
    "        return sensors_df[\"equipment_id\"].unique().tolist()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Sensors data file {sensors_file} not found. Generating new equipment IDs.\")\n",
    "        return None\n",
    "    except KeyError:\n",
    "        print(f\"Warning: No equipment_id column found in {sensors_file}. Generating new equipment IDs.\")\n",
    "        return None\n",
    "\n",
    "def generate_and_save_sample(num_records=100, output_file=\"data/actuators_data.csv\"):\n",
    "    \"\"\"\n",
    "    Generate sample actuator data and save to CSV format.\n",
    "    \n",
    "    Parameters:\n",
    "    - num_records: Number of actuator records to generate\n",
    "    - output_file: CSV file to save the data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the generated actuator data\n",
    "    \"\"\"\n",
    "    # Try to load equipment IDs from sensors data for consistency\n",
    "    equipment_ids = load_sensors_data()\n",
    "    \n",
    "    print(f\"Generating {num_records} actuator records...\")\n",
    "    df = generate_actuators_data(num_records, equipment_ids, output_file)\n",
    "    print(f\"Saved CSV data to {output_file}\")\n",
    "    \n",
    "    # Display a sample of the data\n",
    "    print(\"\\nSample data (first 5 records):\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Show basic statistics\n",
    "    print(\"\\nBasic statistics:\")\n",
    "    print(f\"Total actuators: {len(df)}\")\n",
    "    print(f\"Unique equipment IDs: {df['equipment_id'].nunique()}\")\n",
    "    print(f\"Actuator type distribution:\\n{df['actuator_type'].value_counts()[:5]}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Generate and save sample data\n",
    "    df = generate_and_save_sample(\n",
    "        num_records=100, \n",
    "        output_file=\"data/actuators_data.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec0db8",
   "metadata": {},
   "source": [
    "ActuatorCommands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f93f5622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10000 actuator commands...\n",
      "Generated 10000 commands so far...\n",
      "Successfully generated 10000 actuator commands.\n",
      "Data saved to data/actuator_commands.csv\n",
      "\n",
      "Sample data (first 5 records):\n",
      "         command_id   actuator_id                timestamp  command_value  \\\n",
      "0  CMD-3B0FE47DA496  ACT-EF54959F  2025-07-08 20:38:42.771            1.0   \n",
      "1  CMD-AF14DC8DE979  ACT-EF54959F  2025-07-08 20:43:54.456            1.0   \n",
      "2  CMD-7A7A7DA249D9  ACT-EF54959F  2025-07-08 22:01:24.123            1.0   \n",
      "3  CMD-10A270E97B11  ACT-EF54959F  2025-07-08 23:11:30.013            1.0   \n",
      "4  CMD-392AC3FD6B89  ACT-EF54959F  2025-07-09 01:21:39.333            1.0   \n",
      "\n",
      "  command_type control_mode operator_id        batch_id        step_id  \n",
      "0         open         Auto         NaN  BATCH-E5574981  STEP-F3AB499C  \n",
      "1         open         Auto         NaN  BATCH-E50133B1            NaN  \n",
      "2         open         Auto         NaN  BATCH-E5574981            NaN  \n",
      "3         open       Manual   OP-B6553C  BATCH-68D30686  STEP-4A057770  \n",
      "4         open       Manual   OP-3740CB  BATCH-E5574981  STEP-3CCF4245  \n",
      "\n",
      "Data Statistics:\n",
      "Total commands: 10000\n",
      "Unique actuators: 100\n",
      "Unique batches: 20\n",
      "Unique steps: 50\n",
      "Unique operators: 15\n",
      "Command types: ['close', 'open', 'position', 'reset', 'setpoint', 'speed', 'start', 'stop']\n",
      "Control modes: ['Auto', 'Cascade', 'Manual', 'Supervised']\n",
      "Time range (from sample): approximately 2025-07-08 19:18:59.994000 to 2025-07-15 18:45:34.620000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def load_actuators_data(actuators_file=\"data/actuators_data.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated actuators data\n",
    "    \n",
    "    Parameters:\n",
    "    - actuators_file: CSV file containing actuator data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the actuators data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(actuators_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Actuators data file {actuators_file} not found.\")\n",
    "        print(\"Please run the actuators data generation script first.\")\n",
    "        return None\n",
    "\n",
    "def generate_actuator_commands(actuators_df, num_commands_per_actuator=100, \n",
    "                            start_time=None, end_time=None, output_file=\"data/actuator_commands.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic actuator commands data based on the actuators table\n",
    "    \n",
    "    Parameters:\n",
    "    - actuators_df: DataFrame containing actuator data\n",
    "    - num_commands_per_actuator: Number of commands to generate per actuator\n",
    "    - start_time: Start time for commands (defaults to 7 days ago)\n",
    "    - end_time: End time for commands (defaults to now)\n",
    "    - output_file: CSV file to save the commands data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing a sample of the generated commands data\n",
    "    \"\"\"\n",
    "    if actuators_df is None or len(actuators_df) == 0:\n",
    "        print(\"Error: No actuator data available.\")\n",
    "        return None\n",
    "    \n",
    "    # Set default time range if not provided\n",
    "    if start_time is None:\n",
    "        start_time = datetime.now() - timedelta(days=7)\n",
    "    if end_time is None:\n",
    "        end_time = datetime.now()\n",
    "    \n",
    "    # Create a set of batch IDs, step IDs and operator IDs to simulate relationships\n",
    "    batch_ids = [f\"BATCH-{uuid.uuid4().hex[:8].upper()}\" for _ in range(20)]\n",
    "    step_ids = [f\"STEP-{uuid.uuid4().hex[:8].upper()}\" for _ in range(50)]\n",
    "    operator_ids = [f\"OP-{uuid.uuid4().hex[:6].upper()}\" for _ in range(15)]\n",
    "    \n",
    "    # Command types and control modes\n",
    "    command_types = [\"position\", \"speed\", \"open\", \"close\", \"start\", \"stop\", \"setpoint\", \"reset\"]\n",
    "    control_modes = [\"Auto\", \"Manual\", \"Cascade\", \"Supervised\"]\n",
    "    \n",
    "    # Control mode weights (Auto is most common)\n",
    "    control_mode_weights = [0.7, 0.2, 0.05, 0.05]\n",
    "    \n",
    "    # Calculate total number of commands\n",
    "    total_commands = len(actuators_df) * num_commands_per_actuator\n",
    "    \n",
    "    # Prepare the output file with CSV writer for memory efficiency\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        fieldnames = [\n",
    "            'command_id', 'actuator_id', 'timestamp', 'command_value', \n",
    "            'command_type', 'control_mode', 'operator_id', 'batch_id', 'step_id'\n",
    "        ]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        print(f\"Generating {total_commands} actuator commands...\")\n",
    "        commands_count = 0\n",
    "        \n",
    "        # Process each actuator\n",
    "        for _, actuator in actuators_df.iterrows():\n",
    "            # Get the actuator's control range\n",
    "            min_val = actuator['control_range_min']\n",
    "            max_val = actuator['control_range_max']\n",
    "            actuator_type = actuator['actuator_type']\n",
    "            \n",
    "            # Determine appropriate command types for this actuator type\n",
    "            if actuator_type in ['valve', 'damper']:\n",
    "                specific_commands = [\"open\", \"close\", \"position\"]\n",
    "            elif actuator_type in ['motor', 'pump', 'fan', 'agitator', 'conveyor', 'mixer', 'blower']:\n",
    "                specific_commands = [\"start\", \"stop\", \"speed\"]\n",
    "            elif actuator_type in ['heater', 'compressor']:\n",
    "                specific_commands = [\"start\", \"stop\", \"setpoint\"]\n",
    "            elif actuator_type in ['cylinder', 'positioner']:\n",
    "                specific_commands = [\"position\", \"reset\"]\n",
    "            elif actuator_type in ['relay', 'switch']:\n",
    "                specific_commands = [\"open\", \"close\"]\n",
    "            else:\n",
    "                specific_commands = command_types\n",
    "            \n",
    "            # Generate timestamps within the specified range\n",
    "            time_points = sorted([\n",
    "                start_time + (end_time - start_time) * random.random()\n",
    "                for _ in range(num_commands_per_actuator)\n",
    "            ])\n",
    "            \n",
    "            # Generate commands for this actuator\n",
    "            for i in range(num_commands_per_actuator):\n",
    "                # Create a unique command ID\n",
    "                command_id = f\"CMD-{uuid.uuid4().hex[:12].upper()}\"\n",
    "                \n",
    "                # Format timestamp\n",
    "                timestamp = time_points[i].strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "                \n",
    "                # Select command type\n",
    "                command_type = random.choice(specific_commands)\n",
    "                \n",
    "                # Determine command value based on command type and actuator type\n",
    "                if command_type == \"open\" or command_type == \"start\":\n",
    "                    # For binary/open commands, use max value\n",
    "                    command_value = max_val\n",
    "                elif command_type == \"close\" or command_type == \"stop\":\n",
    "                    # For binary/close commands, use min value\n",
    "                    command_value = min_val\n",
    "                elif command_type == \"reset\":\n",
    "                    # Reset to a default position (usually 0 or middle)\n",
    "                    if min_val == 0 and max_val == 1:  # Binary\n",
    "                        command_value = 0\n",
    "                    else:\n",
    "                        command_value = min_val + (max_val - min_val) * 0.1  # 10% position\n",
    "                else:\n",
    "                    # For setpoints and positions, use a value within range\n",
    "                    # Create clustering around common setpoints (e.g., 0%, 25%, 50%, 75%, 100%)\n",
    "                    if random.random() < 0.6:  # 60% chance of common setpoint\n",
    "                        common_points = [\n",
    "                            min_val,\n",
    "                            min_val + (max_val - min_val) * 0.25,\n",
    "                            min_val + (max_val - min_val) * 0.5,\n",
    "                            min_val + (max_val - min_val) * 0.75,\n",
    "                            max_val\n",
    "                        ]\n",
    "                        command_value = random.choice(common_points)\n",
    "                    else:\n",
    "                        # Random value within range\n",
    "                        command_value = min_val + random.random() * (max_val - min_val)\n",
    "                \n",
    "                # Round command value appropriately\n",
    "                if min_val == 0 and max_val == 1:  # Binary actuator\n",
    "                    command_value = round(command_value)\n",
    "                else:\n",
    "                    command_value = round(command_value, 2)\n",
    "                \n",
    "                # Determine control mode (weighted selection)\n",
    "                control_mode = random.choices(control_modes, weights=control_mode_weights)[0]\n",
    "                \n",
    "                # Only include operator ID for manual control mode\n",
    "                if control_mode == \"Manual\":\n",
    "                    operator_id = random.choice(operator_ids)\n",
    "                else:\n",
    "                    operator_id = \"\"\n",
    "                \n",
    "                # Batch ID and Step ID (some commands may not be associated with a batch/step)\n",
    "                if random.random() < 0.8:  # 80% chance of having a batch\n",
    "                    batch_id = random.choice(batch_ids)\n",
    "                    # If there's a batch, high chance of having a step\n",
    "                    if random.random() < 0.9:  # 90% chance of having a step if there's a batch\n",
    "                        step_id = random.choice(step_ids)\n",
    "                    else:\n",
    "                        step_id = \"\"\n",
    "                else:\n",
    "                    batch_id = \"\"\n",
    "                    step_id = \"\"\n",
    "                \n",
    "                # Write the command to the CSV\n",
    "                writer.writerow({\n",
    "                    'command_id': command_id,\n",
    "                    'actuator_id': actuator['actuator_id'],\n",
    "                    'timestamp': timestamp,\n",
    "                    'command_value': command_value,\n",
    "                    'command_type': command_type,\n",
    "                    'control_mode': control_mode,\n",
    "                    'operator_id': operator_id,\n",
    "                    'batch_id': batch_id,\n",
    "                    'step_id': step_id\n",
    "                })\n",
    "                \n",
    "                commands_count += 1\n",
    "                if commands_count % 10000 == 0:\n",
    "                    print(f\"Generated {commands_count} commands so far...\")\n",
    "    \n",
    "    print(f\"Successfully generated {commands_count} actuator commands.\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    # Return a sample of the data (first 1000 rows) for preview\n",
    "    return pd.read_csv(output_file, nrows=1000)\n",
    "\n",
    "def get_sample_statistics(output_file):\n",
    "    \"\"\"\n",
    "    Get basic statistics about the generated data\n",
    "    \n",
    "    Parameters:\n",
    "    - output_file: CSV file containing the commands data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the first chunk to get column information\n",
    "        sample_df = pd.read_csv(output_file, nrows=1000)\n",
    "        \n",
    "        # Sample statistics on chunks to avoid memory issues\n",
    "        num_rows = 0\n",
    "        actuator_ids = set()\n",
    "        batch_ids = set()\n",
    "        step_ids = set()\n",
    "        operator_ids = set()\n",
    "        command_types = set()\n",
    "        control_modes = set()\n",
    "        \n",
    "        # Process in chunks\n",
    "        for chunk in pd.read_csv(output_file, chunksize=10000):\n",
    "            num_rows += len(chunk)\n",
    "            actuator_ids.update(chunk['actuator_id'].unique())\n",
    "            batch_ids.update([bid for bid in chunk['batch_id'].unique() if isinstance(bid, str) and bid])\n",
    "            step_ids.update([sid for sid in chunk['step_id'].unique() if isinstance(sid, str) and sid])\n",
    "            operator_ids.update([oid for oid in chunk['operator_id'].unique() if isinstance(oid, str) and oid])\n",
    "            command_types.update(chunk['command_type'].unique())\n",
    "            control_modes.update(chunk['control_mode'].unique())\n",
    "        \n",
    "        print(\"\\nData Statistics:\")\n",
    "        print(f\"Total commands: {num_rows}\")\n",
    "        print(f\"Unique actuators: {len(actuator_ids)}\")\n",
    "        print(f\"Unique batches: {len(batch_ids)}\")\n",
    "        print(f\"Unique steps: {len(step_ids)}\")\n",
    "        print(f\"Unique operators: {len(operator_ids)}\")\n",
    "        print(f\"Command types: {sorted(command_types)}\")\n",
    "        print(f\"Control modes: {sorted(control_modes)}\")\n",
    "        \n",
    "        # Get time range if available\n",
    "        if 'timestamp' in sample_df.columns:\n",
    "            # Get min and max timestamp from the sample\n",
    "            min_time = pd.to_datetime(sample_df['timestamp']).min()\n",
    "            max_time = pd.to_datetime(sample_df['timestamp']).max()\n",
    "            print(f\"Time range (from sample): approximately {min_time} to {max_time}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting statistics: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Load the actuators data\n",
    "    actuators_df = load_actuators_data()\n",
    "    \n",
    "    if actuators_df is not None:\n",
    "        # Define the time range (past 7 days)\n",
    "        end_time = datetime.now()\n",
    "        start_time = end_time - timedelta(days=7)\n",
    "        \n",
    "        # Generate commands\n",
    "        sample_df = generate_actuator_commands(\n",
    "            actuators_df, \n",
    "            num_commands_per_actuator=100,  # 100 commands per actuator\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            output_file=\"data/actuator_commands.csv\"\n",
    "        )\n",
    "        \n",
    "        # Display a sample of the data\n",
    "        if sample_df is not None:\n",
    "            print(\"\\nSample data (first 5 records):\")\n",
    "            print(sample_df.head())\n",
    "            \n",
    "            # Get statistics\n",
    "            get_sample_statistics(\"data/actuator_commands.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b71dbf4",
   "metadata": {},
   "source": [
    "DeviceDiagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aaa3ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2000 device diagnostic records...\n",
      "Successfully generated 2000 device diagnostic records.\n",
      "Data saved to data/device_diagnostics.csv\n",
      "\n",
      "Sample data (first 5 records):\n",
      "       diagnostic_id     device_id                timestamp  \\\n",
      "0  DIAG-078498B17D62  SEN-0C25D1C0  2025-06-15 21:02:37.927   \n",
      "1  DIAG-86B1F9CFBC73  SEN-0C25D1C0  2025-06-20 08:28:30.712   \n",
      "2  DIAG-0F953E086CDA  SEN-0C25D1C0  2025-06-21 15:20:21.753   \n",
      "3  DIAG-B05B63B3D703  SEN-0C25D1C0  2025-06-26 23:12:14.977   \n",
      "4  DIAG-D1056E3A8636  SEN-0C25D1C0  2025-07-01 20:24:37.738   \n",
      "\n",
      "      diagnostic_type  status_code                  diagnostic_message  \\\n",
      "0      Drift Analysis            0                    Normal operation   \n",
      "1  Response Time Test            0                    Normal operation   \n",
      "2  Communication Test            0        Device functioning correctly   \n",
      "3      Drift Analysis            0                   Diagnostic passed   \n",
      "4  Response Time Test            0  All parameters within normal range   \n",
      "\n",
      "   severity_level  battery_level  communication_quality  internal_temperature  \\\n",
      "0               0            NaN                   88.6                  29.2   \n",
      "1               0            NaN                   84.7                  28.4   \n",
      "2               0           94.7                   88.8                  23.7   \n",
      "3               0           75.0                   85.4                  30.9   \n",
      "4               0            NaN                   84.3                  26.7   \n",
      "\n",
      "   maintenance_required  \n",
      "0                     0  \n",
      "1                     0  \n",
      "2                     0  \n",
      "3                     0  \n",
      "4                     0  \n",
      "\n",
      "Data Statistics:\n",
      "Total diagnostic records: 2000\n",
      "Unique devices: 200\n",
      "Diagnostic types: ['Calibration Check', 'Communication Test', 'Current Draw Test', 'Drift Analysis', 'Feedback Verification', 'Interference Check', 'Leak Test', 'Lubrication Check', 'Movement Test', 'Position Verification', 'Power Supply Test', 'Range Verification', 'Response Time Test', 'Self-Diagnostic', 'Signal Quality Test', 'Speed Test', 'Torque Test', 'Wear Analysis']\n",
      "Status codes: [0, 1, 2]\n",
      "\n",
      "Severity Level Distribution:\n",
      "Level 0: 1879 records (94.0%)\n",
      "Level 1: 108 records (5.4%)\n",
      "Level 2: 13 records (0.7%)\n",
      "Level 3: 0 records (0.0%)\n",
      "Level 4: 0 records (0.0%)\n",
      "Level 5: 0 records (0.0%)\n",
      "\n",
      "Maintenance Required: 0 records (0.0%)\n",
      "Time range (from sample): approximately 2025-06-15 19:34:31.431000 to 2025-07-15 18:49:33.489000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def load_sensors_and_actuators_data(sensors_file=\"data/sensors_data.csv\", actuators_file=\"data/actuators_data.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated sensors and actuators data to create device diagnostics\n",
    "    \n",
    "    Parameters:\n",
    "    - sensors_file: CSV file containing sensor data\n",
    "    - actuators_file: CSV file containing actuator data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing combined device data\n",
    "    \"\"\"\n",
    "    devices_df = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        # Load sensors data\n",
    "        sensors_df = pd.read_csv(sensors_file)\n",
    "        sensors_df['device_type'] = 'sensor'\n",
    "        sensors_df = sensors_df.rename(columns={'sensor_id': 'device_id', 'sensor_type': 'device_subtype'})\n",
    "        \n",
    "        # Select relevant columns\n",
    "        sensors_cols = ['device_id', 'device_type', 'device_subtype', 'equipment_id', 'manufacturer', 'model_number', 'status']\n",
    "        sensors_df = sensors_df[sensors_cols]\n",
    "        \n",
    "        devices_df = pd.concat([devices_df, sensors_df])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Sensors data file {sensors_file} not found.\")\n",
    "    \n",
    "    try:\n",
    "        # Load actuators data\n",
    "        actuators_df = pd.read_csv(actuators_file)\n",
    "        actuators_df['device_type'] = 'actuator'\n",
    "        actuators_df = actuators_df.rename(columns={'actuator_id': 'device_id', 'actuator_type': 'device_subtype'})\n",
    "        \n",
    "        # Select relevant columns\n",
    "        actuators_cols = ['device_id', 'device_type', 'device_subtype', 'equipment_id', 'manufacturer', 'model_number', 'status']\n",
    "        actuators_df = actuators_df[actuators_cols]\n",
    "        \n",
    "        devices_df = pd.concat([devices_df, actuators_df])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Actuators data file {actuators_file} not found.\")\n",
    "    \n",
    "    if len(devices_df) == 0:\n",
    "        print(\"Error: No device data found. Please run sensor and actuator data generation scripts first.\")\n",
    "        return None\n",
    "    \n",
    "    return devices_df\n",
    "\n",
    "def generate_device_diagnostics(devices_df, num_diagnostics_per_device=10, \n",
    "                              start_time=None, end_time=None, output_file=\"data/device_diagnostics.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic device diagnostics data based on the sensors and actuators tables\n",
    "    \n",
    "    Parameters:\n",
    "    - devices_df: DataFrame containing device data\n",
    "    - num_diagnostics_per_device: Number of diagnostic records to generate per device\n",
    "    - start_time: Start time for diagnostics (defaults to 30 days ago)\n",
    "    - end_time: End time for diagnostics (defaults to now)\n",
    "    - output_file: CSV file to save the diagnostics data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing a sample of the generated diagnostics data\n",
    "    \"\"\"\n",
    "    if devices_df is None or len(devices_df) == 0:\n",
    "        print(\"Error: No device data available.\")\n",
    "        return None\n",
    "    \n",
    "    # Set default time range if not provided (diagnostic data typically spans longer time than readings)\n",
    "    if start_time is None:\n",
    "        start_time = datetime.now() - timedelta(days=30)\n",
    "    if end_time is None:\n",
    "        end_time = datetime.now()\n",
    "    \n",
    "    # Define diagnostic types\n",
    "    diagnostic_types = {\n",
    "        'sensor': [\n",
    "            'Calibration Check', 'Signal Quality Test', 'Range Verification', \n",
    "            'Response Time Test', 'Interference Check', 'Power Supply Test',\n",
    "            'Communication Test', 'Self-Diagnostic', 'Drift Analysis'\n",
    "        ],\n",
    "        'actuator': [\n",
    "            'Movement Test', 'Response Time Test', 'Leak Test', 'Position Verification', \n",
    "            'Torque Test', 'Speed Test', 'Current Draw Test', 'Self-Diagnostic',\n",
    "            'Feedback Verification', 'Lubrication Check', 'Wear Analysis'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Define severity levels (0 = normal, 1-5 = increasing severity)\n",
    "    severity_levels = [0, 0, 0, 0, 0, 1, 1, 2, 2, 3, 4, 5]  # Weighted towards normal\n",
    "    \n",
    "    # Define status codes\n",
    "    # 0 = Normal, 1 = Warning, 2 = Minor Issue, 3 = Moderate Issue, 4 = Major Issue, 5 = Critical Failure\n",
    "    status_code_messages = {\n",
    "        0: [\"Normal operation\", \"No issues detected\", \"All parameters within normal range\", \n",
    "            \"Device functioning correctly\", \"Diagnostic passed\"],\n",
    "        1: [\"Minor deviation detected\", \"Parameter near warning threshold\", \"Slight performance degradation\", \n",
    "            \"Recommend monitoring\", \"Non-critical warning\"],\n",
    "        2: [\"Parameter outside optimal range\", \"Performance degradation detected\", \"Maintenance recommended\", \n",
    "            \"Minor issue detected\", \"Device requires attention\"],\n",
    "        3: [\"Significant deviation detected\", \"Multiple parameters out of range\", \"Performance significantly degraded\", \n",
    "            \"Maintenance required soon\", \"Device operating outside specifications\"],\n",
    "        4: [\"Major issue detected\", \"Device may fail soon\", \"Immediate maintenance required\", \n",
    "            \"Performance severely degraded\", \"Reliability compromised\"],\n",
    "        5: [\"Critical failure detected\", \"Device non-operational\", \"Emergency maintenance required\", \n",
    "            \"Safety risk possible\", \"Replace device immediately\"]\n",
    "    }\n",
    "    \n",
    "    # Calculate total number of diagnostics\n",
    "    total_diagnostics = len(devices_df) * num_diagnostics_per_device\n",
    "    \n",
    "    # Prepare the output file with CSV writer for memory efficiency\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        fieldnames = [\n",
    "            'diagnostic_id', 'device_id', 'timestamp', 'diagnostic_type', \n",
    "            'status_code', 'diagnostic_message', 'severity_level', \n",
    "            'battery_level', 'communication_quality', 'internal_temperature',\n",
    "            'maintenance_required'\n",
    "        ]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        print(f\"Generating {total_diagnostics} device diagnostic records...\")\n",
    "        diagnostics_count = 0\n",
    "        \n",
    "        # Process each device\n",
    "        for _, device in devices_df.iterrows():\n",
    "            device_id = device['device_id']\n",
    "            device_type = device['device_type']\n",
    "            device_subtype = device['device_subtype']\n",
    "            device_status = device['status']\n",
    "            \n",
    "            # Get applicable diagnostic types for this device type\n",
    "            applicable_diagnostics = diagnostic_types.get(device_type, diagnostic_types['sensor'])\n",
    "            \n",
    "            # Generate timestamps within the specified range (more spread out than readings)\n",
    "            time_points = sorted([\n",
    "                start_time + (end_time - start_time) * random.random()\n",
    "                for _ in range(num_diagnostics_per_device)\n",
    "            ])\n",
    "            \n",
    "            # Current device state (will evolve over time to simulate deterioration)\n",
    "            device_health = 100.0  # Start at 100% health\n",
    "            \n",
    "            # Rate of deterioration (different for each device)\n",
    "            deterioration_rate = random.uniform(0.1, 2.0)\n",
    "            \n",
    "            # Generate diagnostic records for this device\n",
    "            for i in range(num_diagnostics_per_device):\n",
    "                # Create a unique diagnostic ID\n",
    "                diagnostic_id = f\"DIAG-{uuid.uuid4().hex[:12].upper()}\"\n",
    "                \n",
    "                # Format timestamp\n",
    "                timestamp = time_points[i].strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "                \n",
    "                # Determine diagnostic type\n",
    "                diagnostic_type = random.choice(applicable_diagnostics)\n",
    "                \n",
    "                # Simulate device health deterioration over time\n",
    "                # Devices in \"Maintenance\" or \"Fault\" status deteriorate faster\n",
    "                if device_status in [\"Maintenance\", \"Fault\"]:\n",
    "                    deterioration_factor = 2.0\n",
    "                else:\n",
    "                    deterioration_factor = 1.0\n",
    "                \n",
    "                # Calculate position in time series (0 to 1)\n",
    "                time_position = i / (num_diagnostics_per_device - 1) if num_diagnostics_per_device > 1 else 0\n",
    "                \n",
    "                # Decrease health over time with some randomness\n",
    "                health_decrease = deterioration_rate * deterioration_factor * time_position\n",
    "                health_decrease += random.uniform(-0.5, 0.5) * health_decrease  # Add noise\n",
    "                device_health -= health_decrease\n",
    "                device_health = max(50, device_health)  # Don't let it go below 50%\n",
    "                \n",
    "                # Determine severity based on device health and some randomness\n",
    "                if device_health > 95:\n",
    "                    severity_candidates = [0]\n",
    "                elif device_health > 90:\n",
    "                    severity_candidates = [0, 0, 0, 1]\n",
    "                elif device_health > 80:\n",
    "                    severity_candidates = [0, 0, 1, 1, 2]\n",
    "                elif device_health > 70:\n",
    "                    severity_candidates = [0, 1, 1, 2, 2]\n",
    "                elif device_health > 60:\n",
    "                    severity_candidates = [1, 2, 2, 3, 3]\n",
    "                else:\n",
    "                    severity_candidates = [2, 3, 3, 4, 4, 5]\n",
    "                \n",
    "                severity_level = random.choice(severity_candidates)\n",
    "                \n",
    "                # Set status code based on severity\n",
    "                status_code = severity_level\n",
    "                \n",
    "                # Get appropriate diagnostic message\n",
    "                diagnostic_message = random.choice(status_code_messages[status_code])\n",
    "                \n",
    "                # Generate battery level (only for wireless devices)\n",
    "                has_battery = random.random() < 0.3  # 30% of devices are wireless\n",
    "                if has_battery:\n",
    "                    # Battery level decreases over time, with some recharges\n",
    "                    base_battery = 100 - 50 * time_position  # Decreases from 100% to 50%\n",
    "                    # Occasionally \"recharge\" the battery\n",
    "                    if random.random() < 0.2:  # 20% chance of recent recharge\n",
    "                        base_battery = min(100, base_battery + random.uniform(30, 80))\n",
    "                    \n",
    "                    battery_level = round(base_battery + random.uniform(-10, 10), 1)  # Add some noise\n",
    "                    battery_level = max(5, min(100, battery_level))  # Keep between 5% and 100%\n",
    "                else:\n",
    "                    battery_level = None\n",
    "                \n",
    "                # Generate communication quality\n",
    "                base_comm_quality = 100 - 20 * time_position  # Slight degradation over time\n",
    "                # Add random fluctuations\n",
    "                comm_quality = round(base_comm_quality + random.uniform(-15, 5), 1)\n",
    "                comm_quality = max(60, min(100, comm_quality))  # Keep between 60% and 100%\n",
    "                \n",
    "                # Generate internal temperature\n",
    "                if device_type == 'sensor':\n",
    "                    # Sensors typically run cooler\n",
    "                    base_temp = 25 + 5 * time_position  # Gradual increase over time\n",
    "                    temp_variation = random.uniform(-3, 5)\n",
    "                else:\n",
    "                    # Actuators often run hotter\n",
    "                    base_temp = 30 + 8 * time_position  # More significant increase over time\n",
    "                    temp_variation = random.uniform(-3, 8)\n",
    "                \n",
    "                internal_temperature = round(base_temp + temp_variation, 1)\n",
    "                \n",
    "                # Determine if maintenance is required\n",
    "                maintenance_required = severity_level >= 3  # Levels 3, 4, 5 require maintenance\n",
    "                \n",
    "                # Write the diagnostic record to the CSV\n",
    "                writer.writerow({\n",
    "                    'diagnostic_id': diagnostic_id,\n",
    "                    'device_id': device_id,\n",
    "                    'timestamp': timestamp,\n",
    "                    'diagnostic_type': diagnostic_type,\n",
    "                    'status_code': status_code,\n",
    "                    'diagnostic_message': diagnostic_message,\n",
    "                    'severity_level': severity_level,\n",
    "                    'battery_level': battery_level if has_battery else '',\n",
    "                    'communication_quality': comm_quality,\n",
    "                    'internal_temperature': internal_temperature,\n",
    "                    'maintenance_required': 1 if maintenance_required else 0\n",
    "                })\n",
    "                \n",
    "                diagnostics_count += 1\n",
    "                if diagnostics_count % 10000 == 0:\n",
    "                    print(f\"Generated {diagnostics_count} diagnostic records so far...\")\n",
    "    \n",
    "    print(f\"Successfully generated {diagnostics_count} device diagnostic records.\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    # Return a sample of the data (first 1000 rows) for preview\n",
    "    return pd.read_csv(output_file, nrows=1000)\n",
    "\n",
    "def get_sample_statistics(output_file):\n",
    "    \"\"\"\n",
    "    Get basic statistics about the generated diagnostics data\n",
    "    \n",
    "    Parameters:\n",
    "    - output_file: CSV file containing the diagnostics data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the first chunk to get column information\n",
    "        sample_df = pd.read_csv(output_file, nrows=1000)\n",
    "        \n",
    "        # Sample statistics on chunks to avoid memory issues\n",
    "        num_rows = 0\n",
    "        device_ids = set()\n",
    "        diagnostic_types = set()\n",
    "        status_codes = set()\n",
    "        severity_counts = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "        maintenance_required_count = 0\n",
    "        \n",
    "        # Process in chunks\n",
    "        for chunk in pd.read_csv(output_file, chunksize=10000):\n",
    "            num_rows += len(chunk)\n",
    "            device_ids.update(chunk['device_id'].unique())\n",
    "            diagnostic_types.update(chunk['diagnostic_type'].unique())\n",
    "            status_codes.update(chunk['status_code'].unique())\n",
    "            \n",
    "            # Count severity levels\n",
    "            for severity in range(6):\n",
    "                severity_counts[severity] += len(chunk[chunk['severity_level'] == severity])\n",
    "            \n",
    "            # Count maintenance required\n",
    "            maintenance_required_count += chunk['maintenance_required'].sum()\n",
    "        \n",
    "        print(\"\\nData Statistics:\")\n",
    "        print(f\"Total diagnostic records: {num_rows}\")\n",
    "        print(f\"Unique devices: {len(device_ids)}\")\n",
    "        print(f\"Diagnostic types: {sorted(diagnostic_types)}\")\n",
    "        print(f\"Status codes: {sorted(status_codes)}\")\n",
    "        \n",
    "        print(\"\\nSeverity Level Distribution:\")\n",
    "        for severity, count in severity_counts.items():\n",
    "            percentage = (count / num_rows) * 100 if num_rows > 0 else 0\n",
    "            print(f\"Level {severity}: {count} records ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nMaintenance Required: {maintenance_required_count} records ({(maintenance_required_count / num_rows) * 100:.1f}%)\")\n",
    "        \n",
    "        # Get time range if available\n",
    "        if 'timestamp' in sample_df.columns:\n",
    "            min_time = pd.to_datetime(sample_df['timestamp']).min()\n",
    "            max_time = pd.to_datetime(sample_df['timestamp']).max()\n",
    "            print(f\"Time range (from sample): approximately {min_time} to {max_time}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting statistics: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Load the device data (combining sensors and actuators)\n",
    "    devices_df = load_sensors_and_actuators_data()\n",
    "    \n",
    "    if devices_df is not None:\n",
    "        # Define the time range (past 30 days for diagnostics)\n",
    "        end_time = datetime.now()\n",
    "        start_time = end_time - timedelta(days=30)\n",
    "        \n",
    "        # Generate diagnostic records\n",
    "        sample_df = generate_device_diagnostics(\n",
    "            devices_df, \n",
    "            num_diagnostics_per_device=10,  # 10 diagnostics per device\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            output_file=\"data/device_diagnostics.csv\"\n",
    "        )\n",
    "        \n",
    "        # Display a sample of the data\n",
    "        if sample_df is not None:\n",
    "            print(\"\\nSample data (first 5 records):\")\n",
    "            print(sample_df.head())\n",
    "            \n",
    "            # Get statistics\n",
    "            get_sample_statistics(\"data/device_diagnostics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c004b08",
   "metadata": {},
   "source": [
    "ControlLoops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c80913f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 50 control loops...\n",
      "Successfully generated 50 control loops.\n",
      "Data saved to data/control_loops.csv\n",
      "\n",
      "Sample data (first 5 records):\n",
      "         loop_id                    loop_name process_variable_sensor_id  \\\n",
      "0  LOOP-B9F55919  Oxygen-Positioner Control 1               SEN-5108DE00   \n",
      "1  LOOP-4DCCB066      Humidity-Pump Control 2               SEN-ED322A76   \n",
      "2  LOOP-F2C8B181       Oxygen-Doser Control 3               SEN-D8485E11   \n",
      "3  LOOP-744E9C8F           Flow-Fan Control 4               SEN-36198AE5   \n",
      "4  LOOP-94ACA76F        Flow-Heater Control 5               SEN-D5682186   \n",
      "\n",
      "  control_output_actuator_id controller_type control_mode  setpoint_value  \\\n",
      "0               ACT-E271F55F           Ratio      Cascade           16.52   \n",
      "1               ACT-4B0AFAAC             PID         Auto           57.44   \n",
      "2               ACT-8BB70EA3             PID         Auto           16.61   \n",
      "3               ACT-B4C149AC             PID      Cascade           80.19   \n",
      "4               ACT-BCB64149             PID         Auto           79.70   \n",
      "\n",
      "  setpoint_unit  p_value  i_value  d_value equipment_id  status  \n",
      "0             %    18.65    2.274    0.939  EQ-78EB9935  Active  \n",
      "1           %RH     5.31    1.250    0.458  EQ-C0EC1A01  Active  \n",
      "2             %     7.06    1.291    0.141  EQ-C3AF6C97  Active  \n",
      "3          m³/h     3.61    0.941    0.304  EQ-6E8BD686  Tuning  \n",
      "4          m³/h     7.43    0.559    0.002  EQ-D56E7067  Active  \n",
      "\n",
      "Control Loops Statistics:\n",
      "Total control loops: 50\n",
      "\n",
      "Controller Type Distribution:\n",
      "  PID: 29 (58.0%)\n",
      "  Cascade: 8 (16.0%)\n",
      "  Ratio: 4 (8.0%)\n",
      "  Model Predictive: 4 (8.0%)\n",
      "  Fuzzy Logic: 2 (4.0%)\n",
      "  Feedforward: 2 (4.0%)\n",
      "  On-Off: 1 (2.0%)\n",
      "\n",
      "Control Mode Distribution:\n",
      "  Auto: 34 (68.0%)\n",
      "  Manual: 8 (16.0%)\n",
      "  Cascade: 5 (10.0%)\n",
      "  Supervised: 3 (6.0%)\n",
      "\n",
      "Status Distribution:\n",
      "  Active: 41 (82.0%)\n",
      "  Inactive: 5 (10.0%)\n",
      "  Tuning: 3 (6.0%)\n",
      "  Fault: 1 (2.0%)\n",
      "\n",
      "PID Parameters (Average):\n",
      "  P: 7.37\n",
      "  I: 1.549\n",
      "  D: 0.557\n",
      "\n",
      "Unique process variable sensors: 50 of 50\n",
      "Unique control output actuators: 28 of 50\n",
      "\n",
      "Common Control Loop Types:\n",
      "  temperature-heater: 3 loops\n",
      "  ph-pump: 3 loops\n",
      "  weight-pump: 2 loops\n",
      "  co2-motor: 2 loops\n",
      "  co2-valve: 2 loops\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "\n",
    "def load_devices_data(sensors_file=\"data/sensors_data.csv\", actuators_file=\"data/actuators_data.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated sensors and actuators data to create control loops\n",
    "    \n",
    "    Parameters:\n",
    "    - sensors_file: CSV file containing sensor data\n",
    "    - actuators_file: CSV file containing actuator data\n",
    "    \n",
    "    Returns:\n",
    "    - Two DataFrames containing sensors and actuators data\n",
    "    \"\"\"\n",
    "    sensors_df = None\n",
    "    actuators_df = None\n",
    "    \n",
    "    try:\n",
    "        # Load sensors data\n",
    "        sensors_df = pd.read_csv(sensors_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Sensors data file {sensors_file} not found.\")\n",
    "    \n",
    "    try:\n",
    "        # Load actuators data\n",
    "        actuators_df = pd.read_csv(actuators_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Actuators data file {actuators_file} not found.\")\n",
    "    \n",
    "    if sensors_df is None or actuators_df is None:\n",
    "        print(\"Error: Both sensor and actuator data are required for control loops. Please run sensor and actuator data generation scripts first.\")\n",
    "        return None, None\n",
    "    \n",
    "    return sensors_df, actuators_df\n",
    "\n",
    "def generate_control_loops_data(sensors_df, actuators_df, num_loops=50, output_file=\"data/control_loops.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic control loops data based on the sensors and actuators tables\n",
    "    \n",
    "    Parameters:\n",
    "    - sensors_df: DataFrame containing sensors data\n",
    "    - actuators_df: DataFrame containing actuators data\n",
    "    - num_loops: Number of control loops to generate\n",
    "    - output_file: CSV file to save the control loops data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the generated control loops data\n",
    "    \"\"\"\n",
    "    if sensors_df is None or actuators_df is None or len(sensors_df) == 0 or len(actuators_df) == 0:\n",
    "        print(\"Error: Valid sensor and actuator data required.\")\n",
    "        return None\n",
    "    \n",
    "    # Filter sensors by type (only certain sensor types are used for process variables)\n",
    "    pv_sensor_types = ['temperature', 'pressure', 'flow', 'level', 'ph', 'conductivity', \n",
    "                       'speed', 'position', 'weight', 'humidity', 'oxygen', 'co2']\n",
    "    \n",
    "    pv_sensors_df = sensors_df[sensors_df['sensor_type'].isin(pv_sensor_types)]\n",
    "    \n",
    "    if len(pv_sensors_df) == 0:\n",
    "        print(\"Warning: No suitable process variable sensors found. Using all sensors instead.\")\n",
    "        pv_sensors_df = sensors_df\n",
    "    \n",
    "    # Filter actuators by type (only certain actuator types are used for control outputs)\n",
    "    cv_actuator_types = ['valve', 'motor', 'pump', 'heater', 'fan', 'agitator', \n",
    "                         'damper', 'positioner', 'doser', 'compressor']\n",
    "    \n",
    "    cv_actuators_df = actuators_df[actuators_df['actuator_type'].isin(cv_actuator_types)]\n",
    "    \n",
    "    if len(cv_actuators_df) == 0:\n",
    "        print(\"Warning: No suitable control variable actuators found. Using all actuators instead.\")\n",
    "        cv_actuators_df = actuators_df\n",
    "    \n",
    "    # Make sure we have enough sensors and actuators\n",
    "    num_loops = min(num_loops, len(pv_sensors_df), len(cv_actuators_df))\n",
    "    \n",
    "    if num_loops == 0:\n",
    "        print(\"Error: Not enough sensors and actuators to create control loops.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Generating {num_loops} control loops...\")\n",
    "    \n",
    "    # Get unique equipment IDs\n",
    "    equipment_ids = list(set(sensors_df['equipment_id'].unique()) | set(actuators_df['equipment_id'].unique()))\n",
    "    \n",
    "    # Define controller types and their probabilities\n",
    "    controller_types = {\n",
    "        \"PID\": 0.6,        # Most common\n",
    "        \"Cascade\": 0.15,\n",
    "        \"Feedforward\": 0.1,\n",
    "        \"On-Off\": 0.05,\n",
    "        \"Ratio\": 0.05,\n",
    "        \"Model Predictive\": 0.03,\n",
    "        \"Fuzzy Logic\": 0.02\n",
    "    }\n",
    "    \n",
    "    # Define control modes and their probabilities\n",
    "    control_modes = {\n",
    "        \"Auto\": 0.7,       # Most common\n",
    "        \"Manual\": 0.15,\n",
    "        \"Cascade\": 0.1,\n",
    "        \"Supervised\": 0.05\n",
    "    }\n",
    "    \n",
    "    # Create data structure\n",
    "    data = {\n",
    "        'loop_id': [f\"LOOP-{uuid.uuid4().hex[:8].upper()}\" for _ in range(num_loops)],\n",
    "        'loop_name': [],\n",
    "        'process_variable_sensor_id': [],\n",
    "        'control_output_actuator_id': [],\n",
    "        'controller_type': [],\n",
    "        'control_mode': [],\n",
    "        'setpoint_value': [],\n",
    "        'setpoint_unit': [],\n",
    "        'p_value': [],\n",
    "        'i_value': [],\n",
    "        'd_value': [],\n",
    "        'equipment_id': [],\n",
    "        'status': []\n",
    "    }\n",
    "    \n",
    "    # Sample sensors and actuators without replacement to ensure uniqueness\n",
    "    sampled_sensors = pv_sensors_df.sample(n=num_loops).reset_index(drop=True)\n",
    "    sampled_actuators = cv_actuators_df.sample(n=num_loops).reset_index(drop=True)\n",
    "    \n",
    "    # Create logical pairings based on sensor and actuator types\n",
    "    pairings = []\n",
    "    \n",
    "    # First, try to pair sensors and actuators on the same equipment\n",
    "    for i in range(num_loops):\n",
    "        sensor = sampled_sensors.iloc[i]\n",
    "        \n",
    "        # Find actuators on the same equipment as this sensor\n",
    "        same_equipment_actuators = sampled_actuators[sampled_actuators['equipment_id'] == sensor['equipment_id']]\n",
    "        \n",
    "        if len(same_equipment_actuators) > 0:\n",
    "            # Pick a random actuator from the same equipment\n",
    "            actuator = same_equipment_actuators.sample(1).iloc[0]\n",
    "            equipment_id = sensor['equipment_id']\n",
    "        else:\n",
    "            # If no matching actuator on same equipment, just pick a random one\n",
    "            actuator = sampled_actuators.iloc[i]\n",
    "            \n",
    "            # Use one of their equipment IDs (prefer the sensor's)\n",
    "            if random.random() < 0.7:\n",
    "                equipment_id = sensor['equipment_id']\n",
    "            else:\n",
    "                equipment_id = actuator['equipment_id']\n",
    "        \n",
    "        pairings.append((sensor, actuator, equipment_id))\n",
    "    \n",
    "    # Create appropriate loop names and parameter values\n",
    "    for i, (sensor, actuator, equipment_id) in enumerate(pairings):\n",
    "        # Create a descriptive loop name based on what it controls\n",
    "        sensor_type = sensor['sensor_type']\n",
    "        actuator_type = actuator['actuator_type']\n",
    "        \n",
    "        # Create logical loop name\n",
    "        if sensor_type == 'temperature' and actuator_type in ['heater', 'valve']:\n",
    "            loop_name = f\"Temperature Control {i+1}\"\n",
    "        elif sensor_type == 'flow' and actuator_type in ['valve', 'pump']:\n",
    "            loop_name = f\"Flow Control {i+1}\"\n",
    "        elif sensor_type == 'pressure' and actuator_type in ['valve', 'compressor']:\n",
    "            loop_name = f\"Pressure Control {i+1}\"\n",
    "        elif sensor_type == 'level' and actuator_type in ['valve', 'pump']:\n",
    "            loop_name = f\"Level Control {i+1}\"\n",
    "        elif sensor_type == 'ph' and actuator_type in ['pump', 'valve', 'doser']:\n",
    "            loop_name = f\"pH Control {i+1}\"\n",
    "        elif sensor_type == 'speed' and actuator_type in ['motor', 'fan']:\n",
    "            loop_name = f\"Speed Control {i+1}\"\n",
    "        elif sensor_type == 'position' and actuator_type in ['positioner', 'motor']:\n",
    "            loop_name = f\"Position Control {i+1}\"\n",
    "        else:\n",
    "            loop_name = f\"{sensor_type.capitalize()}-{actuator_type.capitalize()} Control {i+1}\"\n",
    "        \n",
    "        data['loop_name'].append(loop_name)\n",
    "        data['process_variable_sensor_id'].append(sensor['sensor_id'])\n",
    "        data['control_output_actuator_id'].append(actuator['actuator_id'])\n",
    "        \n",
    "        # Select controller type (weighted random)\n",
    "        data['controller_type'].append(\n",
    "            random.choices(list(controller_types.keys()), \n",
    "                         weights=list(controller_types.values()))[0]\n",
    "        )\n",
    "        \n",
    "        # Select control mode (weighted random)\n",
    "        data['control_mode'].append(\n",
    "            random.choices(list(control_modes.keys()), \n",
    "                         weights=list(control_modes.values()))[0]\n",
    "        )\n",
    "        \n",
    "        # Set appropriate setpoint based on sensor type\n",
    "        sensor_unit = sensor['measurement_unit']\n",
    "        sensor_range_min = sensor['measurement_range_min']\n",
    "        sensor_range_max = sensor['measurement_range_max']\n",
    "        \n",
    "        # Set setpoint somewhere in the middle of the range\n",
    "        setpoint = sensor_range_min + (sensor_range_max - sensor_range_min) * random.uniform(0.3, 0.7)\n",
    "        data['setpoint_value'].append(round(setpoint, 2))\n",
    "        data['setpoint_unit'].append(sensor_unit)\n",
    "        \n",
    "        # Set PID parameters based on controller type\n",
    "        controller_type = data['controller_type'][-1]\n",
    "        \n",
    "        if controller_type == \"PID\":\n",
    "            # Standard PID values\n",
    "            p_value = round(random.uniform(0.5, 10.0), 2)\n",
    "            i_value = round(random.uniform(0.05, 2.0), 3)\n",
    "            d_value = round(random.uniform(0, 0.5), 3)\n",
    "        elif controller_type == \"On-Off\":\n",
    "            # On-Off controllers don't use P, I, D in the same way\n",
    "            p_value = 1.0  # Just binary\n",
    "            i_value = 0.0\n",
    "            d_value = 0.0\n",
    "        else:\n",
    "            # Other controller types with some variation\n",
    "            p_value = round(random.uniform(0.1, 20.0), 2)\n",
    "            i_value = round(random.uniform(0, 5.0), 3)\n",
    "            d_value = round(random.uniform(0, 2.0), 3)\n",
    "        \n",
    "        data['p_value'].append(p_value)\n",
    "        data['i_value'].append(i_value)\n",
    "        data['d_value'].append(d_value)\n",
    "        \n",
    "        # Set equipment and status\n",
    "        data['equipment_id'].append(equipment_id)\n",
    "        \n",
    "        # Status (mostly active)\n",
    "        statuses = [\"Active\", \"Tuning\", \"Inactive\", \"Fault\"]\n",
    "        weights = [0.85, 0.05, 0.07, 0.03]  # Mostly active\n",
    "        data['status'].append(random.choices(statuses, weights=weights)[0])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Successfully generated {num_loops} control loops.\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def display_statistics(df):\n",
    "    \"\"\"\n",
    "    Display basic statistics about the generated control loops data\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing control loops data\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"No data to analyze.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nControl Loops Statistics:\")\n",
    "    print(f\"Total control loops: {len(df)}\")\n",
    "    \n",
    "    print(\"\\nController Type Distribution:\")\n",
    "    type_counts = df['controller_type'].value_counts()\n",
    "    for controller_type, count in type_counts.items():\n",
    "        print(f\"  {controller_type}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nControl Mode Distribution:\")\n",
    "    mode_counts = df['control_mode'].value_counts()\n",
    "    for control_mode, count in mode_counts.items():\n",
    "        print(f\"  {control_mode}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nStatus Distribution:\")\n",
    "    status_counts = df['status'].value_counts()\n",
    "    for status, count in status_counts.items():\n",
    "        print(f\"  {status}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nPID Parameters (Average):\")\n",
    "    print(f\"  P: {df['p_value'].mean():.2f}\")\n",
    "    print(f\"  I: {df['i_value'].mean():.3f}\")\n",
    "    print(f\"  D: {df['d_value'].mean():.3f}\")\n",
    "    \n",
    "    # Check for uniqueness\n",
    "    print(f\"\\nUnique process variable sensors: {df['process_variable_sensor_id'].nunique()} of {len(df)}\")\n",
    "    print(f\"Unique control output actuators: {df['control_output_actuator_id'].nunique()} of {len(df)}\")\n",
    "    \n",
    "    # Analyze the most common sensor-actuator pairings\n",
    "    print(\"\\nCommon Control Loop Types:\")\n",
    "    # Get sensor types\n",
    "    sensors_df = pd.read_csv(\"data/sensors_data.csv\")\n",
    "    actuators_df = pd.read_csv(\"data/actuators_data.csv\")\n",
    "    \n",
    "    # Merge to get sensor and actuator types\n",
    "    merged_df = df.merge(\n",
    "        sensors_df[['sensor_id', 'sensor_type']], \n",
    "        left_on='process_variable_sensor_id', \n",
    "        right_on='sensor_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    merged_df = merged_df.merge(\n",
    "        actuators_df[['actuator_id', 'actuator_type']], \n",
    "        left_on='control_output_actuator_id', \n",
    "        right_on='actuator_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Count sensor-actuator type pairs\n",
    "    pair_counts = merged_df.groupby(['sensor_type', 'actuator_type']).size().reset_index(name='count')\n",
    "    pair_counts = pair_counts.sort_values('count', ascending=False)\n",
    "    \n",
    "    # Display top 5 pairs\n",
    "    for _, row in pair_counts.head(5).iterrows():\n",
    "        print(f\"  {row['sensor_type']}-{row['actuator_type']}: {row['count']} loops\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Load the sensors and actuators data\n",
    "    sensors_df, actuators_df = load_devices_data()\n",
    "    \n",
    "    if sensors_df is not None and actuators_df is not None:\n",
    "        # Generate control loops data\n",
    "        control_loops_df = generate_control_loops_data(\n",
    "            sensors_df, \n",
    "            actuators_df,\n",
    "            num_loops=50,  # Number of control loops to generate\n",
    "            output_file=\"data/control_loops.csv\"\n",
    "        )\n",
    "        \n",
    "        # Display sample data and statistics\n",
    "        if control_loops_df is not None:\n",
    "            print(\"\\nSample data (first 5 records):\")\n",
    "            print(control_loops_df.head())\n",
    "            \n",
    "            # Display statistics\n",
    "            display_statistics(control_loops_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
