{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "768819de",
   "metadata": {},
   "source": [
    "Level 2: Process Monitoring & Supervision Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20503157",
   "metadata": {},
   "source": [
    "Equipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99feddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 existing equipment IDs from Level 1.\n",
      "Generating 130 additional equipment records.\n",
      "Successfully generated 150 equipment records.\n",
      "Data saved to data/equipment.csv\n",
      "\n",
      "Sample data (first 5 records):\n",
      "  equipment_id               equipment_name     equipment_type        area_id  \\\n",
      "0  EQ-9A644928  Falling Film Evaporator 715         Evaporator  AREA-CF44DDA4   \n",
      "1  EQ-8953C760              Case Packer 398  Packaging Machine  AREA-B64653E6   \n",
      "2  EQ-9F6621AF             Vacuum Dryer 654              Dryer  AREA-B64653E6   \n",
      "3  EQ-D56E7067  Continuous Crystallizer 637       Crystallizer  AREA-7FBCEF28   \n",
      "4  EQ-422154D2             Paddle Mixer 177              Mixer  AREA-7FBCEF28   \n",
      "\n",
      "  manufacturer model_number serial_number installation_date  \\\n",
      "0        Eaton   EAT-EV9056      SN516340        2023-10-15   \n",
      "1     Yokogawa   YOK-PA6751      SN932707        2024-04-01   \n",
      "2    Flowserve   FLO-DR5102      SN615451        2016-12-31   \n",
      "3   Alfa Laval   ALF-CR6667      SN923969        2015-10-25   \n",
      "4        Festo   FES-MI5382      SN187367        2023-05-29   \n",
      "\n",
      "  last_maintenance_date next_maintenance_date equipment_status  \\\n",
      "0            2025-02-01            2025-12-25          Running   \n",
      "1            2025-07-11            2025-10-22          Running   \n",
      "2            2025-05-14            2025-08-21          Running   \n",
      "3            2025-04-11            2025-08-01          Running   \n",
      "4            2025-01-22            2025-09-10          Running   \n",
      "\n",
      "  parent_equipment_id  \n",
      "0                      \n",
      "1                      \n",
      "2         EQ-6809A01E  \n",
      "3         EQ-870463FE  \n",
      "4                      \n",
      "\n",
      "Equipment Statistics:\n",
      "Total equipment: 150\n",
      "\n",
      "Equipment Type Distribution:\n",
      "  Conveyor: 10 (6.7%)\n",
      "  Crystallizer: 8 (5.3%)\n",
      "  Mixer: 8 (5.3%)\n",
      "  Tank: 8 (5.3%)\n",
      "  Extruder: 7 (4.7%)\n",
      "  Testing Station: 7 (4.7%)\n",
      "  Centrifuge: 7 (4.7%)\n",
      "  Packaging Machine: 7 (4.7%)\n",
      "  Furnace: 7 (4.7%)\n",
      "  CNC Machine: 6 (4.0%)\n",
      "\n",
      "Status Distribution:\n",
      "  Running: 88 (58.7%)\n",
      "  Idle: 30 (20.0%)\n",
      "  Fault: 10 (6.7%)\n",
      "  Maintenance: 7 (4.7%)\n",
      "  Offline: 7 (4.7%)\n",
      "  Standby: 6 (4.0%)\n",
      "  Startup: 2 (1.3%)\n",
      "\n",
      "Process Area Distribution:\n",
      "  AREA-CF44DDA4: 20 (13.3%)\n",
      "  AREA-1481E592: 18 (12.0%)\n",
      "  AREA-852DE6F5: 18 (12.0%)\n",
      "  AREA-430367D3: 15 (10.0%)\n",
      "  AREA-FD3916B8: 15 (10.0%)\n",
      "  AREA-B64653E6: 14 (9.3%)\n",
      "  AREA-0AE50033: 14 (9.3%)\n",
      "  AREA-E3317DB3: 13 (8.7%)\n",
      "  AREA-D0BBE7EE: 12 (8.0%)\n",
      "  AREA-7FBCEF28: 11 (7.3%)\n",
      "\n",
      "Manufacturer Distribution:\n",
      "  Mitsubishi Electric: 8 (5.3%)\n",
      "  Siemens: 8 (5.3%)\n",
      "  Yokogawa: 8 (5.3%)\n",
      "  Emerson: 8 (5.3%)\n",
      "  Omron: 8 (5.3%)\n",
      "\n",
      "Hierarchy Statistics:\n",
      "  Equipment with parent: 32 (21.3%)\n",
      "  Top-level equipment: 118 (78.7%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "\n",
    "def load_level1_data(sensors_file=\"data/sensors_data.csv\", \n",
    "                     actuators_file=\"data/actuators_data.csv\",\n",
    "                     control_loops_file=\"data/control_loops.csv\"):\n",
    "    \"\"\"\n",
    "    Load previously generated Level 1 data to extract equipment IDs and create relationships\n",
    "    \n",
    "    Parameters:\n",
    "    - sensors_file: CSV file containing sensor data\n",
    "    - actuators_file: CSV file containing actuator data\n",
    "    - control_loops_file: CSV file containing control loops data\n",
    "    \n",
    "    Returns:\n",
    "    - Set of unique equipment IDs from Level 1 data\n",
    "    \"\"\"\n",
    "    equipment_ids = set()\n",
    "    \n",
    "    # Try to load sensors data\n",
    "    try:\n",
    "        sensors_df = pd.read_csv(sensors_file)\n",
    "        if 'equipment_id' in sensors_df.columns:\n",
    "            equipment_ids.update(sensors_df['equipment_id'].unique())\n",
    "    except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        print(f\"Note: Could not load equipment IDs from {sensors_file}\")\n",
    "    \n",
    "    # Try to load actuators data\n",
    "    try:\n",
    "        actuators_df = pd.read_csv(actuators_file)\n",
    "        if 'equipment_id' in actuators_df.columns:\n",
    "            equipment_ids.update(actuators_df['equipment_id'].unique())\n",
    "    except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        print(f\"Note: Could not load equipment IDs from {actuators_file}\")\n",
    "    \n",
    "    # Try to load control loops data\n",
    "    try:\n",
    "        control_loops_df = pd.read_csv(control_loops_file)\n",
    "        if 'equipment_id' in control_loops_df.columns:\n",
    "            equipment_ids.update(control_loops_df['equipment_id'].unique())\n",
    "    except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        print(f\"Note: Could not load equipment IDs from {control_loops_file}\")\n",
    "    \n",
    "    return equipment_ids\n",
    "\n",
    "def generate_equipment_data(existing_equipment_ids=None, num_equipment=100, output_file=\"data/equipment.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic data for the Equipment table from ISA-95 Level 2.\n",
    "    \n",
    "    Parameters:\n",
    "    - existing_equipment_ids: Set of equipment IDs from Level 1 to maintain relationships\n",
    "    - num_equipment: Total number of equipment records to generate\n",
    "    - output_file: CSV file to save the data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the generated equipment data\n",
    "    \"\"\"\n",
    "    # Define possible values for categorical fields\n",
    "    equipment_types = [\n",
    "        \"Reactor\", \"Mixer\", \"Pump\", \"Compressor\", \"Heat Exchanger\", \"Distillation Column\",\n",
    "        \"Filter\", \"Dryer\", \"Tank\", \"Furnace\", \"Conveyor\", \"Mill\", \"Centrifuge\", \"Evaporator\",\n",
    "        \"Crystallizer\", \"Extruder\", \"Boiler\", \"Blender\", \"Separator\", \"Packaging Machine\",\n",
    "        \"CNC Machine\", \"Robot\", \"Injection Molder\", \"Press\", \"Welder\", \"Assembly Station\",\n",
    "        \"Filling Machine\", \"Labeling Machine\", \"Testing Station\", \"Sterilizer\"\n",
    "    ]\n",
    "    \n",
    "    # Create subtypes for more specific classification\n",
    "    equipment_subtypes = {\n",
    "        \"Reactor\": [\"Batch Reactor\", \"Continuous Stirred Tank Reactor\", \"Plug Flow Reactor\", \"Fluidized Bed Reactor\"],\n",
    "        \"Mixer\": [\"Ribbon Blender\", \"Paddle Mixer\", \"High Shear Mixer\", \"Tumble Mixer\", \"V-Blender\"],\n",
    "        \"Pump\": [\"Centrifugal Pump\", \"Positive Displacement Pump\", \"Diaphragm Pump\", \"Peristaltic Pump\"],\n",
    "        \"Compressor\": [\"Reciprocating Compressor\", \"Rotary Screw Compressor\", \"Centrifugal Compressor\"],\n",
    "        \"Heat Exchanger\": [\"Shell and Tube\", \"Plate\", \"Spiral\", \"Air Cooled\"],\n",
    "        \"Distillation Column\": [\"Batch Distillation\", \"Continuous Distillation\", \"Vacuum Distillation\"],\n",
    "        \"Filter\": [\"Bag Filter\", \"Cartridge Filter\", \"Plate and Frame Filter\", \"Rotary Drum Filter\"],\n",
    "        \"Dryer\": [\"Spray Dryer\", \"Rotary Dryer\", \"Fluidized Bed Dryer\", \"Vacuum Dryer\"],\n",
    "        \"Tank\": [\"Storage Tank\", \"Mixing Tank\", \"Buffer Tank\", \"Pressure Vessel\"],\n",
    "        \"Furnace\": [\"Electric Furnace\", \"Gas Furnace\", \"Induction Furnace\"],\n",
    "        \"Conveyor\": [\"Belt Conveyor\", \"Roller Conveyor\", \"Screw Conveyor\", \"Pneumatic Conveyor\"],\n",
    "        \"Mill\": [\"Ball Mill\", \"Hammer Mill\", \"Roller Mill\", \"Colloid Mill\"],\n",
    "        \"Centrifuge\": [\"Disc Centrifuge\", \"Basket Centrifuge\", \"Decanter Centrifuge\"],\n",
    "        \"Evaporator\": [\"Falling Film Evaporator\", \"Rising Film Evaporator\", \"Multiple Effect Evaporator\"],\n",
    "        \"Crystallizer\": [\"Batch Crystallizer\", \"Continuous Crystallizer\", \"Cooling Crystallizer\"],\n",
    "        \"Extruder\": [\"Single Screw Extruder\", \"Twin Screw Extruder\", \"Multi-Screw Extruder\"],\n",
    "        \"Boiler\": [\"Fire Tube Boiler\", \"Water Tube Boiler\", \"Electric Boiler\"],\n",
    "        \"Blender\": [\"V-Blender\", \"Double Cone Blender\", \"Ribbon Blender\", \"Paddle Blender\"],\n",
    "        \"Separator\": [\"Cyclone Separator\", \"Magnetic Separator\", \"Electrostatic Separator\"],\n",
    "        \"Packaging Machine\": [\"Form-Fill-Seal Machine\", \"Case Packer\", \"Wrapping Machine\", \"Cartoner\"],\n",
    "        \"CNC Machine\": [\"CNC Mill\", \"CNC Lathe\", \"CNC Router\", \"CNC Plasma Cutter\"],\n",
    "        \"Robot\": [\"Articulated Robot\", \"SCARA Robot\", \"Delta Robot\", \"Collaborative Robot\"],\n",
    "        \"Injection Molder\": [\"Hydraulic Injection Molder\", \"Electric Injection Molder\", \"Hybrid Injection Molder\"],\n",
    "        \"Press\": [\"Hydraulic Press\", \"Mechanical Press\", \"Pneumatic Press\"],\n",
    "        \"Welder\": [\"Arc Welder\", \"MIG Welder\", \"TIG Welder\", \"Spot Welder\"],\n",
    "        \"Assembly Station\": [\"Manual Assembly Station\", \"Semi-Automated Assembly Station\", \"Fully Automated Assembly Station\"],\n",
    "        \"Filling Machine\": [\"Volumetric Filler\", \"Gravity Filler\", \"Piston Filler\", \"Vacuum Filler\"],\n",
    "        \"Labeling Machine\": [\"Pressure Sensitive Labeler\", \"Cut and Stack Labeler\", \"Sleeve Labeler\"],\n",
    "        \"Testing Station\": [\"Visual Inspection Station\", \"Dimensional Testing Station\", \"Functional Testing Station\"],\n",
    "        \"Sterilizer\": [\"Steam Sterilizer\", \"Ethylene Oxide Sterilizer\", \"Radiation Sterilizer\", \"Chemical Sterilizer\"]\n",
    "    }\n",
    "    \n",
    "    manufacturers = [\n",
    "        \"Siemens\", \"ABB\", \"Emerson\", \"Honeywell\", \"Schneider Electric\", \"Yokogawa\", \n",
    "        \"Rockwell Automation\", \"GE\", \"Mitsubishi Electric\", \"Omron\", \"Endress+Hauser\",\n",
    "        \"Festo\", \"SMC\", \"BÃ¼rkert\", \"Danfoss\", \"Alfa Laval\", \"Sulzer\", \"Andritz\", \n",
    "        \"Atlas Copco\", \"SPX Flow\", \"Grundfos\", \"ITT\", \"Flowserve\", \"KSB\", \"Weir\",\n",
    "        \"Metso Outotec\", \"Thermo Fisher Scientific\", \"WIKA\", \"Eaton\", \"Phoenix Contact\"\n",
    "    ]\n",
    "    \n",
    "    statuses = [\"Running\", \"Idle\", \"Maintenance\", \"Fault\", \"Standby\", \"Offline\", \"Startup\", \"Shutdown\"]\n",
    "    \n",
    "    # Generate process area IDs (to be used as foreign keys)\n",
    "    # In a real system, these would come from the ProcessAreas table\n",
    "    process_area_ids = [f\"AREA-{uuid.uuid4().hex[:8].upper()}\" for _ in range(10)]\n",
    "    \n",
    "    # Create a set of existing equipment data (if any)\n",
    "    if existing_equipment_ids is not None and len(existing_equipment_ids) > 0:\n",
    "        existing_equipment = list(existing_equipment_ids)\n",
    "        # Calculate how many new equipment records to generate\n",
    "        num_new_equipment = max(0, num_equipment - len(existing_equipment))\n",
    "        print(f\"Found {len(existing_equipment)} existing equipment IDs from Level 1.\")\n",
    "        print(f\"Generating {num_new_equipment} additional equipment records.\")\n",
    "    else:\n",
    "        existing_equipment = []\n",
    "        num_new_equipment = num_equipment\n",
    "        print(f\"No existing equipment IDs found. Generating {num_new_equipment} new equipment records.\")\n",
    "    \n",
    "    # Generate new equipment IDs if needed\n",
    "    new_equipment_ids = [f\"EQ-{uuid.uuid4().hex[:8].upper()}\" for _ in range(num_new_equipment)]\n",
    "    \n",
    "    # Combine existing and new equipment IDs\n",
    "    all_equipment_ids = existing_equipment + new_equipment_ids\n",
    "    \n",
    "    # Ensure we don't exceed the requested number\n",
    "    all_equipment_ids = all_equipment_ids[:num_equipment]\n",
    "    \n",
    "    # Generate equipment data\n",
    "    data = {\n",
    "        \"equipment_id\": all_equipment_ids,\n",
    "        \"equipment_name\": [],\n",
    "        \"equipment_type\": [],\n",
    "        \"area_id\": [],\n",
    "        \"manufacturer\": [],\n",
    "        \"model_number\": [],\n",
    "        \"serial_number\": [],\n",
    "        \"installation_date\": [],\n",
    "        \"last_maintenance_date\": [],\n",
    "        \"next_maintenance_date\": [],\n",
    "        \"equipment_status\": [],\n",
    "        \"parent_equipment_id\": []\n",
    "    }\n",
    "    \n",
    "    # Create hierarchical structure with some equipment having parent equipment\n",
    "    # First, identify which equipment will be parents (about 20%)\n",
    "    potential_parents = random.sample(all_equipment_ids, int(len(all_equipment_ids) * 0.2))\n",
    "    \n",
    "    # Create a dictionary to track parent-child relationships\n",
    "    equipment_hierarchy = {}\n",
    "    \n",
    "    # Now generate the details for each equipment\n",
    "    for eq_id in all_equipment_ids:\n",
    "        # Select equipment type\n",
    "        eq_type = random.choice(equipment_types)\n",
    "        data[\"equipment_type\"].append(eq_type)\n",
    "        \n",
    "        # Select subtype if available\n",
    "        if eq_type in equipment_subtypes:\n",
    "            subtype = random.choice(equipment_subtypes[eq_type])\n",
    "            # Create a descriptive name\n",
    "            eq_name = f\"{subtype} {random.randint(100, 999)}\"\n",
    "        else:\n",
    "            eq_name = f\"{eq_type} {random.randint(100, 999)}\"\n",
    "        \n",
    "        data[\"equipment_name\"].append(eq_name)\n",
    "        \n",
    "        # Assign to a process area\n",
    "        data[\"area_id\"].append(random.choice(process_area_ids))\n",
    "        \n",
    "        # Select manufacturer\n",
    "        manufacturer = random.choice(manufacturers)\n",
    "        data[\"manufacturer\"].append(manufacturer)\n",
    "        \n",
    "        # Generate model number\n",
    "        model_prefix = manufacturer[:3].upper()\n",
    "        data[\"model_number\"].append(f\"{model_prefix}-{eq_type[:2].upper()}{random.randint(1000, 9999)}\")\n",
    "        \n",
    "        # Generate serial number\n",
    "        data[\"serial_number\"].append(f\"SN{random.randint(100000, 999999)}\")\n",
    "        \n",
    "        # Generate installation date (1-10 years ago)\n",
    "        install_date = datetime.now() - timedelta(days=random.randint(365, 3650))\n",
    "        data[\"installation_date\"].append(install_date.strftime(\"%Y-%m-%d\"))\n",
    "        \n",
    "        # Generate last maintenance date (0-6 months ago)\n",
    "        last_maint_date = datetime.now() - timedelta(days=random.randint(0, 180))\n",
    "        data[\"last_maintenance_date\"].append(last_maint_date.strftime(\"%Y-%m-%d\"))\n",
    "        \n",
    "        # Generate next maintenance date (0-6 months in future)\n",
    "        next_maint_date = datetime.now() + timedelta(days=random.randint(1, 180))\n",
    "        data[\"next_maintenance_date\"].append(next_maint_date.strftime(\"%Y-%m-%d\"))\n",
    "        \n",
    "        # Generate status (weighted towards running and idle)\n",
    "        status_weights = [0.6, 0.2, 0.05, 0.05, 0.05, 0.02, 0.02, 0.01]  # Weights for each status\n",
    "        data[\"equipment_status\"].append(random.choices(statuses, weights=status_weights)[0])\n",
    "        \n",
    "        # Determine parent equipment (if any)\n",
    "        # About 30% of equipment will have a parent\n",
    "        if eq_id not in potential_parents and random.random() < 0.3:\n",
    "            # Ensure we don't create circular references\n",
    "            available_parents = [p for p in potential_parents if p != eq_id and p not in equipment_hierarchy.get(eq_id, [])]\n",
    "            if available_parents:\n",
    "                parent_id = random.choice(available_parents)\n",
    "                data[\"parent_equipment_id\"].append(parent_id)\n",
    "                \n",
    "                # Update hierarchy\n",
    "                if parent_id not in equipment_hierarchy:\n",
    "                    equipment_hierarchy[parent_id] = []\n",
    "                equipment_hierarchy[parent_id].append(eq_id)\n",
    "            else:\n",
    "                data[\"parent_equipment_id\"].append(\"\")\n",
    "        else:\n",
    "            data[\"parent_equipment_id\"].append(\"\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Successfully generated {len(df)} equipment records.\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def display_statistics(df):\n",
    "    \"\"\"\n",
    "    Display basic statistics about the generated equipment data\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing equipment data\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"No data to analyze.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nEquipment Statistics:\")\n",
    "    print(f\"Total equipment: {len(df)}\")\n",
    "    \n",
    "    print(\"\\nEquipment Type Distribution:\")\n",
    "    type_counts = df['equipment_type'].value_counts().head(10)\n",
    "    for eq_type, count in type_counts.items():\n",
    "        print(f\"  {eq_type}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nStatus Distribution:\")\n",
    "    status_counts = df['equipment_status'].value_counts()\n",
    "    for status, count in status_counts.items():\n",
    "        print(f\"  {status}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nProcess Area Distribution:\")\n",
    "    area_counts = df['area_id'].value_counts()\n",
    "    for area_id, count in area_counts.items():\n",
    "        print(f\"  {area_id}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nManufacturer Distribution:\")\n",
    "    mfg_counts = df['manufacturer'].value_counts().head(5)\n",
    "    for mfg, count in mfg_counts.items():\n",
    "        print(f\"  {mfg}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nHierarchy Statistics:\")\n",
    "    parent_count = df['parent_equipment_id'].apply(lambda x: x != \"\").sum()\n",
    "    print(f\"  Equipment with parent: {parent_count} ({parent_count/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Top-level equipment: {len(df) - parent_count} ({(len(df) - parent_count)/len(df)*100:.1f}%)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Load existing equipment IDs from Level 1 data for consistency\n",
    "    existing_equipment_ids = load_level1_data()\n",
    "    \n",
    "    # Generate equipment data\n",
    "    equipment_df = generate_equipment_data(\n",
    "        existing_equipment_ids=existing_equipment_ids, \n",
    "        num_equipment=150,  # Generate 150 equipment records in total\n",
    "        output_file=\"data/equipment.csv\"\n",
    "    )\n",
    "    \n",
    "    # Display sample data and statistics\n",
    "    if equipment_df is not None:\n",
    "        print(\"\\nSample data (first 5 records):\")\n",
    "        print(equipment_df.head())\n",
    "        \n",
    "        # Display statistics\n",
    "        display_statistics(equipment_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42901312",
   "metadata": {},
   "source": [
    "EquipmentStates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bfa302c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating equipment state history...\n",
      "Successfully generated 2821 equipment state records.\n",
      "Data saved to data/equipment_states.csv\n",
      "\n",
      "Sample data (first 5 records):\n",
      "             state_id equipment_id state_name      start_timestamp  \\\n",
      "0  STATE-7F39D01AE889  EQ-9A644928    Running  2025-07-08 19:15:24   \n",
      "1  STATE-DF87A7248323  EQ-9A644928       Idle  2025-07-08 23:53:24   \n",
      "2  STATE-DD6A8152D5C3  EQ-9A644928   Shutdown  2025-07-09 01:08:00   \n",
      "3  STATE-EA999AAD9A46  EQ-9A644928       Idle  2025-07-09 01:18:22   \n",
      "4  STATE-FAEB61CA1A68  EQ-9A644928       Idle  2025-07-09 02:40:14   \n",
      "\n",
      "         end_timestamp  duration_seconds previous_state    transition_reason  \\\n",
      "0  2025-07-08 23:53:24             16680            NaN  Resumed after break   \n",
      "1  2025-07-09 01:08:00              4475        Running         Shift change   \n",
      "2  2025-07-09 01:18:22               622           Idle        Energy saving   \n",
      "3  2025-07-09 02:40:14              4911       Shutdown         Shift change   \n",
      "4  2025-07-09 03:13:12              1977           Idle  Production complete   \n",
      "\n",
      "  operator_id        batch_id work_order_id  \n",
      "0         NaN  BATCH-74833DC9   WO-D7CFCF4D  \n",
      "1   OP-63E0F3             NaN           NaN  \n",
      "2         NaN  BATCH-2AB1FD72   WO-0323DEBB  \n",
      "3   OP-06FDE7  BATCH-7D8AF010           NaN  \n",
      "4         NaN             NaN           NaN  \n",
      "\n",
      "Equipment States Statistics:\n",
      "Total state records: 2821\n",
      "Unique equipment: 150\n",
      "Unique state names: 13\n",
      "State names: ['Agitating', 'Cleaning', 'Emptying', 'Fault', 'Filling', 'Holding', 'Idle', 'Maintenance', 'Running', 'Setup', 'Shutdown', 'Standby', 'Startup']\n",
      "Average state duration: 186.1 minutes\n",
      "States with batch association: 2821 (100.0%)\n",
      "States with work order association: 2821 (100.0%)\n",
      "States with operator association: 2821 (100.0%)\n",
      "Time range (from sample): approximately 2025-07-08 19:15:24 to 2025-07-13 02:18:12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def load_equipment_data(equipment_file=\"data/equipment.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated equipment data\n",
    "    \n",
    "    Parameters:\n",
    "    - equipment_file: CSV file containing equipment data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the equipment data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(equipment_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Equipment data file {equipment_file} not found.\")\n",
    "        print(\"Please run the equipment data generation script first.\")\n",
    "        return None\n",
    "\n",
    "def generate_equipment_states(equipment_df, states_per_equipment=20, \n",
    "                            start_time=None, end_time=None, output_file=\"data/equipment_states.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic equipment state data based on the equipment table\n",
    "    \n",
    "    Parameters:\n",
    "    - equipment_df: DataFrame containing equipment data\n",
    "    - states_per_equipment: Average number of state transitions per equipment\n",
    "    - start_time: Start time for state history (defaults to 7 days ago)\n",
    "    - end_time: End time for state history (defaults to now)\n",
    "    - output_file: CSV file to save the states data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing a sample of the generated states data\n",
    "    \"\"\"\n",
    "    if equipment_df is None or len(equipment_df) == 0:\n",
    "        print(\"Error: No equipment data available.\")\n",
    "        return None\n",
    "    \n",
    "    # Set default time range if not provided\n",
    "    if start_time is None:\n",
    "        start_time = datetime.now() - timedelta(days=7)\n",
    "    if end_time is None:\n",
    "        end_time = datetime.now()\n",
    "    \n",
    "    # Create batch IDs and work order IDs to simulate relationships\n",
    "    batch_ids = [f\"BATCH-{uuid.uuid4().hex[:8].upper()}\" for _ in range(30)]\n",
    "    work_order_ids = [f\"WO-{uuid.uuid4().hex[:8].upper()}\" for _ in range(20)]\n",
    "    \n",
    "    # Create operator IDs\n",
    "    operator_ids = [f\"OP-{uuid.uuid4().hex[:6].upper()}\" for _ in range(15)]\n",
    "    \n",
    "    # Define possible equipment states and transitions\n",
    "    equipment_states = {\n",
    "        # General states for most equipment\n",
    "        \"general\": [\n",
    "            \"Running\", \"Idle\", \"Setup\", \"Cleaning\", \"Maintenance\", \"Fault\", \n",
    "            \"Shutdown\", \"Standby\", \"Startup\", \"Emergency Stop\"\n",
    "        ],\n",
    "        # Specific states for reactors\n",
    "        \"Reactor\": [\n",
    "            \"Running\", \"Idle\", \"Charging\", \"Reaction\", \"Discharging\", \"Cleaning\", \n",
    "            \"Heating\", \"Cooling\", \"Maintenance\", \"Fault\", \"Standby\"\n",
    "        ],\n",
    "        # Specific states for pumps\n",
    "        \"Pump\": [\n",
    "            \"Running\", \"Idle\", \"Startup\", \"Shutdown\", \"Maintenance\", \"Fault\", \n",
    "            \"Standby\", \"Cavitation\", \"Overheating\"\n",
    "        ],\n",
    "        # Specific states for mixers\n",
    "        \"Mixer\": [\n",
    "            \"Running\", \"Idle\", \"Loading\", \"Mixing\", \"Unloading\", \"Cleaning\", \n",
    "            \"Maintenance\", \"Fault\", \"Standby\"\n",
    "        ],\n",
    "        # Specific states for tanks\n",
    "        \"Tank\": [\n",
    "            \"Filling\", \"Holding\", \"Emptying\", \"Idle\", \"Cleaning\", \"Maintenance\", \n",
    "            \"Fault\", \"Agitating\", \"Heating\", \"Cooling\"\n",
    "        ],\n",
    "        # Specific states for packaging machines\n",
    "        \"Packaging Machine\": [\n",
    "            \"Running\", \"Idle\", \"Setup\", \"Loading Material\", \"Fault\", \"Maintenance\", \n",
    "            \"Standby\", \"Adjusting\", \"Cleaning\", \"Warming Up\"\n",
    "        ],\n",
    "        # Specific states for CNC machines\n",
    "        \"CNC Machine\": [\n",
    "            \"Running\", \"Idle\", \"Setup\", \"Tool Change\", \"Program Loading\", \"Maintenance\", \n",
    "            \"Fault\", \"Homing\", \"Material Loading\", \"Finished\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Define state transition probabilities from current state to next state\n",
    "    # Higher probability for common transitions, lower for rare ones\n",
    "    transition_probabilities = {\n",
    "        \"Running\": {\"Running\": 0.7, \"Idle\": 0.1, \"Fault\": 0.05, \"Maintenance\": 0.05, \"Cleaning\": 0.05, \"Shutdown\": 0.05},\n",
    "        \"Idle\": {\"Running\": 0.5, \"Idle\": 0.2, \"Setup\": 0.1, \"Maintenance\": 0.1, \"Shutdown\": 0.1},\n",
    "        \"Setup\": {\"Running\": 0.8, \"Idle\": 0.1, \"Fault\": 0.1},\n",
    "        \"Cleaning\": {\"Idle\": 0.5, \"Running\": 0.3, \"Maintenance\": 0.2},\n",
    "        \"Maintenance\": {\"Idle\": 0.6, \"Running\": 0.3, \"Fault\": 0.1},\n",
    "        \"Fault\": {\"Maintenance\": 0.5, \"Idle\": 0.3, \"Shutdown\": 0.2},\n",
    "        \"Shutdown\": {\"Startup\": 0.5, \"Idle\": 0.5},\n",
    "        \"Standby\": {\"Running\": 0.6, \"Idle\": 0.3, \"Shutdown\": 0.1},\n",
    "        \"Startup\": {\"Running\": 0.8, \"Fault\": 0.1, \"Idle\": 0.1},\n",
    "        \"Emergency Stop\": {\"Maintenance\": 0.6, \"Idle\": 0.3, \"Shutdown\": 0.1},\n",
    "        # Reactor specific\n",
    "        \"Charging\": {\"Reaction\": 0.8, \"Fault\": 0.1, \"Idle\": 0.1},\n",
    "        \"Reaction\": {\"Discharging\": 0.7, \"Fault\": 0.1, \"Cooling\": 0.2},\n",
    "        \"Discharging\": {\"Cleaning\": 0.6, \"Idle\": 0.4},\n",
    "        \"Heating\": {\"Reaction\": 0.7, \"Fault\": 0.1, \"Idle\": 0.2},\n",
    "        \"Cooling\": {\"Discharging\": 0.7, \"Idle\": 0.3},\n",
    "        # Pump specific\n",
    "        \"Cavitation\": {\"Fault\": 0.6, \"Maintenance\": 0.4},\n",
    "        \"Overheating\": {\"Shutdown\": 0.5, \"Maintenance\": 0.5},\n",
    "        # Mixer specific\n",
    "        \"Loading\": {\"Mixing\": 0.9, \"Fault\": 0.1},\n",
    "        \"Mixing\": {\"Unloading\": 0.8, \"Fault\": 0.1, \"Idle\": 0.1},\n",
    "        \"Unloading\": {\"Cleaning\": 0.5, \"Idle\": 0.5},\n",
    "        # Tank specific\n",
    "        \"Filling\": {\"Holding\": 0.8, \"Agitating\": 0.1, \"Fault\": 0.1},\n",
    "        \"Holding\": {\"Emptying\": 0.6, \"Agitating\": 0.2, \"Heating\": 0.1, \"Cooling\": 0.1},\n",
    "        \"Emptying\": {\"Cleaning\": 0.5, \"Idle\": 0.5},\n",
    "        \"Agitating\": {\"Holding\": 0.5, \"Emptying\": 0.3, \"Fault\": 0.2},\n",
    "        \"Heating\": {\"Holding\": 0.8, \"Fault\": 0.2},\n",
    "        # Packaging machine specific\n",
    "        \"Loading Material\": {\"Running\": 0.8, \"Fault\": 0.2},\n",
    "        \"Adjusting\": {\"Running\": 0.9, \"Fault\": 0.1},\n",
    "        \"Warming Up\": {\"Running\": 0.9, \"Fault\": 0.1},\n",
    "        # CNC machine specific\n",
    "        \"Tool Change\": {\"Running\": 0.9, \"Fault\": 0.1},\n",
    "        \"Program Loading\": {\"Running\": 0.8, \"Homing\": 0.2},\n",
    "        \"Homing\": {\"Running\": 0.9, \"Fault\": 0.1},\n",
    "        \"Material Loading\": {\"Running\": 0.9, \"Idle\": 0.1},\n",
    "        \"Finished\": {\"Idle\": 0.8, \"Material Loading\": 0.2}\n",
    "    }\n",
    "    \n",
    "    # Define typical state durations in minutes\n",
    "    state_durations = {\n",
    "        \"Running\": (60, 480),        # 1-8 hours\n",
    "        \"Idle\": (15, 120),           # 15 min - 2 hours\n",
    "        \"Setup\": (20, 90),           # 20-90 min\n",
    "        \"Cleaning\": (30, 120),       # 30 min - 2 hours\n",
    "        \"Maintenance\": (60, 240),    # 1-4 hours\n",
    "        \"Fault\": (15, 240),          # 15 min - 4 hours\n",
    "        \"Shutdown\": (5, 30),         # 5-30 min\n",
    "        \"Standby\": (10, 120),        # 10 min - 2 hours\n",
    "        \"Startup\": (5, 30),          # 5-30 min\n",
    "        \"Emergency Stop\": (5, 60),   # 5-60 min\n",
    "        # Reactor specific\n",
    "        \"Charging\": (15, 90),        # 15-90 min\n",
    "        \"Reaction\": (60, 360),       # 1-6 hours\n",
    "        \"Discharging\": (15, 60),     # 15-60 min\n",
    "        \"Heating\": (15, 120),        # 15 min - 2 hours\n",
    "        \"Cooling\": (30, 180),        # 30 min - 3 hours\n",
    "        # Pump specific\n",
    "        \"Cavitation\": (5, 30),       # 5-30 min\n",
    "        \"Overheating\": (10, 45),     # 10-45 min\n",
    "        # Mixer specific\n",
    "        \"Loading\": (10, 45),         # 10-45 min\n",
    "        \"Mixing\": (30, 240),         # 30 min - 4 hours\n",
    "        \"Unloading\": (10, 45),       # 10-45 min\n",
    "        # Tank specific\n",
    "        \"Filling\": (20, 120),        # 20 min - 2 hours\n",
    "        \"Holding\": (60, 720),        # 1-12 hours\n",
    "        \"Emptying\": (20, 120),       # 20 min - 2 hours\n",
    "        \"Agitating\": (30, 180),      # 30 min - 3 hours\n",
    "        # Packaging machine specific\n",
    "        \"Loading Material\": (5, 30), # 5-30 min\n",
    "        \"Adjusting\": (10, 45),       # 10-45 min\n",
    "        \"Warming Up\": (10, 30),      # 10-30 min\n",
    "        # CNC machine specific\n",
    "        \"Tool Change\": (2, 15),      # 2-15 min\n",
    "        \"Program Loading\": (1, 5),   # 1-5 min\n",
    "        \"Homing\": (1, 5),            # 1-5 min\n",
    "        \"Material Loading\": (5, 20), # 5-20 min\n",
    "        \"Finished\": (1, 10)          # 1-10 min\n",
    "    }\n",
    "    \n",
    "    # Define transition reasons\n",
    "    transition_reasons = {\n",
    "        \"Running\": [\"Production schedule\", \"Normal operation\", \"Process started\", \"Resumed after break\"],\n",
    "        \"Idle\": [\"Production complete\", \"Waiting for materials\", \"Break time\", \"Shift change\", \"No orders\"],\n",
    "        \"Setup\": [\"Product changeover\", \"New batch preparation\", \"Recipe change\", \"Tooling change\"],\n",
    "        \"Cleaning\": [\"Scheduled cleaning\", \"Product changeover\", \"Contamination prevention\", \"End of batch\"],\n",
    "        \"Maintenance\": [\"Scheduled maintenance\", \"Preventative service\", \"Component replacement\", \"Calibration\"],\n",
    "        \"Fault\": [\"Error detected\", \"Component failure\", \"Safety interlock\", \"Process deviation\", \"Power issue\"],\n",
    "        \"Shutdown\": [\"End of shift\", \"Planned downtime\", \"Weekend shutdown\", \"Holiday shutdown\", \"Energy saving\"],\n",
    "        \"Standby\": [\"Waiting for upstream process\", \"Energy saving mode\", \"Temporary pause\", \"Break time\"],\n",
    "        \"Startup\": [\"Beginning of shift\", \"Power restored\", \"After maintenance\", \"Morning startup\"],\n",
    "        \"Emergency Stop\": [\"Safety button pressed\", \"Hazard detected\", \"Operator emergency\", \"Control system trigger\"],\n",
    "        # Additional specific reasons\n",
    "        \"Charging\": [\"Raw material loading\", \"Batch start\", \"Recipe preparation\"],\n",
    "        \"Reaction\": [\"Process running\", \"Chemical reaction\", \"Temperature reached\"],\n",
    "        \"Discharging\": [\"Batch complete\", \"Transfer to storage\", \"Moving to next stage\"],\n",
    "        \"Heating\": [\"Temperature ramp-up\", \"Process requirement\", \"Preparation phase\"],\n",
    "        \"Cooling\": [\"Temperature reduction\", \"Process complete\", \"Preparation for discharge\"],\n",
    "        \"Cavitation\": [\"Insufficient inlet pressure\", \"Air in system\", \"Pump issue\"],\n",
    "        \"Overheating\": [\"Excessive load\", \"Cooling failure\", \"Friction issue\"],\n",
    "        \"Loading\": [\"Material addition\", \"Batch preparation\", \"Recipe start\"],\n",
    "        \"Mixing\": [\"Blending process\", \"Homogenization\", \"Formula requirement\"],\n",
    "        \"Unloading\": [\"Process complete\", \"Transfer operation\", \"Batch finished\"],\n",
    "        \"Filling\": [\"Inventory replenishment\", \"Process start\", \"Batch preparation\"],\n",
    "        \"Holding\": [\"Process requirement\", \"Waiting for test results\", \"Stabilization period\"],\n",
    "        \"Emptying\": [\"Transfer to production\", \"Tank cleaning preparation\", \"Process complete\"],\n",
    "        \"Agitating\": [\"Prevent settling\", \"Improve mixing\", \"Maintain suspension\"],\n",
    "        \"Tool Change\": [\"Different operation\", \"Tool wear\", \"Program requirement\"],\n",
    "        \"Program Loading\": [\"New part\", \"Production change\", \"Updated program\"],\n",
    "        \"Homing\": [\"Reference position\", \"Startup procedure\", \"After emergency stop\"],\n",
    "        \"Material Loading\": [\"New workpiece\", \"Batch start\", \"Production run\"],\n",
    "        \"Finished\": [\"Operation complete\", \"Program end\", \"Batch finished\"]\n",
    "    }\n",
    "    \n",
    "    # Prepare the output file with CSV writer for memory efficiency\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        fieldnames = [\n",
    "            'state_id', 'equipment_id', 'state_name', 'start_timestamp', \n",
    "            'end_timestamp', 'duration_seconds', 'previous_state', \n",
    "            'transition_reason', 'operator_id', 'batch_id', 'work_order_id'\n",
    "        ]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        print(f\"Generating equipment state history...\")\n",
    "        states_count = 0\n",
    "        \n",
    "        # Process each equipment\n",
    "        for _, equipment in equipment_df.iterrows():\n",
    "            equipment_id = equipment['equipment_id']\n",
    "            equipment_type = equipment['equipment_type']\n",
    "            \n",
    "            # Get equipment status from equipment table\n",
    "            current_status = equipment['equipment_status'] if 'equipment_status' in equipment.index else \"Running\"\n",
    "            \n",
    "            # Determine appropriate states for this equipment type\n",
    "            if equipment_type in equipment_states:\n",
    "                possible_states = equipment_states[equipment_type]\n",
    "            else:\n",
    "                possible_states = equipment_states[\"general\"]\n",
    "            \n",
    "            # Vary the number of state transitions per equipment to make it more realistic\n",
    "            # Some equipment changes state frequently, others rarely\n",
    "            equipment_state_count = max(2, int(random.normalvariate(states_per_equipment, states_per_equipment/4)))\n",
    "            \n",
    "            # Initialize with a random state or use current status if it's a valid state\n",
    "            if current_status in possible_states:\n",
    "                current_state = current_status\n",
    "            else:\n",
    "                current_state = random.choice(possible_states)\n",
    "            \n",
    "            # Initialize time to the start time\n",
    "            current_time = start_time\n",
    "            \n",
    "            # Generate state transitions for this equipment\n",
    "            for i in range(equipment_state_count):\n",
    "                # Create a unique state ID\n",
    "                state_id = f\"STATE-{uuid.uuid4().hex[:12].upper()}\"\n",
    "                \n",
    "                # Determine state duration based on typical ranges\n",
    "                if current_state in state_durations:\n",
    "                    min_duration, max_duration = state_durations[current_state]\n",
    "                else:\n",
    "                    min_duration, max_duration = 30, 120  # Default 30 min - 2 hours\n",
    "                \n",
    "                # Add some randomness to duration\n",
    "                duration_minutes = random.uniform(min_duration, max_duration)\n",
    "                \n",
    "                # Convert to seconds\n",
    "                duration_seconds = duration_minutes * 60\n",
    "                \n",
    "                # Calculate end time\n",
    "                state_end_time = current_time + timedelta(seconds=duration_seconds)\n",
    "                \n",
    "                # If we've exceeded the end time, truncate and finish\n",
    "                if state_end_time > end_time:\n",
    "                    state_end_time = end_time\n",
    "                    duration_seconds = (state_end_time - current_time).total_seconds()\n",
    "                \n",
    "                # Determine if this state is associated with a batch\n",
    "                has_batch = random.random() < 0.7  # 70% chance of having a batch\n",
    "                if has_batch:\n",
    "                    batch_id = random.choice(batch_ids)\n",
    "                    # If there's a batch, higher chance of having a work order\n",
    "                    if random.random() < 0.8:  # 80% chance of having a work order if there's a batch\n",
    "                        work_order_id = random.choice(work_order_ids)\n",
    "                    else:\n",
    "                        work_order_id = \"\"\n",
    "                else:\n",
    "                    batch_id = \"\"\n",
    "                    work_order_id = \"\"\n",
    "                \n",
    "                # Determine if an operator was involved\n",
    "                # Higher chance for manual states like Setup, Maintenance\n",
    "                if current_state in [\"Setup\", \"Maintenance\", \"Cleaning\", \"Emergency Stop\"]:\n",
    "                    operator_chance = 0.9  # 90% chance\n",
    "                else:\n",
    "                    operator_chance = 0.3  # 30% chance\n",
    "                \n",
    "                if random.random() < operator_chance:\n",
    "                    operator_id = random.choice(operator_ids)\n",
    "                else:\n",
    "                    operator_id = \"\"\n",
    "                \n",
    "                # Determine transition reason\n",
    "                if current_state in transition_reasons:\n",
    "                    reason = random.choice(transition_reasons[current_state])\n",
    "                else:\n",
    "                    reason = \"Normal operation\"\n",
    "                \n",
    "                # Write the state record to the CSV\n",
    "                writer.writerow({\n",
    "                    'state_id': state_id,\n",
    "                    'equipment_id': equipment_id,\n",
    "                    'state_name': current_state,\n",
    "                    'start_timestamp': current_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                    'end_timestamp': state_end_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                    'duration_seconds': int(duration_seconds),\n",
    "                    'previous_state': \"\" if i == 0 else previous_state,\n",
    "                    'transition_reason': reason,\n",
    "                    'operator_id': operator_id,\n",
    "                    'batch_id': batch_id,\n",
    "                    'work_order_id': work_order_id\n",
    "                })\n",
    "                \n",
    "                states_count += 1\n",
    "                \n",
    "                # Remember the current state for the next record\n",
    "                previous_state = current_state\n",
    "                \n",
    "                # Move to the next time point\n",
    "                current_time = state_end_time\n",
    "                \n",
    "                # If we've reached the end time, stop generating states for this equipment\n",
    "                if current_time >= end_time:\n",
    "                    break\n",
    "                \n",
    "                # Determine the next state based on transition probabilities\n",
    "                if current_state in transition_probabilities:\n",
    "                    next_state_probs = transition_probabilities[current_state]\n",
    "                    \n",
    "                    # Filter to only include states valid for this equipment\n",
    "                    valid_next_states = {s: p for s, p in next_state_probs.items() if s in possible_states}\n",
    "                    \n",
    "                    # If no valid transitions, pick a random valid state\n",
    "                    if not valid_next_states:\n",
    "                        current_state = random.choice(possible_states)\n",
    "                    else:\n",
    "                        # Normalize probabilities\n",
    "                        total_prob = sum(valid_next_states.values())\n",
    "                        normalized_probs = {s: p/total_prob for s, p in valid_next_states.items()}\n",
    "                        \n",
    "                        # Select next state based on probabilities\n",
    "                        next_state = random.choices(\n",
    "                            list(normalized_probs.keys()), \n",
    "                            weights=list(normalized_probs.values()),\n",
    "                            k=1\n",
    "                        )[0]\n",
    "                        \n",
    "                        current_state = next_state\n",
    "                else:\n",
    "                    # If no defined transitions, pick a random state\n",
    "                    current_state = random.choice(possible_states)\n",
    "                \n",
    "                if states_count % 10000 == 0:\n",
    "                    print(f\"Generated {states_count} state records so far...\")\n",
    "    \n",
    "    print(f\"Successfully generated {states_count} equipment state records.\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    # Return a sample of the data (first 1000 rows) for preview\n",
    "    return pd.read_csv(output_file, nrows=1000)\n",
    "\n",
    "def get_sample_statistics(output_file):\n",
    "    \"\"\"\n",
    "    Get basic statistics about the generated equipment states data\n",
    "    \n",
    "    Parameters:\n",
    "    - output_file: CSV file containing the states data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the first chunk to get column information\n",
    "        sample_df = pd.read_csv(output_file, nrows=1000)\n",
    "        \n",
    "        # Sample statistics on chunks to avoid memory issues\n",
    "        num_rows = 0\n",
    "        equipment_ids = set()\n",
    "        state_names = set()\n",
    "        state_durations = []\n",
    "        batch_count = 0\n",
    "        work_order_count = 0\n",
    "        operator_count = 0\n",
    "        \n",
    "        # Process in chunks\n",
    "        for chunk in pd.read_csv(output_file, chunksize=10000):\n",
    "            num_rows += len(chunk)\n",
    "            equipment_ids.update(chunk['equipment_id'].unique())\n",
    "            state_names.update(chunk['state_name'].unique())\n",
    "            \n",
    "            # Sample some durations (not all to save memory)\n",
    "            sample_durations = chunk['duration_seconds'].sample(min(1000, len(chunk))).tolist()\n",
    "            state_durations.extend(sample_durations)\n",
    "            \n",
    "            # Count associations\n",
    "            batch_count += chunk['batch_id'].apply(lambda x: x != \"\").sum()\n",
    "            work_order_count += chunk['work_order_id'].apply(lambda x: x != \"\").sum()\n",
    "            operator_count += chunk['operator_id'].apply(lambda x: x != \"\").sum()\n",
    "        \n",
    "        print(\"\\nEquipment States Statistics:\")\n",
    "        print(f\"Total state records: {num_rows}\")\n",
    "        print(f\"Unique equipment: {len(equipment_ids)}\")\n",
    "        print(f\"Unique state names: {len(state_names)}\")\n",
    "        print(f\"State names: {sorted(state_names)}\")\n",
    "        \n",
    "        if state_durations:\n",
    "            avg_duration_min = sum(state_durations) / len(state_durations) / 60\n",
    "            print(f\"Average state duration: {avg_duration_min:.1f} minutes\")\n",
    "        \n",
    "        # Calculate percentages\n",
    "        if num_rows > 0:\n",
    "            print(f\"States with batch association: {batch_count} ({batch_count/num_rows*100:.1f}%)\")\n",
    "            print(f\"States with work order association: {work_order_count} ({work_order_count/num_rows*100:.1f}%)\")\n",
    "            print(f\"States with operator association: {operator_count} ({operator_count/num_rows*100:.1f}%)\")\n",
    "        \n",
    "        # Get time range if available\n",
    "        if 'start_timestamp' in sample_df.columns and 'end_timestamp' in sample_df.columns:\n",
    "            min_time = pd.to_datetime(sample_df['start_timestamp']).min()\n",
    "            max_time = pd.to_datetime(sample_df['end_timestamp']).max()\n",
    "            print(f\"Time range (from sample): approximately {min_time} to {max_time}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting statistics: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Load the equipment data\n",
    "    equipment_df = load_equipment_data()\n",
    "    \n",
    "    if equipment_df is not None:\n",
    "        # Define the time range (past 7 days)\n",
    "        end_time = datetime.now()\n",
    "        start_time = end_time - timedelta(days=7)\n",
    "        \n",
    "        # Generate equipment states history\n",
    "        sample_df = generate_equipment_states(\n",
    "            equipment_df, \n",
    "            states_per_equipment=20,  # Average 20 state changes per equipment over the time period\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            output_file=\"data/equipment_states.csv\"\n",
    "        )\n",
    "        \n",
    "        # Display a sample of the data\n",
    "        if sample_df is not None:\n",
    "            print(\"\\nSample data (first 5 records):\")\n",
    "            print(sample_df.head())\n",
    "            \n",
    "            # Get statistics\n",
    "            get_sample_statistics(\"data/equipment_states.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f562de0",
   "metadata": {},
   "source": [
    "Alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87a459b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using time range from equipment states: 2025-07-08 19:15:24 to 2025-07-13 02:18:12\n",
      "Generating alarm history...\n",
      "Successfully generated 1561 alarm records.\n",
      "Data saved to data/alarms.csv\n",
      "\n",
      "Sample data (first 5 records):\n",
      "             alarm_id                                         alarm_name  \\\n",
      "0  ALARM-68E9C4871581     Falling Film Evaporator 715 - High Temperature   \n",
      "1  ALARM-98FBCEB7D2DE  Falling Film Evaporator 715 - Communication Error   \n",
      "2  ALARM-173B0A5B271A      Falling Film Evaporator 715 - Low Temperature   \n",
      "3  ALARM-383C19D7D555             Falling Film Evaporator 715 - Low Flow   \n",
      "4  ALARM-5569DAD55960       Falling Film Evaporator 715 - Emergency Stop   \n",
      "\n",
      "  equipment_id           alarm_type  priority activation_timestamp  \\\n",
      "0  EQ-9A644928     High Temperature         3  2025-07-11 10:44:03   \n",
      "1  EQ-9A644928  Communication Error         3  2025-07-11 19:51:49   \n",
      "2  EQ-9A644928      Low Temperature         2  2025-07-10 05:14:12   \n",
      "3  EQ-9A644928             Low Flow         4  2025-07-09 10:58:16   \n",
      "4  EQ-9A644928       Emergency Stop         3  2025-07-12 19:42:47   \n",
      "\n",
      "  acknowledgment_timestamp acknowledgment_operator_id resolution_timestamp  \\\n",
      "0      2025-07-11 12:41:13                  OP-0C27C3  2025-07-11 19:52:14   \n",
      "1      2025-07-11 20:32:35                  OP-297919                  NaN   \n",
      "2      2025-07-10 05:38:42                  OP-348C8D  2025-07-10 09:11:01   \n",
      "3      2025-07-09 13:16:22                  OP-84D457  2025-07-09 20:06:55   \n",
      "4      2025-07-12 19:55:44                  OP-8EA278                  NaN   \n",
      "\n",
      "                                    alarm_message  alarm_value  \\\n",
      "0  Overheating detected - verify cooling function    71.544691   \n",
      "1          Communication with control system lost          NaN   \n",
      "2  Insufficient heating detected - verify heaters    63.716383   \n",
      "3                   Flow rate below minimum limit     0.000000   \n",
      "4                 Emergency stop button activated          NaN   \n",
      "\n",
      "   setpoint_value        batch_id work_order_id  \n",
      "0       50.469464             NaN           NaN  \n",
      "1             NaN  BATCH-11E0C139   WO-AC4336F6  \n",
      "2       70.107761  BATCH-02AD9CB2   WO-E04A6AED  \n",
      "3       10.863520  BATCH-11E0C139   WO-33E25A5E  \n",
      "4             NaN  BATCH-B8EC0F91           NaN  \n",
      "\n",
      "Alarms Statistics:\n",
      "Total alarm records: 1561\n",
      "Unique equipment with alarms: 150\n",
      "Unique alarm types: 65\n",
      "Alarm types: ['Agitator Failure', 'Axis Error', 'Bearing Failure', 'Bearing Temperature High', 'Cavitation', 'Code Reader Failure', 'Collision Risk', 'Communication Error', 'Contamination Risk', 'Control Deviation', 'Conveyor Failure', 'Coolant Low', 'Cooling System Failure', 'Discharge Pressure High', 'Efficiency Low', 'Emergency Stop', 'Empty Tank', 'Exothermic Reaction', 'Feed Rate Deviation', 'Feed Rate Error', 'Film Break', 'Heating System Failure', 'High Flow', 'High Level', 'High Pressure', 'High Temperature', 'High Torque', 'High Vibration', 'Label Misalignment', 'Leak Detected', 'Low Flow', 'Low Level', 'Low Pressure', 'Low Temperature', 'Low Torque', 'Machine Stop', 'Maintenance Due', 'Material Error', 'Material Jam', 'Mixer Imbalance', 'Motor Overload', 'No Flow', 'Out of Material', 'Overflow Risk', 'Package Count Error', 'Positioning Error', 'Power Failure', 'Pressure Relief Valve', 'Print Quality', 'Program Error', 'Reaction Rate Deviation', 'Reactor Integrity', 'Safety Interlock', 'Seal Failure', 'Seal Quality', 'Sensor Fault', 'Shaft Misalignment', 'Speed Deviation', 'Spindle Overload', 'Suction Pressure Low', 'Temperature Deviation', 'Tool Change Error', 'Tool Wear', 'Vibration High', 'pH Deviation']\n",
      "\n",
      "Priority Distribution:\n",
      "  Priority 1: 66 (4.2%)\n",
      "  Priority 2: 230 (14.7%)\n",
      "  Priority 3: 449 (28.8%)\n",
      "  Priority 4: 816 (52.3%)\n",
      "\n",
      "Unacknowledged alarms: 107 (6.9%)\n",
      "Acknowledged but unresolved alarms: 221 (14.2%)\n",
      "Alarms with batch association: 1561 (100.0%)\n",
      "Alarms with work order association: 1561 (100.0%)\n",
      "Time range (from sample): approximately 2025-07-08 19:15:32 to 2025-07-13 02:17:48\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def load_equipment_data(equipment_file=\"data/equipment.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated equipment data\n",
    "    \n",
    "    Parameters:\n",
    "    - equipment_file: CSV file containing equipment data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the equipment data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(equipment_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Equipment data file {equipment_file} not found.\")\n",
    "        print(\"Please run the equipment data generation script first.\")\n",
    "        return None\n",
    "\n",
    "def load_equipment_states(states_file=\"data/equipment_states.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated equipment states data\n",
    "    \n",
    "    Parameters:\n",
    "    - states_file: CSV file containing equipment states data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the equipment states data (sample)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Just load a sample to get the time range and equipment IDs\n",
    "        return pd.read_csv(states_file, nrows=1000)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Note: Equipment states file {states_file} not found.\")\n",
    "        print(\"Alarms will be generated without correlation to equipment states.\")\n",
    "        return None\n",
    "\n",
    "def generate_alarms(equipment_df, equipment_states_df=None, num_alarms_per_equipment=10, \n",
    "                   start_time=None, end_time=None, output_file=\"data/alarms.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic alarm data based on the equipment table\n",
    "    \n",
    "    Parameters:\n",
    "    - equipment_df: DataFrame containing equipment data\n",
    "    - equipment_states_df: DataFrame containing equipment states data (optional)\n",
    "    - num_alarms_per_equipment: Average number of alarms per equipment\n",
    "    - start_time: Start time for alarm history (defaults to 7 days ago)\n",
    "    - end_time: End time for alarm history (defaults to now)\n",
    "    - output_file: CSV file to save the alarms data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing a sample of the generated alarms data\n",
    "    \"\"\"\n",
    "    if equipment_df is None or len(equipment_df) == 0:\n",
    "        print(\"Error: No equipment data available.\")\n",
    "        return None\n",
    "    \n",
    "    # Set default time range if not provided\n",
    "    if start_time is None:\n",
    "        start_time = datetime.now() - timedelta(days=7)\n",
    "    if end_time is None:\n",
    "        end_time = datetime.now()\n",
    "    \n",
    "    # Try to extract time range from equipment states if available\n",
    "    if equipment_states_df is not None and len(equipment_states_df) > 0:\n",
    "        try:\n",
    "            # Convert string timestamps to datetime\n",
    "            equipment_states_df['start_timestamp'] = pd.to_datetime(equipment_states_df['start_timestamp'])\n",
    "            equipment_states_df['end_timestamp'] = pd.to_datetime(equipment_states_df['end_timestamp'])\n",
    "            \n",
    "            # Get time range from equipment states\n",
    "            states_start = equipment_states_df['start_timestamp'].min()\n",
    "            states_end = equipment_states_df['end_timestamp'].max()\n",
    "            \n",
    "            # Use equipment states time range if available\n",
    "            if not pd.isna(states_start) and not pd.isna(states_end):\n",
    "                start_time = states_start\n",
    "                end_time = states_end\n",
    "                print(f\"Using time range from equipment states: {start_time} to {end_time}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not extract time range from equipment states: {e}\")\n",
    "    \n",
    "    # Create batch IDs and work order IDs to simulate relationships\n",
    "    batch_ids = [f\"BATCH-{uuid.uuid4().hex[:8].upper()}\" for _ in range(30)]\n",
    "    work_order_ids = [f\"WO-{uuid.uuid4().hex[:8].upper()}\" for _ in range(20)]\n",
    "    \n",
    "    # Create operator IDs\n",
    "    operator_ids = [f\"OP-{uuid.uuid4().hex[:6].upper()}\" for _ in range(15)]\n",
    "    \n",
    "    # Define alarm types and details based on equipment types\n",
    "    alarm_types = {\n",
    "        # General alarms for most equipment\n",
    "        \"general\": [\n",
    "            \"High Temperature\", \"Low Temperature\", \"High Pressure\", \"Low Pressure\", \n",
    "            \"High Flow\", \"Low Flow\", \"High Level\", \"Low Level\", \"Power Failure\", \n",
    "            \"Communication Error\", \"Sensor Fault\", \"Control Deviation\", \n",
    "            \"Emergency Stop\", \"Safety Interlock\", \"Maintenance Due\"\n",
    "        ],\n",
    "        # Specific alarms for reactors\n",
    "        \"Reactor\": [\n",
    "            \"High Temperature\", \"Low Temperature\", \"High Pressure\", \"Low Pressure\", \n",
    "            \"Agitator Failure\", \"Cooling System Failure\", \"Heating System Failure\", \n",
    "            \"Pressure Relief Valve\", \"Reaction Rate Deviation\", \"pH Deviation\",\n",
    "            \"Reactor Integrity\", \"Exothermic Reaction\", \"Feed Rate Deviation\"\n",
    "        ],\n",
    "        # Specific alarms for pumps\n",
    "        \"Pump\": [\n",
    "            \"Cavitation\", \"High Vibration\", \"Low Flow\", \"No Flow\", \"Seal Failure\", \n",
    "            \"Motor Overload\", \"High Temperature\", \"Discharge Pressure High\", \n",
    "            \"Suction Pressure Low\", \"Efficiency Low\", \"Bearing Temperature High\"\n",
    "        ],\n",
    "        # Specific alarms for mixers\n",
    "        \"Mixer\": [\n",
    "            \"High Torque\", \"Low Torque\", \"High Temperature\", \"Vibration High\", \n",
    "            \"Motor Overload\", \"Shaft Misalignment\", \"Bearing Failure\", \n",
    "            \"Speed Deviation\", \"Mixer Imbalance\", \"Seal Failure\"\n",
    "        ],\n",
    "        # Specific alarms for tanks\n",
    "        \"Tank\": [\n",
    "            \"High Level\", \"Low Level\", \"High Temperature\", \"Low Temperature\", \n",
    "            \"High Pressure\", \"Leak Detected\", \"Agitator Failure\", \"Cooling System Failure\", \n",
    "            \"Heating System Failure\", \"Overflow Risk\", \"Empty Tank\", \"Contamination Risk\"\n",
    "        ],\n",
    "        # Specific alarms for packaging machines\n",
    "        \"Packaging Machine\": [\n",
    "            \"Material Jam\", \"Label Misalignment\", \"Out of Material\", \"Code Reader Failure\", \n",
    "            \"Seal Quality\", \"Film Break\", \"Conveyor Failure\", \"Temperature Deviation\", \n",
    "            \"Print Quality\", \"Package Count Error\", \"Machine Stop\"\n",
    "        ],\n",
    "        # Specific alarms for CNC machines\n",
    "        \"CNC Machine\": [\n",
    "            \"Tool Wear\", \"Axis Error\", \"Program Error\", \"Spindle Overload\", \n",
    "            \"Feed Rate Error\", \"Tool Change Error\", \"Coolant Low\", \"Material Error\", \n",
    "            \"Positioning Error\", \"Collision Risk\", \"Emergency Stop\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Define priority levels and their distribution\n",
    "    priority_levels = {\n",
    "        1: \"Critical\",    # ~5%\n",
    "        2: \"High\",        # ~15%\n",
    "        3: \"Medium\",      # ~30%\n",
    "        4: \"Low\",         # ~50%\n",
    "    }\n",
    "    \n",
    "    priority_weights = [0.05, 0.15, 0.3, 0.5]\n",
    "    \n",
    "    # Define typical alarm durations (time to acknowledgment and resolution)\n",
    "    # Format: (min_ack_minutes, max_ack_minutes, min_resolve_minutes, max_resolve_minutes)\n",
    "    alarm_durations = {\n",
    "        1: (1, 10, 10, 120),     # Critical: Quick ack (1-10min), resolve in 10min-2hrs\n",
    "        2: (5, 30, 20, 240),     # High: Ack in 5-30min, resolve in 20min-4hrs\n",
    "        3: (10, 120, 30, 480),   # Medium: Ack in 10min-2hrs, resolve in 30min-8hrs\n",
    "        4: (30, 240, 60, 720)    # Low: Ack in 30min-4hrs, resolve in 1-12hrs\n",
    "    }\n",
    "    \n",
    "    # Define alarm messages for each alarm type\n",
    "    alarm_messages = {\n",
    "        \"High Temperature\": [\n",
    "            \"Temperature exceeds safe operating limits\", \n",
    "            \"High temperature alarm - check cooling system\",\n",
    "            \"Temperature above setpoint by {value}Â°C\",\n",
    "            \"Overheating detected - verify cooling function\"\n",
    "        ],\n",
    "        \"Low Temperature\": [\n",
    "            \"Temperature below minimum operating limits\",\n",
    "            \"Low temperature alarm - check heating system\",\n",
    "            \"Temperature below setpoint by {value}Â°C\",\n",
    "            \"Insufficient heating detected - verify heaters\"\n",
    "        ],\n",
    "        \"High Pressure\": [\n",
    "            \"Pressure exceeds maximum safe limit\",\n",
    "            \"High pressure alarm - check relief valve\",\n",
    "            \"Pressure above setpoint by {value} bar\",\n",
    "            \"Excessive pressure detected - risk of damage\"\n",
    "        ],\n",
    "        \"Low Pressure\": [\n",
    "            \"Pressure below minimum operating limit\",\n",
    "            \"Low pressure alarm - check supply pressure\",\n",
    "            \"Pressure below setpoint by {value} bar\",\n",
    "            \"Insufficient pressure for operation\"\n",
    "        ],\n",
    "        \"High Flow\": [\n",
    "            \"Flow rate exceeds maximum limit\",\n",
    "            \"High flow alarm - check control valve\",\n",
    "            \"Flow above setpoint by {value} mÂ³/h\",\n",
    "            \"Excessive flow detected - verify valve position\"\n",
    "        ],\n",
    "        \"Low Flow\": [\n",
    "            \"Flow rate below minimum limit\",\n",
    "            \"Low flow alarm - check for blockage\",\n",
    "            \"Flow below setpoint by {value} mÂ³/h\",\n",
    "            \"Insufficient flow detected - verify pump operation\"\n",
    "        ],\n",
    "        \"High Level\": [\n",
    "            \"Level exceeds maximum safe limit\",\n",
    "            \"High level alarm - risk of overflow\",\n",
    "            \"Level above setpoint by {value}%\",\n",
    "            \"Excessive level detected - check outlet valve\"\n",
    "        ],\n",
    "        \"Low Level\": [\n",
    "            \"Level below minimum operating limit\",\n",
    "            \"Low level alarm - check supply\",\n",
    "            \"Level below setpoint by {value}%\",\n",
    "            \"Insufficient level detected - verify inlet flow\"\n",
    "        ],\n",
    "        \"Power Failure\": [\n",
    "            \"Power supply interruption detected\",\n",
    "            \"Power failure alarm - switching to backup\",\n",
    "            \"Main power loss - check electrical supply\",\n",
    "            \"Power quality issue detected\"\n",
    "        ],\n",
    "        \"Communication Error\": [\n",
    "            \"Communication with control system lost\",\n",
    "            \"Network communication failure\",\n",
    "            \"Data transmission error - check connections\",\n",
    "            \"Communication timeout - device not responding\"\n",
    "        ],\n",
    "        \"Sensor Fault\": [\n",
    "            \"Sensor reading outside valid range\",\n",
    "            \"Sensor calibration error detected\",\n",
    "            \"Sensor failure - maintenance required\",\n",
    "            \"Invalid sensor data - check wiring\"\n",
    "        ],\n",
    "        \"Control Deviation\": [\n",
    "            \"Process variable deviating from setpoint\",\n",
    "            \"Control loop unable to maintain setpoint\",\n",
    "            \"PID control deviation exceeds {value}%\",\n",
    "            \"Sustained control error detected\"\n",
    "        ],\n",
    "        \"Emergency Stop\": [\n",
    "            \"Emergency stop button activated\",\n",
    "            \"Emergency shutdown initiated\",\n",
    "            \"E-stop circuit triggered - check safety devices\",\n",
    "            \"Safety system activated emergency stop\"\n",
    "        ],\n",
    "        \"Safety Interlock\": [\n",
    "            \"Safety interlock triggered - access violation\",\n",
    "            \"Guard door opened during operation\",\n",
    "            \"Safety circuit interrupted - check interlocks\",\n",
    "            \"Safety barrier breach detected\"\n",
    "        ],\n",
    "        \"Maintenance Due\": [\n",
    "            \"Scheduled maintenance overdue\",\n",
    "            \"Service interval exceeded by {value} hours\",\n",
    "            \"Maintenance required - performance degraded\",\n",
    "            \"Preventative maintenance reminder\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Define default messages for alarm types not specifically listed\n",
    "    default_alarm_messages = [\n",
    "        \"{alarm_type} detected - check equipment\",\n",
    "        \"{alarm_type} alarm activated\",\n",
    "        \"{alarm_type} condition requires attention\",\n",
    "        \"Alert: {alarm_type} on {equipment_name}\"\n",
    "    ]\n",
    "    \n",
    "    # Prepare the output file with CSV writer for memory efficiency\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        fieldnames = [\n",
    "            'alarm_id', 'alarm_name', 'equipment_id', 'alarm_type', 'priority',\n",
    "            'activation_timestamp', 'acknowledgment_timestamp', 'acknowledgment_operator_id',\n",
    "            'resolution_timestamp', 'alarm_message', 'alarm_value', 'setpoint_value',\n",
    "            'batch_id', 'work_order_id'\n",
    "        ]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        print(f\"Generating alarm history...\")\n",
    "        alarms_count = 0\n",
    "        \n",
    "        # Process each equipment\n",
    "        for _, equipment in equipment_df.iterrows():\n",
    "            equipment_id = equipment['equipment_id']\n",
    "            equipment_type = equipment['equipment_type']\n",
    "            equipment_name = equipment['equipment_name'] if 'equipment_name' in equipment.index else f\"Equipment {equipment_id}\"\n",
    "            \n",
    "            # Determine appropriate alarm types for this equipment type\n",
    "            if equipment_type in alarm_types:\n",
    "                possible_alarms = alarm_types[equipment_type]\n",
    "            else:\n",
    "                possible_alarms = alarm_types[\"general\"]\n",
    "            \n",
    "            # Vary the number of alarms per equipment to make it more realistic\n",
    "            # Some equipment has more alarms than others\n",
    "            # Use a Poisson distribution around the average\n",
    "            equipment_alarm_count = max(0, int(np.random.poisson(num_alarms_per_equipment)))\n",
    "            \n",
    "            # Generate alarms for this equipment\n",
    "            for i in range(equipment_alarm_count):\n",
    "                # Create a unique alarm ID\n",
    "                alarm_id = f\"ALARM-{uuid.uuid4().hex[:12].upper()}\"\n",
    "                \n",
    "                # Select alarm type\n",
    "                alarm_type = random.choice(possible_alarms)\n",
    "                \n",
    "                # Create alarm name\n",
    "                alarm_name = f\"{equipment_name} - {alarm_type}\"\n",
    "                \n",
    "                # Determine priority (weighted random)\n",
    "                priority = random.choices(list(priority_levels.keys()), weights=priority_weights)[0]\n",
    "                \n",
    "                # Generate activation timestamp\n",
    "                activation_time = start_time + (end_time - start_time) * random.random()\n",
    "                \n",
    "                # Determine acknowledgment and resolution times\n",
    "                min_ack, max_ack, min_resolve, max_resolve = alarm_durations[priority]\n",
    "                \n",
    "                ack_delay_minutes = random.uniform(min_ack, max_ack)\n",
    "                resolve_delay_minutes = random.uniform(min_resolve, max_resolve)\n",
    "                \n",
    "                # Some alarms may not be acknowledged or resolved yet\n",
    "                if random.random() < 0.05:  # 5% of alarms not acknowledged\n",
    "                    acknowledgment_time = None\n",
    "                    resolution_time = None\n",
    "                    acknowledgment_operator_id = \"\"\n",
    "                else:\n",
    "                    acknowledgment_time = activation_time + timedelta(minutes=ack_delay_minutes)\n",
    "                    \n",
    "                    # Check if acknowledgment time is beyond end time\n",
    "                    if acknowledgment_time > end_time:\n",
    "                        acknowledgment_time = None\n",
    "                        resolution_time = None\n",
    "                        acknowledgment_operator_id = \"\"\n",
    "                    else:\n",
    "                        # Assign operator who acknowledged\n",
    "                        acknowledgment_operator_id = random.choice(operator_ids)\n",
    "                        \n",
    "                        # Determine resolution time\n",
    "                        if random.random() < 0.1:  # 10% of acknowledged alarms not resolved\n",
    "                            resolution_time = None\n",
    "                        else:\n",
    "                            resolution_time = acknowledgment_time + timedelta(minutes=resolve_delay_minutes)\n",
    "                            \n",
    "                            # Check if resolution time is beyond end time\n",
    "                            if resolution_time > end_time:\n",
    "                                resolution_time = None\n",
    "                \n",
    "                # Generate alarm values\n",
    "                if alarm_type in [\"High Temperature\", \"Low Temperature\"]:\n",
    "                    setpoint = random.uniform(50, 150)\n",
    "                    deviation = random.uniform(5, 30) * (1 if \"High\" in alarm_type else -1)\n",
    "                    alarm_value = setpoint + deviation\n",
    "                elif alarm_type in [\"High Pressure\", \"Low Pressure\"]:\n",
    "                    setpoint = random.uniform(2, 10)\n",
    "                    deviation = random.uniform(0.5, 3) * (1 if \"High\" in alarm_type else -1)\n",
    "                    alarm_value = setpoint + deviation\n",
    "                elif alarm_type in [\"High Flow\", \"Low Flow\"]:\n",
    "                    setpoint = random.uniform(10, 100)\n",
    "                    deviation = random.uniform(5, 30) * (1 if \"High\" in alarm_type else -1)\n",
    "                    alarm_value = max(0, setpoint + deviation)\n",
    "                elif alarm_type in [\"High Level\", \"Low Level\"]:\n",
    "                    setpoint = random.uniform(40, 80)\n",
    "                    deviation = random.uniform(10, 40) * (1 if \"High\" in alarm_type else -1)\n",
    "                    alarm_value = max(0, min(100, setpoint + deviation))\n",
    "                elif alarm_type == \"Control Deviation\":\n",
    "                    setpoint = random.uniform(50, 150)\n",
    "                    deviation = random.uniform(10, 50)\n",
    "                    alarm_value = setpoint + deviation\n",
    "                else:\n",
    "                    # For other alarm types, no specific value\n",
    "                    alarm_value = \"\"\n",
    "                    setpoint = \"\"\n",
    "                \n",
    "                # Generate alarm message\n",
    "                if alarm_type in alarm_messages:\n",
    "                    message_template = random.choice(alarm_messages[alarm_type])\n",
    "                    # Replace {value} with the deviation if present\n",
    "                    if \"{value}\" in message_template and alarm_value != \"\" and setpoint != \"\":\n",
    "                        try:\n",
    "                            deviation_val = abs(float(alarm_value) - float(setpoint))\n",
    "                            message = message_template.replace(\"{value}\", f\"{deviation_val:.1f}\")\n",
    "                        except (ValueError, TypeError):\n",
    "                            message = message_template.replace(\"{value}\", \"significant\")\n",
    "                    else:\n",
    "                        message = message_template\n",
    "                else:\n",
    "                    message_template = random.choice(default_alarm_messages)\n",
    "                    message = message_template.replace(\"{alarm_type}\", alarm_type).replace(\"{equipment_name}\", equipment_name)\n",
    "                \n",
    "                # Determine if this alarm is associated with a batch\n",
    "                has_batch = random.random() < 0.7  # 70% chance of having a batch\n",
    "                if has_batch:\n",
    "                    batch_id = random.choice(batch_ids)\n",
    "                    # If there's a batch, higher chance of having a work order\n",
    "                    if random.random() < 0.8:  # 80% chance of having a work order if there's a batch\n",
    "                        work_order_id = random.choice(work_order_ids)\n",
    "                    else:\n",
    "                        work_order_id = \"\"\n",
    "                else:\n",
    "                    batch_id = \"\"\n",
    "                    work_order_id = \"\"\n",
    "                \n",
    "                # Format timestamps as strings (None remains None)\n",
    "                activation_timestamp = activation_time.strftime(\"%Y-%m-%d %H:%M:%S\") if activation_time else None\n",
    "                acknowledgment_timestamp = acknowledgment_time.strftime(\"%Y-%m-%d %H:%M:%S\") if acknowledgment_time else None\n",
    "                resolution_timestamp = resolution_time.strftime(\"%Y-%m-%d %H:%M:%S\") if resolution_time else None\n",
    "                \n",
    "                # Write the alarm record to the CSV\n",
    "                writer.writerow({\n",
    "                    'alarm_id': alarm_id,\n",
    "                    'alarm_name': alarm_name,\n",
    "                    'equipment_id': equipment_id,\n",
    "                    'alarm_type': alarm_type,\n",
    "                    'priority': priority,\n",
    "                    'activation_timestamp': activation_timestamp,\n",
    "                    'acknowledgment_timestamp': acknowledgment_timestamp,\n",
    "                    'acknowledgment_operator_id': acknowledgment_operator_id,\n",
    "                    'resolution_timestamp': resolution_timestamp,\n",
    "                    'alarm_message': message,\n",
    "                    'alarm_value': alarm_value,\n",
    "                    'setpoint_value': setpoint,\n",
    "                    'batch_id': batch_id,\n",
    "                    'work_order_id': work_order_id\n",
    "                })\n",
    "                \n",
    "                alarms_count += 1\n",
    "                if alarms_count % 10000 == 0:\n",
    "                    print(f\"Generated {alarms_count} alarm records so far...\")\n",
    "    \n",
    "    print(f\"Successfully generated {alarms_count} alarm records.\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    # Return a sample of the data (first 1000 rows) for preview\n",
    "    return pd.read_csv(output_file, nrows=1000)\n",
    "\n",
    "def get_sample_statistics(output_file):\n",
    "    \"\"\"\n",
    "    Get basic statistics about the generated alarms data\n",
    "    \n",
    "    Parameters:\n",
    "    - output_file: CSV file containing the alarms data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the first chunk to get column information\n",
    "        sample_df = pd.read_csv(output_file, nrows=1000)\n",
    "        \n",
    "        # Sample statistics on chunks to avoid memory issues\n",
    "        num_rows = 0\n",
    "        equipment_ids = set()\n",
    "        alarm_types = set()\n",
    "        priority_counts = {1: 0, 2: 0, 3: 0, 4: 0}\n",
    "        unacknowledged_count = 0\n",
    "        unresolved_count = 0\n",
    "        batch_count = 0\n",
    "        work_order_count = 0\n",
    "        \n",
    "        # Process in chunks\n",
    "        for chunk in pd.read_csv(output_file, chunksize=10000):\n",
    "            num_rows += len(chunk)\n",
    "            equipment_ids.update(chunk['equipment_id'].unique())\n",
    "            alarm_types.update(chunk['alarm_type'].unique())\n",
    "            \n",
    "            # Count priorities\n",
    "            for priority in range(1, 5):\n",
    "                priority_counts[priority] += len(chunk[chunk['priority'] == priority])\n",
    "            \n",
    "            # Count unacknowledged and unresolved alarms\n",
    "            unacknowledged_count += chunk['acknowledgment_timestamp'].isna().sum()\n",
    "            unresolved_count += chunk['resolution_timestamp'].isna().sum() - chunk['acknowledgment_timestamp'].isna().sum()\n",
    "            \n",
    "            # Count associations\n",
    "            batch_count += chunk['batch_id'].apply(lambda x: x != \"\").sum()\n",
    "            work_order_count += chunk['work_order_id'].apply(lambda x: x != \"\").sum()\n",
    "        \n",
    "        print(\"\\nAlarms Statistics:\")\n",
    "        print(f\"Total alarm records: {num_rows}\")\n",
    "        print(f\"Unique equipment with alarms: {len(equipment_ids)}\")\n",
    "        print(f\"Unique alarm types: {len(alarm_types)}\")\n",
    "        print(f\"Alarm types: {sorted(alarm_types)}\")\n",
    "        \n",
    "        print(\"\\nPriority Distribution:\")\n",
    "        for priority, count in priority_counts.items():\n",
    "            print(f\"  Priority {priority}: {count} ({count/num_rows*100:.1f}%)\")\n",
    "        \n",
    "        # Calculate percentages\n",
    "        if num_rows > 0:\n",
    "            print(f\"\\nUnacknowledged alarms: {unacknowledged_count} ({unacknowledged_count/num_rows*100:.1f}%)\")\n",
    "            print(f\"Acknowledged but unresolved alarms: {unresolved_count} ({unresolved_count/num_rows*100:.1f}%)\")\n",
    "            print(f\"Alarms with batch association: {batch_count} ({batch_count/num_rows*100:.1f}%)\")\n",
    "            print(f\"Alarms with work order association: {work_order_count} ({work_order_count/num_rows*100:.1f}%)\")\n",
    "        \n",
    "        # Get time range if available\n",
    "        if 'activation_timestamp' in sample_df.columns:\n",
    "            try:\n",
    "                min_time = pd.to_datetime(sample_df['activation_timestamp']).min()\n",
    "                max_time = pd.to_datetime(sample_df['activation_timestamp']).max()\n",
    "                print(f\"Time range (from sample): approximately {min_time} to {max_time}\")\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting statistics: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Load the equipment data\n",
    "    equipment_df = load_equipment_data()\n",
    "    \n",
    "    # Try to load equipment states data for time range correlation\n",
    "    equipment_states_df = load_equipment_states()\n",
    "    \n",
    "    if equipment_df is not None:\n",
    "        # Define the time range (past 7 days if not using equipment states time range)\n",
    "        end_time = datetime.now()\n",
    "        start_time = end_time - timedelta(days=7)\n",
    "        \n",
    "        # Generate alarms data\n",
    "        sample_df = generate_alarms(\n",
    "            equipment_df,\n",
    "            equipment_states_df,\n",
    "            num_alarms_per_equipment=10,  # Average 10 alarms per equipment over the time period\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            output_file=\"data/alarms.csv\"\n",
    "        )\n",
    "        \n",
    "        # Display a sample of the data\n",
    "        if sample_df is not None:\n",
    "            print(\"\\nSample data (first 5 records):\")\n",
    "            print(sample_df.head())\n",
    "            \n",
    "            # Get statistics\n",
    "            get_sample_statistics(\"data/alarms.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33911bd",
   "metadata": {},
   "source": [
    "ProcessParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ae3e2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Recipes data file data/recipes.csv not found.\n",
      "Process parameters will be generated without recipe context.\n",
      "Note: Batches data file data/batches.csv not found.\n",
      "Process parameters will be generated without batch context.\n",
      "Creating synthetic batch IDs for process parameters...\n",
      "Creating synthetic recipe IDs for process parameters...\n",
      "Generating process parameters data...\n",
      "Generated 50000 parameter records so far...\n",
      "Successfully generated 68900 process parameter records.\n",
      "Data saved to data/process_parameters.csv\n",
      "\n",
      "Sample data (first 5 records):\n",
      "       parameter_id parameter_name equipment_id            timestamp  \\\n",
      "0  PARAM-D33552D2-1          Speed  EQ-9A644928  2025-07-08 19:15:25   \n",
      "1  PARAM-D33552D2-2          Speed  EQ-9A644928  2025-07-08 20:57:14   \n",
      "2  PARAM-D33552D2-3          Speed  EQ-9A644928  2025-07-08 22:39:03   \n",
      "3  PARAM-D33552D2-4          Speed  EQ-9A644928  2025-07-09 00:20:52   \n",
      "4  PARAM-D33552D2-5          Speed  EQ-9A644928  2025-07-09 02:02:41   \n",
      "\n",
      "   setpoint_value  actual_value  deviation unit  upper_control_limit  \\\n",
      "0     1333.322625        1293.0      -40.0  rpm               1722.0   \n",
      "1     1333.322625        1298.0      -35.0  rpm               1722.0   \n",
      "2     1333.322625        1304.0      -29.0  rpm               1722.0   \n",
      "3     1333.322625        1396.0       63.0  rpm               1722.0   \n",
      "4     1333.322625        1402.0       69.0  rpm               1722.0   \n",
      "\n",
      "   lower_control_limit  upper_spec_limit  lower_spec_limit control_mode  \\\n",
      "0                945.0            1675.0             992.0         Auto   \n",
      "1                945.0            1675.0             992.0         Auto   \n",
      "2                945.0            1675.0             992.0         Auto   \n",
      "3                945.0            1675.0             992.0         Auto   \n",
      "4                945.0            1675.0             992.0         Auto   \n",
      "\n",
      "  recipe_id        batch_id  \n",
      "0       NaN  BATCH-30D55226  \n",
      "1       NaN  BATCH-30D55226  \n",
      "2       NaN  BATCH-30D55226  \n",
      "3       NaN  BATCH-30D55226  \n",
      "4       NaN  BATCH-30D55226  \n",
      "\n",
      "Process Parameters Statistics:\n",
      "Total parameter records: 68900\n",
      "Unique equipment with parameters: 150\n",
      "Unique parameter names: 47\n",
      "Parameter names: ['Agitator Speed', 'Air Flow', 'Bearing Temperature', 'Catalyst Level', 'Cold Side Flow', 'Cold Side Outlet Temp', 'Concentration', 'Conversion', 'Current', 'Density', 'Differential Pressure', 'Discharge Pressure', 'Efficiency', 'Energy Consumption', 'Feed Rate', 'Flow Rate', 'Fouling Factor', 'Heat Transfer Rate', 'Hot Side Flow', 'Hot Side Inlet Temp', 'Hot Side Outlet Temp', 'Humidity', 'Inlet Flow', 'Jacket Temperature', 'Level', 'Moisture Content', 'Motor Current', 'NPSH Available', 'Outlet Flow', 'Outlet Temperature', 'Power', 'Pressure', 'Pressure Drop', 'Pressure Drop Cold', 'Pressure Drop Hot', 'Product Temperature', 'Pump Speed', 'Reactant Flow', 'Reaction Time', 'Residence Time', 'Speed', 'Suction Pressure', 'Temperature', 'Vibration', 'Voltage', 'Volume', 'pH']\n",
      "Control modes: ['Auto', 'Cascade', 'Manual', 'Off', 'Supervised']\n",
      "\n",
      "Parameters with recipe association: 68900 (100.0%)\n",
      "Parameters with batch association: 68900 (100.0%)\n",
      "\n",
      "Deviation Statistics (from sample):\n",
      "  Average deviation: 0.5518\n",
      "  Average absolute deviation: 9.6763\n",
      "  Maximum absolute deviation: 842.0000\n",
      "\n",
      "Time range (from sample): approximately 2025-07-08 19:15:25 to 2025-07-15 19:15:25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def load_equipment_data(equipment_file=\"data/equipment.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated equipment data\n",
    "    \n",
    "    Parameters:\n",
    "    - equipment_file: CSV file containing equipment data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the equipment data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(equipment_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Equipment data file {equipment_file} not found.\")\n",
    "        print(\"Please run the equipment data generation script first.\")\n",
    "        return None\n",
    "\n",
    "def load_recipes_data(recipes_file=\"data/recipes.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated recipes data if available\n",
    "    \n",
    "    Parameters:\n",
    "    - recipes_file: CSV file containing recipes data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the recipes data or None if not available\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(recipes_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Note: Recipes data file {recipes_file} not found.\")\n",
    "        print(\"Process parameters will be generated without recipe context.\")\n",
    "        return None\n",
    "\n",
    "def load_batches_data(batches_file=\"data/batches.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated batches data if available\n",
    "    \n",
    "    Parameters:\n",
    "    - batches_file: CSV file containing batches data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the batches data or None if not available\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(batches_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Note: Batches data file {batches_file} not found.\")\n",
    "        print(\"Process parameters will be generated without batch context.\")\n",
    "        return None\n",
    "\n",
    "def generate_process_parameters(equipment_df, recipes_df=None, batches_df=None, \n",
    "                               num_parameters_per_equipment=5, samples_per_parameter=100,\n",
    "                               start_time=None, end_time=None, output_file=\"data/process_parameters.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic process parameters data based on the equipment table\n",
    "    \n",
    "    Parameters:\n",
    "    - equipment_df: DataFrame containing equipment data\n",
    "    - recipes_df: DataFrame containing recipes data (optional)\n",
    "    - batches_df: DataFrame containing batches data (optional)\n",
    "    - num_parameters_per_equipment: Average number of parameters per equipment\n",
    "    - samples_per_parameter: Number of time-series samples per parameter\n",
    "    - start_time: Start time for parameter history (defaults to 7 days ago)\n",
    "    - end_time: End time for parameter history (defaults to now)\n",
    "    - output_file: CSV file to save the process parameters data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing a sample of the generated process parameters data\n",
    "    \"\"\"\n",
    "    if equipment_df is None or len(equipment_df) == 0:\n",
    "        print(\"Error: No equipment data available.\")\n",
    "        return None\n",
    "    \n",
    "    # Set default time range if not provided\n",
    "    if start_time is None:\n",
    "        start_time = datetime.now() - timedelta(days=7)\n",
    "    if end_time is None:\n",
    "        end_time = datetime.now()\n",
    "    \n",
    "    # Define parameter types and details based on equipment types\n",
    "    parameter_types = {\n",
    "        # General parameters for most equipment\n",
    "        \"general\": [\n",
    "            {\"name\": \"Temperature\", \"unit\": \"Â°C\", \"range\": (20, 150), \"precision\": 1},\n",
    "            {\"name\": \"Pressure\", \"unit\": \"bar\", \"range\": (1, 15), \"precision\": 2},\n",
    "            {\"name\": \"Flow Rate\", \"unit\": \"mÂ³/h\", \"range\": (0, 100), \"precision\": 1},\n",
    "            {\"name\": \"Level\", \"unit\": \"%\", \"range\": (0, 100), \"precision\": 1},\n",
    "            {\"name\": \"Speed\", \"unit\": \"rpm\", \"range\": (0, 3000), \"precision\": 0},\n",
    "            {\"name\": \"Power\", \"unit\": \"kW\", \"range\": (0, 500), \"precision\": 1},\n",
    "            {\"name\": \"Vibration\", \"unit\": \"mm/s\", \"range\": (0, 15), \"precision\": 2},\n",
    "            {\"name\": \"Current\", \"unit\": \"A\", \"range\": (0, 100), \"precision\": 1},\n",
    "            {\"name\": \"Voltage\", \"unit\": \"V\", \"range\": (0, 480), \"precision\": 0},\n",
    "            {\"name\": \"Efficiency\", \"unit\": \"%\", \"range\": (50, 100), \"precision\": 1}\n",
    "        ],\n",
    "        # Specific parameters for reactors\n",
    "        \"Reactor\": [\n",
    "            {\"name\": \"Reactor Temperature\", \"unit\": \"Â°C\", \"range\": (50, 250), \"precision\": 1},\n",
    "            {\"name\": \"Reactor Pressure\", \"unit\": \"bar\", \"range\": (1, 25), \"precision\": 2},\n",
    "            {\"name\": \"Agitator Speed\", \"unit\": \"rpm\", \"range\": (0, 500), \"precision\": 0},\n",
    "            {\"name\": \"Jacket Temperature\", \"unit\": \"Â°C\", \"range\": (10, 200), \"precision\": 1},\n",
    "            {\"name\": \"Reaction Time\", \"unit\": \"min\", \"range\": (0, 500), \"precision\": 0},\n",
    "            {\"name\": \"pH\", \"unit\": \"pH\", \"range\": (2, 12), \"precision\": 2},\n",
    "            {\"name\": \"Concentration\", \"unit\": \"g/L\", \"range\": (0, 1000), \"precision\": 1},\n",
    "            {\"name\": \"Reactant Flow\", \"unit\": \"L/min\", \"range\": (0, 100), \"precision\": 1},\n",
    "            {\"name\": \"Conversion\", \"unit\": \"%\", \"range\": (0, 100), \"precision\": 1},\n",
    "            {\"name\": \"Catalyst Level\", \"unit\": \"%\", \"range\": (0, 100), \"precision\": 1}\n",
    "        ],\n",
    "        # Specific parameters for pumps\n",
    "        \"Pump\": [\n",
    "            {\"name\": \"Discharge Pressure\", \"unit\": \"bar\", \"range\": (1, 25), \"precision\": 2},\n",
    "            {\"name\": \"Suction Pressure\", \"unit\": \"bar\", \"range\": (0, 5), \"precision\": 2},\n",
    "            {\"name\": \"Flow Rate\", \"unit\": \"mÂ³/h\", \"range\": (0, 500), \"precision\": 1},\n",
    "            {\"name\": \"Pump Speed\", \"unit\": \"rpm\", \"range\": (0, 3600), \"precision\": 0},\n",
    "            {\"name\": \"Motor Current\", \"unit\": \"A\", \"range\": (0, 150), \"precision\": 1},\n",
    "            {\"name\": \"Differential Pressure\", \"unit\": \"bar\", \"range\": (0, 20), \"precision\": 2},\n",
    "            {\"name\": \"Efficiency\", \"unit\": \"%\", \"range\": (40, 95), \"precision\": 1},\n",
    "            {\"name\": \"Vibration\", \"unit\": \"mm/s\", \"range\": (0, 20), \"precision\": 2},\n",
    "            {\"name\": \"Bearing Temperature\", \"unit\": \"Â°C\", \"range\": (20, 120), \"precision\": 1},\n",
    "            {\"name\": \"NPSH Available\", \"unit\": \"m\", \"range\": (0, 15), \"precision\": 2}\n",
    "        ],\n",
    "        # Specific parameters for heat exchangers\n",
    "        \"Heat Exchanger\": [\n",
    "            {\"name\": \"Hot Side Inlet Temp\", \"unit\": \"Â°C\", \"range\": (50, 250), \"precision\": 1},\n",
    "            {\"name\": \"Hot Side Outlet Temp\", \"unit\": \"Â°C\", \"range\": (30, 200), \"precision\": 1},\n",
    "            {\"name\": \"Cold Side Inlet Temp\", \"unit\": \"Â°C\", \"range\": (5, 30), \"precision\": 1},\n",
    "            {\"name\": \"Cold Side Outlet Temp\", \"unit\": \"Â°C\", \"range\": (15, 100), \"precision\": 1},\n",
    "            {\"name\": \"Hot Side Flow\", \"unit\": \"mÂ³/h\", \"range\": (1, 200), \"precision\": 1},\n",
    "            {\"name\": \"Cold Side Flow\", \"unit\": \"mÂ³/h\", \"range\": (1, 200), \"precision\": 1},\n",
    "            {\"name\": \"Pressure Drop Hot\", \"unit\": \"bar\", \"range\": (0, 2), \"precision\": 2},\n",
    "            {\"name\": \"Pressure Drop Cold\", \"unit\": \"bar\", \"range\": (0, 2), \"precision\": 2},\n",
    "            {\"name\": \"Heat Transfer Rate\", \"unit\": \"kW\", \"range\": (10, 5000), \"precision\": 0},\n",
    "            {\"name\": \"Fouling Factor\", \"unit\": \"mÂ²K/kW\", \"range\": (0, 0.5), \"precision\": 3}\n",
    "        ],\n",
    "        # Specific parameters for tanks\n",
    "        \"Tank\": [\n",
    "            {\"name\": \"Level\", \"unit\": \"%\", \"range\": (0, 100), \"precision\": 1},\n",
    "            {\"name\": \"Temperature\", \"unit\": \"Â°C\", \"range\": (10, 80), \"precision\": 1},\n",
    "            {\"name\": \"Pressure\", \"unit\": \"bar\", \"range\": (1, 5), \"precision\": 2},\n",
    "            {\"name\": \"Inlet Flow\", \"unit\": \"mÂ³/h\", \"range\": (0, 50), \"precision\": 1},\n",
    "            {\"name\": \"Outlet Flow\", \"unit\": \"mÂ³/h\", \"range\": (0, 50), \"precision\": 1},\n",
    "            {\"name\": \"Agitator Speed\", \"unit\": \"rpm\", \"range\": (0, 200), \"precision\": 0},\n",
    "            {\"name\": \"pH\", \"unit\": \"pH\", \"range\": (3, 11), \"precision\": 2},\n",
    "            {\"name\": \"Density\", \"unit\": \"kg/mÂ³\", \"range\": (800, 1200), \"precision\": 0},\n",
    "            {\"name\": \"Volume\", \"unit\": \"mÂ³\", \"range\": (0, 200), \"precision\": 1},\n",
    "            {\"name\": \"Jacket Temperature\", \"unit\": \"Â°C\", \"range\": (5, 95), \"precision\": 1}\n",
    "        ],\n",
    "        # Specific parameters for dryers\n",
    "        \"Dryer\": [\n",
    "            {\"name\": \"Inlet Temperature\", \"unit\": \"Â°C\", \"range\": (100, 300), \"precision\": 1},\n",
    "            {\"name\": \"Outlet Temperature\", \"unit\": \"Â°C\", \"range\": (50, 150), \"precision\": 1},\n",
    "            {\"name\": \"Moisture Content\", \"unit\": \"%\", \"range\": (0, 30), \"precision\": 1},\n",
    "            {\"name\": \"Air Flow\", \"unit\": \"mÂ³/h\", \"range\": (500, 5000), \"precision\": 0},\n",
    "            {\"name\": \"Feed Rate\", \"unit\": \"kg/h\", \"range\": (50, 2000), \"precision\": 0},\n",
    "            {\"name\": \"Residence Time\", \"unit\": \"min\", \"range\": (5, 120), \"precision\": 0},\n",
    "            {\"name\": \"Humidity\", \"unit\": \"%RH\", \"range\": (10, 90), \"precision\": 1},\n",
    "            {\"name\": \"Pressure Drop\", \"unit\": \"mbar\", \"range\": (5, 100), \"precision\": 0},\n",
    "            {\"name\": \"Energy Consumption\", \"unit\": \"kWh\", \"range\": (10, 1000), \"precision\": 0},\n",
    "            {\"name\": \"Product Temperature\", \"unit\": \"Â°C\", \"range\": (40, 120), \"precision\": 1}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Define control modes\n",
    "    control_modes = [\"Auto\", \"Manual\", \"Cascade\", \"Supervised\", \"Off\"]\n",
    "    control_mode_weights = [0.7, 0.15, 0.1, 0.04, 0.01]  # Probability weights\n",
    "    \n",
    "    # Create batch IDs and recipe IDs if not provided\n",
    "    if batches_df is None or len(batches_df) == 0:\n",
    "        print(\"Creating synthetic batch IDs for process parameters...\")\n",
    "        batch_ids = [f\"BATCH-{uuid.uuid4().hex[:8].upper()}\" for _ in range(30)]\n",
    "    else:\n",
    "        batch_ids = batches_df['batch_id'].unique().tolist()\n",
    "        \n",
    "    if recipes_df is None or len(recipes_df) == 0:\n",
    "        print(\"Creating synthetic recipe IDs for process parameters...\")\n",
    "        recipe_ids = [f\"RECIPE-{uuid.uuid4().hex[:8].upper()}\" for _ in range(15)]\n",
    "    else:\n",
    "        recipe_ids = recipes_df['recipe_id'].unique().tolist()\n",
    "    \n",
    "    # Prepare the output file with CSV writer for memory efficiency\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        fieldnames = [\n",
    "            'parameter_id', 'parameter_name', 'equipment_id', 'timestamp', \n",
    "            'setpoint_value', 'actual_value', 'deviation', 'unit', \n",
    "            'upper_control_limit', 'lower_control_limit', 'upper_spec_limit', \n",
    "            'lower_spec_limit', 'control_mode', 'recipe_id', 'batch_id'\n",
    "        ]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        print(f\"Generating process parameters data...\")\n",
    "        parameters_count = 0\n",
    "        \n",
    "        # Process each equipment\n",
    "        for _, equipment in equipment_df.iterrows():\n",
    "            equipment_id = equipment['equipment_id']\n",
    "            equipment_type = equipment['equipment_type']\n",
    "            \n",
    "            # Determine appropriate parameters for this equipment type\n",
    "            if equipment_type in parameter_types:\n",
    "                possible_parameters = parameter_types[equipment_type]\n",
    "            else:\n",
    "                possible_parameters = parameter_types[\"general\"]\n",
    "            \n",
    "            # Vary the number of parameters per equipment to make it more realistic\n",
    "            equipment_parameter_count = max(1, int(random.normalvariate(num_parameters_per_equipment, num_parameters_per_equipment/4)))\n",
    "            \n",
    "            # Select parameters for this equipment (without replacement to avoid duplicates)\n",
    "            selected_parameters = random.sample(possible_parameters, min(equipment_parameter_count, len(possible_parameters)))\n",
    "            \n",
    "            # For each parameter, generate time series data\n",
    "            for param in selected_parameters:\n",
    "                param_name = param[\"name\"]\n",
    "                param_unit = param[\"unit\"]\n",
    "                min_value, max_value = param[\"range\"]\n",
    "                precision = param[\"precision\"]\n",
    "                \n",
    "                # Create a base parameter ID\n",
    "                base_parameter_id = f\"PARAM-{uuid.uuid4().hex[:8].upper()}\"\n",
    "                \n",
    "                # Determine if this parameter is associated with a recipe and batch\n",
    "                has_recipe = random.random() < 0.7  # 70% chance of having a recipe\n",
    "                recipe_id = random.choice(recipe_ids) if has_recipe else \"\"\n",
    "                \n",
    "                has_batch = random.random() < 0.6  # 60% chance of having a batch\n",
    "                batch_id = random.choice(batch_ids) if has_batch else \"\"\n",
    "                \n",
    "                # Determine control limits and specification limits\n",
    "                # Control limits are tighter than spec limits\n",
    "                range_width = max_value - min_value\n",
    "                \n",
    "                # Calculate control limits (typically +/- 2 sigma from setpoint)\n",
    "                control_width = range_width * random.uniform(0.1, 0.3)  # 10-30% of range\n",
    "                \n",
    "                # Calculate spec limits (typically +/- 3 sigma from setpoint)\n",
    "                spec_width = range_width * random.uniform(0.2, 0.5)  # 20-50% of range\n",
    "                \n",
    "                # Setpoint is typically in the middle of the range, but can vary\n",
    "                setpoint_base = min_value + range_width * random.uniform(0.3, 0.7)\n",
    "                \n",
    "                # Control limits around setpoint\n",
    "                lcl = max(min_value, setpoint_base - control_width/2)\n",
    "                ucl = min(max_value, setpoint_base + control_width/2)\n",
    "                \n",
    "                # Spec limits outside control limits\n",
    "                lsl = max(min_value, setpoint_base - spec_width/2)\n",
    "                usl = min(max_value, setpoint_base + spec_width/2)\n",
    "                \n",
    "                # Round limits according to precision\n",
    "                lcl = round(lcl, precision)\n",
    "                ucl = round(ucl, precision)\n",
    "                lsl = round(lsl, precision)\n",
    "                usl = round(usl, precision)\n",
    "                \n",
    "                # Select control mode (mostly Auto)\n",
    "                control_mode = random.choices(control_modes, weights=control_mode_weights)[0]\n",
    "                \n",
    "                # Generate time series data for this parameter\n",
    "                # We'll create a base setpoint and then add variations and trends\n",
    "                \n",
    "                # Time points\n",
    "                time_points = [\n",
    "                    start_time + (end_time - start_time) * (i / (samples_per_parameter - 1))\n",
    "                    for i in range(samples_per_parameter)\n",
    "                ]\n",
    "                \n",
    "                # Create setpoint changes over time (step changes)\n",
    "                # Typically setpoints change occasionally in steps\n",
    "                setpoint_changes = []\n",
    "                \n",
    "                # Decide how many setpoint changes to make (0-5)\n",
    "                num_changes = random.randint(0, 5)\n",
    "                change_points = sorted(random.sample(range(1, samples_per_parameter), num_changes))\n",
    "                \n",
    "                current_setpoint = setpoint_base\n",
    "                setpoint_values = [current_setpoint] * samples_per_parameter\n",
    "                \n",
    "                for change_point in change_points:\n",
    "                    # Change setpoint by a percentage of the range\n",
    "                    change_pct = random.uniform(-0.2, 0.2)  # -20% to +20%\n",
    "                    change_amount = range_width * change_pct\n",
    "                    new_setpoint = current_setpoint + change_amount\n",
    "                    \n",
    "                    # Keep within range\n",
    "                    new_setpoint = max(min_value, min(max_value, new_setpoint))\n",
    "                    \n",
    "                    # Round to appropriate precision\n",
    "                    new_setpoint = round(new_setpoint, precision)\n",
    "                    \n",
    "                    # Update all setpoints from this point forward\n",
    "                    for i in range(change_point, samples_per_parameter):\n",
    "                        setpoint_values[i] = new_setpoint\n",
    "                    \n",
    "                    current_setpoint = new_setpoint\n",
    "                \n",
    "                # Generate actual values with different patterns:\n",
    "                # 1. Closely following setpoint with noise\n",
    "                # 2. Gradual drift\n",
    "                # 3. Oscillation around setpoint\n",
    "                # 4. Step response to setpoint changes\n",
    "                # 5. Occasional spikes/outliers\n",
    "                \n",
    "                pattern = random.choice([\"tracking\", \"drift\", \"oscillation\", \"step\", \"spikes\"])\n",
    "                actual_values = []\n",
    "                \n",
    "                if pattern == \"tracking\":\n",
    "                    # Closely tracks setpoint with normal noise\n",
    "                    for i in range(samples_per_parameter):\n",
    "                        setpoint = setpoint_values[i]\n",
    "                        noise = random.normalvariate(0, range_width * 0.02)  # Small noise\n",
    "                        actual_value = setpoint + noise\n",
    "                        actual_values.append(actual_value)\n",
    "                        \n",
    "                elif pattern == \"drift\":\n",
    "                    # Gradual drift from setpoint\n",
    "                    drift_rate = random.uniform(-0.05, 0.05) * range_width / samples_per_parameter\n",
    "                    for i in range(samples_per_parameter):\n",
    "                        setpoint = setpoint_values[i]\n",
    "                        drift = drift_rate * i\n",
    "                        noise = random.normalvariate(0, range_width * 0.01)\n",
    "                        actual_value = setpoint + drift + noise\n",
    "                        actual_values.append(actual_value)\n",
    "                        \n",
    "                elif pattern == \"oscillation\":\n",
    "                    # Oscillation around setpoint\n",
    "                    period = random.uniform(10, 50)  # Oscillation period\n",
    "                    amplitude = random.uniform(0.02, 0.1) * range_width  # Oscillation amplitude\n",
    "                    for i in range(samples_per_parameter):\n",
    "                        setpoint = setpoint_values[i]\n",
    "                        oscillation = amplitude * np.sin(2 * np.pi * i / period)\n",
    "                        noise = random.normalvariate(0, range_width * 0.01)\n",
    "                        actual_value = setpoint + oscillation + noise\n",
    "                        actual_values.append(actual_value)\n",
    "                        \n",
    "                elif pattern == \"step\":\n",
    "                    # Step response to setpoint changes\n",
    "                    response_lag = int(random.uniform(3, 10))  # Lag in samples\n",
    "                    damping = random.uniform(0.7, 0.95)  # Damping factor\n",
    "                    \n",
    "                    # Initialize with first setpoint\n",
    "                    current_response = setpoint_values[0]\n",
    "                    for i in range(samples_per_parameter):\n",
    "                        setpoint = setpoint_values[i]\n",
    "                        \n",
    "                        # Calculate step response with lag\n",
    "                        if i > 0:\n",
    "                            # Move towards setpoint with damping\n",
    "                            current_response = current_response + (setpoint - current_response) * (1 - damping)\n",
    "                        \n",
    "                        noise = random.normalvariate(0, range_width * 0.01)\n",
    "                        actual_value = current_response + noise\n",
    "                        actual_values.append(actual_value)\n",
    "                        \n",
    "                else:  # spikes\n",
    "                    # Occasional spikes/outliers\n",
    "                    spike_probability = 0.05  # 5% chance of spike\n",
    "                    for i in range(samples_per_parameter):\n",
    "                        setpoint = setpoint_values[i]\n",
    "                        if random.random() < spike_probability:\n",
    "                            # Create a spike\n",
    "                            spike_dir = 1 if random.random() > 0.5 else -1\n",
    "                            spike_size = random.uniform(0.1, 0.3) * range_width\n",
    "                            noise = spike_dir * spike_size\n",
    "                        else:\n",
    "                            noise = random.normalvariate(0, range_width * 0.02)\n",
    "                        \n",
    "                        actual_value = setpoint + noise\n",
    "                        actual_values.append(actual_value)\n",
    "                \n",
    "                # Ensure values stay within min/max range\n",
    "                actual_values = [max(min_value, min(max_value, val)) for val in actual_values]\n",
    "                \n",
    "                # Round values to appropriate precision\n",
    "                actual_values = [round(val, precision) for val in actual_values]\n",
    "                \n",
    "                # Calculate deviations\n",
    "                deviations = [actual - setpoint for actual, setpoint in zip(actual_values, setpoint_values)]\n",
    "                \n",
    "                # Write parameter records to CSV\n",
    "                for i in range(samples_per_parameter):\n",
    "                    parameter_id = f\"{base_parameter_id}-{i+1}\"\n",
    "                    timestamp = time_points[i].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    setpoint = setpoint_values[i]\n",
    "                    actual = actual_values[i]\n",
    "                    deviation = deviations[i]\n",
    "                    \n",
    "                    writer.writerow({\n",
    "                        'parameter_id': parameter_id,\n",
    "                        'parameter_name': param_name,\n",
    "                        'equipment_id': equipment_id,\n",
    "                        'timestamp': timestamp,\n",
    "                        'setpoint_value': setpoint,\n",
    "                        'actual_value': actual,\n",
    "                        'deviation': round(deviation, precision),\n",
    "                        'unit': param_unit,\n",
    "                        'upper_control_limit': ucl,\n",
    "                        'lower_control_limit': lcl,\n",
    "                        'upper_spec_limit': usl,\n",
    "                        'lower_spec_limit': lsl,\n",
    "                        'control_mode': control_mode,\n",
    "                        'recipe_id': recipe_id,\n",
    "                        'batch_id': batch_id\n",
    "                    })\n",
    "                    \n",
    "                    parameters_count += 1\n",
    "                    \n",
    "                if parameters_count % 50000 == 0:\n",
    "                    print(f\"Generated {parameters_count} parameter records so far...\")\n",
    "    \n",
    "    print(f\"Successfully generated {parameters_count} process parameter records.\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    # Return a sample of the data (first 1000 rows) for preview\n",
    "    return pd.read_csv(output_file, nrows=1000)\n",
    "\n",
    "def get_sample_statistics(output_file):\n",
    "    \"\"\"\n",
    "    Get basic statistics about the generated process parameters data\n",
    "    \n",
    "    Parameters:\n",
    "    - output_file: CSV file containing the process parameters data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the first chunk to get column information\n",
    "        sample_df = pd.read_csv(output_file, nrows=1000)\n",
    "        \n",
    "        # Sample statistics on chunks to avoid memory issues\n",
    "        num_rows = 0\n",
    "        equipment_ids = set()\n",
    "        parameter_names = set()\n",
    "        control_modes = set()\n",
    "        recipe_count = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        # Create containers for deviation statistics\n",
    "        all_deviations = []\n",
    "        sample_count = 0\n",
    "        max_samples = 100000  # Limit samples for memory efficiency\n",
    "        \n",
    "        # Process in chunks\n",
    "        for chunk in pd.read_csv(output_file, chunksize=10000):\n",
    "            num_rows += len(chunk)\n",
    "            equipment_ids.update(chunk['equipment_id'].unique())\n",
    "            parameter_names.update(chunk['parameter_name'].unique())\n",
    "            control_modes.update(chunk['control_mode'].unique())\n",
    "            \n",
    "            # Count associations\n",
    "            recipe_count += (chunk['recipe_id'] != \"\").sum()\n",
    "            batch_count += (chunk['batch_id'] != \"\").sum()\n",
    "            \n",
    "            # Sample deviations (for statistical analysis)\n",
    "            if sample_count < max_samples:\n",
    "                deviation_sample = chunk['deviation'].sample(min(1000, len(chunk)))\n",
    "                all_deviations.extend(deviation_sample.tolist())\n",
    "                sample_count += len(deviation_sample)\n",
    "        \n",
    "        print(\"\\nProcess Parameters Statistics:\")\n",
    "        print(f\"Total parameter records: {num_rows}\")\n",
    "        print(f\"Unique equipment with parameters: {len(equipment_ids)}\")\n",
    "        print(f\"Unique parameter names: {len(parameter_names)}\")\n",
    "        print(f\"Parameter names: {sorted(parameter_names)}\")\n",
    "        print(f\"Control modes: {sorted(control_modes)}\")\n",
    "        \n",
    "        # Calculate percentages\n",
    "        if num_rows > 0:\n",
    "            print(f\"\\nParameters with recipe association: {recipe_count} ({recipe_count/num_rows*100:.1f}%)\")\n",
    "            print(f\"Parameters with batch association: {batch_count} ({batch_count/num_rows*100:.1f}%)\")\n",
    "        \n",
    "        # Calculate deviation statistics\n",
    "        if all_deviations:\n",
    "            avg_deviation = sum(all_deviations) / len(all_deviations)\n",
    "            abs_deviations = [abs(d) for d in all_deviations]\n",
    "            avg_abs_deviation = sum(abs_deviations) / len(abs_deviations)\n",
    "            max_deviation = max(abs_deviations)\n",
    "            \n",
    "            print(f\"\\nDeviation Statistics (from sample):\")\n",
    "            print(f\"  Average deviation: {avg_deviation:.4f}\")\n",
    "            print(f\"  Average absolute deviation: {avg_abs_deviation:.4f}\")\n",
    "            print(f\"  Maximum absolute deviation: {max_deviation:.4f}\")\n",
    "        \n",
    "        # Get time range if available\n",
    "        if 'timestamp' in sample_df.columns:\n",
    "            try:\n",
    "                min_time = pd.to_datetime(sample_df['timestamp']).min()\n",
    "                max_time = pd.to_datetime(sample_df['timestamp']).max()\n",
    "                print(f\"\\nTime range (from sample): approximately {min_time} to {max_time}\")\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting statistics: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Load the equipment data\n",
    "    equipment_df = load_equipment_data()\n",
    "    \n",
    "    # Try to load recipes and batches data if available\n",
    "    recipes_df = load_recipes_data()\n",
    "    batches_df = load_batches_data()\n",
    "    \n",
    "    if equipment_df is not None:\n",
    "        # Define the time range (past 7 days)\n",
    "        end_time = datetime.now()\n",
    "        start_time = end_time - timedelta(days=7)\n",
    "        \n",
    "        # Generate process parameters data\n",
    "        sample_df = generate_process_parameters(\n",
    "            equipment_df,\n",
    "            recipes_df,\n",
    "            batches_df,\n",
    "            num_parameters_per_equipment=5,  # Average 5 parameters per equipment\n",
    "            samples_per_parameter=100,      # 100 time samples per parameter\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            output_file=\"data/process_parameters.csv\"\n",
    "        )\n",
    "        \n",
    "        # Display a sample of the data\n",
    "        if sample_df is not None:\n",
    "            print(\"\\nSample data (first 5 records):\")\n",
    "            print(sample_df.head())\n",
    "            \n",
    "            # Get statistics\n",
    "            get_sample_statistics(\"data/process_parameters.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2bf4e2",
   "metadata": {},
   "source": [
    "Recipes & Batch Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92504cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Products data file data/products.csv not found.\n",
      "Recipes will be generated with synthetic product IDs.\n",
      "Note: Personnel data file data/personnel.csv not found.\n",
      "Recipes will be generated with synthetic personnel IDs.\n",
      "Generating synthetic product IDs...\n",
      "Generating synthetic personnel IDs...\n",
      "Successfully generated 50 recipe records.\n",
      "Data saved to data/recipes.csv\n",
      "Successfully generated 366 batch step records for 37 recipes.\n",
      "Data saved to data/batch_steps.csv\n",
      "\n",
      "Sample recipes data (first 5 records):\n",
      "         recipe_id                  recipe_name     product_id version  \\\n",
      "0  RECIPE-5FEEC092  Sterilization Procedure 992                    3.2   \n",
      "1  RECIPE-DE9EAF5C  Formulation Recipe D406-470  PROD-D40652D0     3.6   \n",
      "2  RECIPE-45C2D7EF  Formulation Recipe BCB4-619  PROD-BCB4AE01     2.3   \n",
      "3  RECIPE-70CF4DCE   Processing Recipe D9CE-342  PROD-D9CEBCB2     3.1   \n",
      "4  RECIPE-7303DA66    Synthesis Recipe 2BC2-577  PROD-2BC251ED     3.1   \n",
      "\n",
      "     status         author creation_date approval_date    approved_by  \\\n",
      "0     Draft  PERS-6EEFE72E    2024-03-09                                \n",
      "1  Obsolete  PERS-F6442FC4    2024-12-27    2025-07-01  PERS-6A6AC946   \n",
      "2    Active  PERS-C386F4B8    2025-05-05    2025-06-26  PERS-6A6AC946   \n",
      "3    Active  PERS-F6442FC4    2024-04-06    2025-06-22  PERS-A6409662   \n",
      "4     Draft  PERS-DCB17471    2024-08-10                                \n",
      "\n",
      "  recipe_type equipment_requirement  expected_duration_minutes  \\\n",
      "0  Validation               Reactor                        170   \n",
      "1       Batch                  Tank                        286   \n",
      "2       Batch                  Tank                        384   \n",
      "3  Continuous              Extruder                       1293   \n",
      "4  Continuous               Reactor                       3280   \n",
      "\n",
      "                                  recipe_description  \n",
      "0  Standard validation recipe for product product...  \n",
      "1  Regulatory approved batch recipe for product D...  \n",
      "2  batch recipe designed for optimal product BCB4...  \n",
      "3  continuous recipe with enhanced process contro...  \n",
      "4  Validated continuous recipe for consistent pro...  \n",
      "\n",
      "Sample batch steps data (first 5 records):\n",
      "         step_id        recipe_id        step_name  step_number  \\\n",
      "0  STEP-F7523E38  RECIPE-DE9EAF5C            Setup            1   \n",
      "1  STEP-C1FF6678  RECIPE-DE9EAF5C        Cooling 2            2   \n",
      "2  STEP-FD8DE347  RECIPE-DE9EAF5C  pH Adjustment 3            3   \n",
      "3  STEP-42E59DB0  RECIPE-DE9EAF5C        Holding 4            4   \n",
      "4  STEP-96E818F7  RECIPE-DE9EAF5C       Sampling 5            5   \n",
      "\n",
      "                                         description  \\\n",
      "0  Prepare equipment and materials for batch proc...   \n",
      "1  Execute cooling operation according to standar...   \n",
      "2  Standard ph adjustment procedure for batch rec...   \n",
      "3  Execute holding operation according to standar...   \n",
      "4      Standard sampling procedure for batch recipe.   \n",
      "\n",
      "   expected_duration_minutes step_type equipment_requirement  \\\n",
      "0                         14   Utility                  Tank   \n",
      "1                         31   Process                  Tank   \n",
      "2                         23  Standard                  Tank   \n",
      "3                         26   Process                  Tank   \n",
      "4                         34   Quality                  Tank   \n",
      "\n",
      "  predecessor_steps successor_steps  \n",
      "0                     STEP-C1FF6678  \n",
      "1     STEP-F7523E38   STEP-FD8DE347  \n",
      "2     STEP-C1FF6678   STEP-42E59DB0  \n",
      "3     STEP-FD8DE347   STEP-96E818F7  \n",
      "4     STEP-42E59DB0   STEP-F3F09DF0  \n",
      "\n",
      "Recipes Statistics:\n",
      "Total recipes: 50\n",
      "\n",
      "Recipe Type Distribution:\n",
      "  Batch: 26 (52.0%)\n",
      "  Validation: 7 (14.0%)\n",
      "  Continuous: 6 (12.0%)\n",
      "  Discrete: 5 (10.0%)\n",
      "  Cleaning: 4 (8.0%)\n",
      "  Testing: 2 (4.0%)\n",
      "\n",
      "Status Distribution:\n",
      "  Active: 26 (52.0%)\n",
      "  Approved: 8 (16.0%)\n",
      "  In Review: 5 (10.0%)\n",
      "  Draft: 4 (8.0%)\n",
      "  Obsolete: 4 (8.0%)\n",
      "  Testing: 3 (6.0%)\n",
      "\n",
      "Equipment Requirement Distribution:\n",
      "  Reactor: 17 (34.0%)\n",
      "  Tank: 12 (24.0%)\n",
      "  Mixer: 8 (16.0%)\n",
      "  Robot: 3 (6.0%)\n",
      "  Distillation Column: 2 (4.0%)\n",
      "  Blender: 2 (4.0%)\n",
      "  Assembly Station: 2 (4.0%)\n",
      "  Extruder: 1 (2.0%)\n",
      "  Heat Exchanger: 1 (2.0%)\n",
      "  Testing Station: 1 (2.0%)\n",
      "\n",
      "Recipes with product association: 37 (74.0%)\n",
      "\n",
      "Duration Statistics:\n",
      "  Average duration: 501.2 minutes\n",
      "  Minimum duration: 32.0 minutes\n",
      "  Maximum duration: 4303.0 minutes\n",
      "\n",
      "Batch Steps Statistics:\n",
      "Total batch steps: 366\n",
      "Average steps per recipe: 9.9\n",
      "Minimum steps per recipe: 3\n",
      "Maximum steps per recipe: 14\n",
      "\n",
      "Step Type Distribution:\n",
      "  Process: 82 (22.4%)\n",
      "  Utility: 79 (21.6%)\n",
      "  Standard: 60 (16.4%)\n",
      "  Material Handling: 60 (16.4%)\n",
      "  Quality: 37 (10.1%)\n",
      "  Operation: 28 (7.7%)\n",
      "  Cleaning: 20 (5.5%)\n",
      "\n",
      "Step Duration Statistics:\n",
      "  Average step duration: 21.0 minutes\n",
      "  Minimum step duration: 1.0 minutes\n",
      "  Maximum step duration: 288.0 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "\n",
    "def load_equipment_data(equipment_file=\"data/equipment.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated equipment data\n",
    "    \n",
    "    Parameters:\n",
    "    - equipment_file: CSV file containing equipment data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the equipment data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(equipment_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Equipment data file {equipment_file} not found.\")\n",
    "        print(\"Please run the equipment data generation script first.\")\n",
    "        return None\n",
    "    \n",
    "def load_products_data(products_file=\"data/products.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated products data if available\n",
    "    \n",
    "    Parameters:\n",
    "    - products_file: CSV file containing products data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the products data or None if not available\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(products_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Note: Products data file {products_file} not found.\")\n",
    "        print(\"Recipes will be generated with synthetic product IDs.\")\n",
    "        return None\n",
    "\n",
    "def load_personnel_data(personnel_file=\"data/personnel.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated personnel data if available\n",
    "    \n",
    "    Parameters:\n",
    "    - personnel_file: CSV file containing personnel data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the personnel data or None if not available\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(personnel_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Note: Personnel data file {personnel_file} not found.\")\n",
    "        print(\"Recipes will be generated with synthetic personnel IDs.\")\n",
    "        return None\n",
    "\n",
    "def generate_recipes_data(equipment_df, products_df=None, personnel_df=None, num_recipes=50, output_file=\"data/recipes.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic data for the Recipes table from ISA-95 Level 2.\n",
    "    \n",
    "    Parameters:\n",
    "    - equipment_df: DataFrame containing equipment data\n",
    "    - products_df: DataFrame containing products data (optional)\n",
    "    - personnel_df: DataFrame containing personnel data (optional)\n",
    "    - num_recipes: Number of recipe records to generate\n",
    "    - output_file: CSV file to save the data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the generated recipes data\n",
    "    \"\"\"\n",
    "    if equipment_df is None or len(equipment_df) == 0:\n",
    "        print(\"Error: No equipment data available.\")\n",
    "        return None\n",
    "    \n",
    "    # Generate product IDs if not provided\n",
    "    if products_df is None or len(products_df) == 0:\n",
    "        print(\"Generating synthetic product IDs...\")\n",
    "        product_ids = [f\"PROD-{uuid.uuid4().hex[:8].upper()}\" for _ in range(int(num_recipes * 0.7))]\n",
    "    else:\n",
    "        product_ids = products_df['product_id'].unique().tolist()\n",
    "    \n",
    "    # Generate personnel IDs if not provided\n",
    "    if personnel_df is None or len(personnel_df) == 0:\n",
    "        print(\"Generating synthetic personnel IDs...\")\n",
    "        personnel_ids = [f\"PERS-{uuid.uuid4().hex[:8].upper()}\" for _ in range(20)]\n",
    "    else:\n",
    "        personnel_ids = personnel_df['personnel_id'].unique().tolist()\n",
    "    \n",
    "    # Filter equipment to get only production equipment (not instruments/sensors)\n",
    "    production_equipment_types = [\n",
    "        \"Reactor\", \"Mixer\", \"Pump\", \"Compressor\", \"Heat Exchanger\", \"Distillation Column\",\n",
    "        \"Filter\", \"Dryer\", \"Tank\", \"Furnace\", \"Conveyor\", \"Mill\", \"Centrifuge\", \"Evaporator\",\n",
    "        \"Crystallizer\", \"Extruder\", \"Boiler\", \"Blender\", \"Separator\", \"Packaging Machine\",\n",
    "        \"CNC Machine\", \"Robot\", \"Injection Molder\", \"Press\", \"Welder\", \"Assembly Station\",\n",
    "        \"Filling Machine\", \"Labeling Machine\", \"Testing Station\", \"Sterilizer\"\n",
    "    ]\n",
    "    \n",
    "    # Get equipment classes for recipe requirements\n",
    "    equipment_classes = {}\n",
    "    for _, equip in equipment_df.iterrows():\n",
    "        eq_type = equip['equipment_type'] if 'equipment_type' in equip else \"Unknown\"\n",
    "        if eq_type in production_equipment_types:\n",
    "            if eq_type not in equipment_classes:\n",
    "                equipment_classes[eq_type] = []\n",
    "            equipment_classes[eq_type].append(equip['equipment_id'])\n",
    "    \n",
    "    # Define recipe types\n",
    "    recipe_types = [\"Batch\", \"Continuous\", \"Discrete\", \"Testing\", \"Cleaning\", \"Validation\"]\n",
    "    \n",
    "    # Define recipe statuses\n",
    "    recipe_statuses = [\"Active\", \"In Review\", \"Approved\", \"Obsolete\", \"Draft\", \"Testing\"]\n",
    "    status_weights = [0.6, 0.1, 0.15, 0.05, 0.05, 0.05]  # Mostly active recipes\n",
    "    \n",
    "    # Generate recipe data\n",
    "    data = {\n",
    "        \"recipe_id\": [f\"RECIPE-{uuid.uuid4().hex[:8].upper()}\" for _ in range(num_recipes)],\n",
    "        \"recipe_name\": [],\n",
    "        \"product_id\": [],\n",
    "        \"version\": [],\n",
    "        \"status\": [],\n",
    "        \"author\": [],\n",
    "        \"creation_date\": [],\n",
    "        \"approval_date\": [],\n",
    "        \"approved_by\": [],\n",
    "        \"recipe_type\": [],\n",
    "        \"equipment_requirement\": [],\n",
    "        \"expected_duration_minutes\": [],\n",
    "        \"recipe_description\": []\n",
    "    }\n",
    "    \n",
    "    # Product-related recipe names\n",
    "    product_prefixes = [\"Production\", \"Manufacturing\", \"Processing\", \"Assembly\", \"Synthesis\", \"Formulation\"]\n",
    "    \n",
    "    # Cleaning recipe names\n",
    "    cleaning_prefixes = [\"CIP\", \"Cleaning\", \"Sanitization\", \"Sterilization\", \"Flush\", \"Purge\"]\n",
    "    cleaning_suffixes = [\"Procedure\", \"Protocol\", \"Sequence\", \"Cycle\"]\n",
    "    \n",
    "    # Testing recipe names\n",
    "    testing_prefixes = [\"Test\", \"Validation\", \"Verification\", \"Qualification\", \"Calibration\"]\n",
    "    testing_suffixes = [\"Protocol\", \"Procedure\", \"Method\", \"Sequence\"]\n",
    "    \n",
    "    # Recipe description templates\n",
    "    description_templates = [\n",
    "        \"Standard {type} recipe for {product} production using {equipment} equipment.\",\n",
    "        \"{type} recipe designed for optimal {product} quality with defined process parameters.\",\n",
    "        \"Validated {type} recipe for consistent {product} manufacturing in {equipment} environment.\",\n",
    "        \"Optimized {type} process for {product} with reduced cycle time and improved yield.\",\n",
    "        \"Regulatory approved {type} recipe for {product} meeting all quality requirements.\",\n",
    "        \"{type} recipe with enhanced process control for premium {product} production.\"\n",
    "    ]\n",
    "    \n",
    "    # Generate data for each recipe\n",
    "    for i in range(num_recipes):\n",
    "        # Assign a product ID (some recipes may be for cleaning, testing, etc. without a product)\n",
    "        if random.random() < 0.8:  # 80% of recipes are for products\n",
    "            product_id = random.choice(product_ids)\n",
    "            data[\"product_id\"].append(product_id)\n",
    "            \n",
    "            # For product recipes, create product-based names\n",
    "            prefix = random.choice(product_prefixes)\n",
    "            # Extract a product code or ID suffix to use in the name\n",
    "            product_code = product_id.split('-')[-1][:4]\n",
    "            recipe_name = f\"{prefix} Recipe {product_code}-{random.randint(100, 999)}\"\n",
    "            \n",
    "            # Recipe type (mostly batch for product recipes)\n",
    "            if random.random() < 0.7:\n",
    "                recipe_type = \"Batch\"\n",
    "            else:\n",
    "                recipe_type = random.choice([\"Continuous\", \"Discrete\"])\n",
    "        else:\n",
    "            # Non-product recipes (cleaning, testing, etc.)\n",
    "            data[\"product_id\"].append(\"\")\n",
    "            \n",
    "            # Determine if it's a cleaning or testing recipe\n",
    "            if random.random() < 0.5:\n",
    "                # Cleaning recipe\n",
    "                prefix = random.choice(cleaning_prefixes)\n",
    "                suffix = random.choice(cleaning_suffixes)\n",
    "                recipe_name = f\"{prefix} {suffix} {random.randint(100, 999)}\"\n",
    "                recipe_type = random.choice([\"Cleaning\", \"Validation\"])\n",
    "            else:\n",
    "                # Testing recipe\n",
    "                prefix = random.choice(testing_prefixes)\n",
    "                suffix = random.choice(testing_suffixes)\n",
    "                recipe_name = f\"{prefix} {suffix} {random.randint(100, 999)}\"\n",
    "                recipe_type = random.choice([\"Testing\", \"Validation\"])\n",
    "        \n",
    "        data[\"recipe_name\"].append(recipe_name)\n",
    "        data[\"recipe_type\"].append(recipe_type)\n",
    "        \n",
    "        # Version numbering (major.minor)\n",
    "        major_version = random.randint(1, 3)\n",
    "        minor_version = random.randint(0, 9)\n",
    "        data[\"version\"].append(f\"{major_version}.{minor_version}\")\n",
    "        \n",
    "        # Status (weighted random)\n",
    "        data[\"status\"].append(random.choices(recipe_statuses, weights=status_weights)[0])\n",
    "        \n",
    "        # Author (personnel who created the recipe)\n",
    "        data[\"author\"].append(random.choice(personnel_ids))\n",
    "        \n",
    "        # Creation date (1-18 months ago)\n",
    "        creation_days_ago = random.randint(30, 540)\n",
    "        creation_date = datetime.now() - timedelta(days=creation_days_ago)\n",
    "        data[\"creation_date\"].append(creation_date.strftime(\"%Y-%m-%d\"))\n",
    "        \n",
    "        # Approval date and approver\n",
    "        if data[\"status\"][i] in [\"Approved\", \"Active\", \"Obsolete\"]:\n",
    "            # Approved recipes have approval dates after creation\n",
    "            approval_days_ago = random.randint(0, min(creation_days_ago - 1, 30))\n",
    "            approval_date = datetime.now() - timedelta(days=approval_days_ago)\n",
    "            data[\"approval_date\"].append(approval_date.strftime(\"%Y-%m-%d\"))\n",
    "            \n",
    "            # Approver is a different person than author\n",
    "            available_approvers = [p for p in personnel_ids if p != data[\"author\"][i]]\n",
    "            data[\"approved_by\"].append(random.choice(available_approvers))\n",
    "        else:\n",
    "            # Unapproved recipes\n",
    "            data[\"approval_date\"].append(\"\")\n",
    "            data[\"approved_by\"].append(\"\")\n",
    "        \n",
    "        # Equipment requirement\n",
    "        # Select a suitable equipment class for this recipe\n",
    "        if recipe_type == \"Batch\":\n",
    "            possible_classes = [\"Reactor\", \"Mixer\", \"Tank\", \"Blender\"]\n",
    "        elif recipe_type == \"Continuous\":\n",
    "            possible_classes = [\"Extruder\", \"Distillation Column\", \"Reactor\", \"Heat Exchanger\"]\n",
    "        elif recipe_type == \"Discrete\":\n",
    "            possible_classes = [\"CNC Machine\", \"Robot\", \"Injection Molder\", \"Assembly Station\"]\n",
    "        elif recipe_type == \"Cleaning\":\n",
    "            possible_classes = [\"Reactor\", \"Tank\", \"Mixer\", \"Filter\", \"Heat Exchanger\"]\n",
    "        elif recipe_type == \"Testing\":\n",
    "            possible_classes = [\"Testing Station\", \"Reactor\", \"Mixer\"]\n",
    "        else:  # Validation\n",
    "            possible_classes = [\"Reactor\", \"Tank\", \"Mixer\", \"Testing Station\"]\n",
    "        \n",
    "        # Filter to classes that exist in our equipment data\n",
    "        available_classes = [c for c in possible_classes if c in equipment_classes]\n",
    "        \n",
    "        if available_classes:\n",
    "            equipment_class = random.choice(available_classes)\n",
    "            data[\"equipment_requirement\"].append(equipment_class)\n",
    "        else:\n",
    "            # Default to any available equipment class\n",
    "            all_classes = list(equipment_classes.keys())\n",
    "            if all_classes:\n",
    "                data[\"equipment_requirement\"].append(random.choice(all_classes))\n",
    "            else:\n",
    "                data[\"equipment_requirement\"].append(\"Any\")\n",
    "        \n",
    "        # Expected duration\n",
    "        if recipe_type == \"Batch\":\n",
    "            # Batch processes typically take longer\n",
    "            duration = random.randint(60, 480)  # 1-8 hours\n",
    "        elif recipe_type == \"Continuous\":\n",
    "            # Continuous processes typically run for very long periods\n",
    "            duration = random.randint(480, 4320)  # 8-72 hours\n",
    "        elif recipe_type == \"Discrete\":\n",
    "            # Discrete manufacturing typically has shorter cycles\n",
    "            duration = random.randint(10, 120)  # 10 min - 2 hours\n",
    "        elif recipe_type == \"Cleaning\":\n",
    "            # Cleaning processes are usually shorter\n",
    "            duration = random.randint(30, 120)  # 30 min - 2 hours\n",
    "        else:  # Testing and Validation\n",
    "            duration = random.randint(60, 240)  # 1-4 hours\n",
    "        \n",
    "        data[\"expected_duration_minutes\"].append(duration)\n",
    "        \n",
    "        # Generate recipe description\n",
    "        template = random.choice(description_templates)\n",
    "        recipe_type_desc = recipe_type.lower()\n",
    "        product_desc = \"product\" if data[\"product_id\"][i] == \"\" else f\"product {product_id.split('-')[-1]}\"\n",
    "        equipment_desc = data[\"equipment_requirement\"][i].lower()\n",
    "        \n",
    "        description = template.format(\n",
    "            type=recipe_type_desc,\n",
    "            product=product_desc,\n",
    "            equipment=equipment_desc\n",
    "        )\n",
    "        \n",
    "        data[\"recipe_description\"].append(description)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Successfully generated {len(df)} recipe records.\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_batch_steps(recipes_df, num_steps_per_recipe=10, output_file=\"data/batch_steps.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic batch steps data based on the recipes table\n",
    "    \n",
    "    Parameters:\n",
    "    - recipes_df: DataFrame containing recipes data\n",
    "    - num_steps_per_recipe: Average number of steps per recipe\n",
    "    - output_file: CSV file to save the batch steps data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the generated batch steps data\n",
    "    \"\"\"\n",
    "    if recipes_df is None or len(recipes_df) == 0:\n",
    "        print(\"Error: No recipes data available.\")\n",
    "        return None\n",
    "    \n",
    "    # Filter to only include batch and discrete recipes (those that have steps)\n",
    "    batch_recipes = recipes_df[recipes_df['recipe_type'].isin(['Batch', 'Discrete', 'Testing', 'Cleaning'])]\n",
    "    \n",
    "    if len(batch_recipes) == 0:\n",
    "        print(\"Warning: No batch recipes found. Generating steps for all recipes instead.\")\n",
    "        batch_recipes = recipes_df\n",
    "    \n",
    "    # Define step types based on recipe types\n",
    "    step_types = {\n",
    "        \"Batch\": [\n",
    "            \"Charging\", \"Mixing\", \"Heating\", \"Cooling\", \"Reaction\", \"Holding\", \n",
    "            \"Sampling\", \"pH Adjustment\", \"Transfer\", \"Filtration\", \"Discharge\"\n",
    "        ],\n",
    "        \"Discrete\": [\n",
    "            \"Loading\", \"Processing\", \"Assembly\", \"Testing\", \"Inspection\", \n",
    "            \"Machining\", \"Welding\", \"Packaging\", \"Labeling\", \"Unloading\"\n",
    "        ],\n",
    "        \"Testing\": [\n",
    "            \"Sample Preparation\", \"Measurement\", \"Analysis\", \"Verification\", \n",
    "            \"Calibration\", \"Data Collection\", \"Reporting\", \"Cleanup\"\n",
    "        ],\n",
    "        \"Cleaning\": [\n",
    "            \"Pre-rinse\", \"Detergent Wash\", \"Rinse\", \"Sanitization\", \n",
    "            \"Final Rinse\", \"Drying\", \"Inspection\", \"Documentation\"\n",
    "        ],\n",
    "        \"Continuous\": [\n",
    "            \"Startup\", \"Steady State\", \"Parameter Adjustment\", \"Sampling\", \n",
    "            \"Monitoring\", \"Shutdown\", \"Transition\"\n",
    "        ],\n",
    "        \"Validation\": [\n",
    "            \"Setup\", \"Execution\", \"Data Collection\", \"Analysis\", \n",
    "            \"Verification\", \"Documentation\", \"Approval\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Common steps for most recipes\n",
    "    common_steps = [\"Setup\", \"Documentation\", \"Cleanup\"]\n",
    "    \n",
    "    # Generate batch steps data\n",
    "    data = {\n",
    "        \"step_id\": [],\n",
    "        \"recipe_id\": [],\n",
    "        \"step_name\": [],\n",
    "        \"step_number\": [],\n",
    "        \"description\": [],\n",
    "        \"expected_duration_minutes\": [],\n",
    "        \"step_type\": [],\n",
    "        \"equipment_requirement\": [],\n",
    "        \"predecessor_steps\": [],\n",
    "        \"successor_steps\": []\n",
    "    }\n",
    "    \n",
    "    # Process each recipe\n",
    "    for _, recipe in batch_recipes.iterrows():\n",
    "        recipe_id = recipe['recipe_id']\n",
    "        recipe_type = recipe['recipe_type']\n",
    "        recipe_duration = recipe['expected_duration_minutes']\n",
    "        \n",
    "        # Determine appropriate steps for this recipe type\n",
    "        if recipe_type in step_types:\n",
    "            possible_steps = step_types[recipe_type]\n",
    "        else:\n",
    "            possible_steps = step_types[\"Batch\"]  # Default to batch steps\n",
    "        \n",
    "        # Always include some common steps\n",
    "        all_possible_steps = possible_steps + common_steps\n",
    "        \n",
    "        # Vary the number of steps per recipe\n",
    "        num_steps = max(3, int(random.normalvariate(num_steps_per_recipe, num_steps_per_recipe/4)))\n",
    "        \n",
    "        # Make sure we don't have more steps than possible step types\n",
    "        num_steps = min(num_steps, len(all_possible_steps))\n",
    "        \n",
    "        # For recipes with few steps, ensure we have at least setup, main operation, and cleanup\n",
    "        if num_steps <= 3:\n",
    "            selected_steps = [\"Setup\", random.choice(possible_steps), \"Cleanup\"]\n",
    "        else:\n",
    "            # Select steps without replacement (to avoid duplicates)\n",
    "            # Always include Setup as first step and Cleanup as last step\n",
    "            middle_steps = random.sample(possible_steps, min(num_steps - 2, len(possible_steps)))\n",
    "            if len(middle_steps) < num_steps - 2:\n",
    "                # We need to add more steps - repeat some randomly\n",
    "                additional_needed = num_steps - 2 - len(middle_steps)\n",
    "                additional_steps = random.choices(possible_steps, k=additional_needed)\n",
    "                middle_steps.extend(additional_steps)\n",
    "            selected_steps = [\"Setup\"] + middle_steps + [\"Cleanup\"]\n",
    "        \n",
    "        # Calculate step durations (should sum approximately to recipe duration)\n",
    "        # Setup and cleanup are typically shorter\n",
    "        setup_duration = max(5, int(recipe_duration * 0.05))  # 5% of total time, min 5 minutes\n",
    "        cleanup_duration = max(5, int(recipe_duration * 0.05))  # 5% of total time, min 5 minutes\n",
    "        \n",
    "        # Remaining time for operational steps\n",
    "        remaining_duration = recipe_duration - (setup_duration + cleanup_duration)\n",
    "        \n",
    "        # Divide remaining time among operational steps\n",
    "        # Use a random distribution to make some steps longer than others\n",
    "        if len(selected_steps) > 2:\n",
    "            # Generate random weights for duration distribution\n",
    "            weights = [random.random() for _ in range(len(selected_steps) - 2)]\n",
    "            total_weight = sum(weights)\n",
    "            # Normalize weights\n",
    "            normalized_weights = [w / total_weight for w in weights]\n",
    "            # Calculate durations\n",
    "            op_durations = [max(1, int(remaining_duration * w)) for w in normalized_weights]\n",
    "        else:\n",
    "            op_durations = []\n",
    "        \n",
    "        # Combine all durations\n",
    "        step_durations = [setup_duration] + op_durations + [cleanup_duration]\n",
    "        \n",
    "        # Create step records\n",
    "        step_ids = []\n",
    "        for i, (step_name, duration) in enumerate(zip(selected_steps, step_durations)):\n",
    "            step_id = f\"STEP-{uuid.uuid4().hex[:8].upper()}\"\n",
    "            step_ids.append(step_id)\n",
    "            \n",
    "            # Determine step type (more specific classification)\n",
    "            if step_name in [\"Setup\", \"Cleanup\", \"Documentation\"]:\n",
    "                step_type = \"Utility\"\n",
    "            elif step_name in [\"Charging\", \"Loading\", \"Transfer\", \"Discharge\", \"Unloading\"]:\n",
    "                step_type = \"Material Handling\"\n",
    "            elif step_name in [\"Heating\", \"Cooling\", \"Reaction\", \"Holding\"]:\n",
    "                step_type = \"Process\"\n",
    "            elif step_name in [\"Sampling\", \"Testing\", \"Inspection\", \"Analysis\", \"Measurement\"]:\n",
    "                step_type = \"Quality\"\n",
    "            elif step_name in [\"Mixing\", \"Assembly\", \"Machining\", \"Welding\"]:\n",
    "                step_type = \"Operation\"\n",
    "            elif step_name in [\"Pre-rinse\", \"Detergent Wash\", \"Rinse\", \"Sanitization\", \"Final Rinse\", \"Drying\"]:\n",
    "                step_type = \"Cleaning\"\n",
    "            else:\n",
    "                step_type = \"Standard\"\n",
    "            \n",
    "            # Create detailed step name\n",
    "            detailed_step_name = f\"{step_name} {i+1}\" if i > 0 and i < len(selected_steps)-1 else step_name\n",
    "            \n",
    "            # Create step description\n",
    "            if step_name == \"Setup\":\n",
    "                description = f\"Prepare equipment and materials for {recipe_type.lower()} process.\"\n",
    "            elif step_name == \"Cleanup\":\n",
    "                description = f\"Clean equipment and dispose of waste materials after {recipe_type.lower()} completion.\"\n",
    "            elif step_name == \"Documentation\":\n",
    "                description = f\"Record process parameters and batch information for {recipe_type.lower()} record.\"\n",
    "            else:\n",
    "                descriptions = [\n",
    "                    f\"Execute {step_name.lower()} operation according to standard procedure.\",\n",
    "                    f\"Perform {step_name.lower()} step with specified parameters.\",\n",
    "                    f\"Complete {step_name.lower()} phase of the {recipe_type.lower()} process.\",\n",
    "                    f\"{step_name} operation with quality verification.\",\n",
    "                    f\"Standard {step_name.lower()} procedure for {recipe_type.lower()} recipe.\"\n",
    "                ]\n",
    "                description = random.choice(descriptions)\n",
    "            \n",
    "            # Equipment requirement (inherit from recipe)\n",
    "            equipment_requirement = recipe['equipment_requirement']\n",
    "            \n",
    "            data[\"step_id\"].append(step_id)\n",
    "            data[\"recipe_id\"].append(recipe_id)\n",
    "            data[\"step_name\"].append(detailed_step_name)\n",
    "            data[\"step_number\"].append(i + 1)\n",
    "            data[\"description\"].append(description)\n",
    "            data[\"expected_duration_minutes\"].append(duration)\n",
    "            data[\"step_type\"].append(step_type)\n",
    "            data[\"equipment_requirement\"].append(equipment_requirement)\n",
    "            \n",
    "            # Set predecessor steps (leave blank for first step)\n",
    "            if i == 0:\n",
    "                data[\"predecessor_steps\"].append(\"\")\n",
    "            else:\n",
    "                data[\"predecessor_steps\"].append(step_ids[i-1])\n",
    "            \n",
    "            # Set successor steps (leave blank for last step)\n",
    "            if i == len(selected_steps) - 1:\n",
    "                data[\"successor_steps\"].append(\"\")\n",
    "            else:\n",
    "                # Will be filled in the next iteration\n",
    "                data[\"successor_steps\"].append(\"\")\n",
    "        \n",
    "        # Fill in successor steps\n",
    "        for i in range(len(step_ids) - 1):\n",
    "            data[\"successor_steps\"][len(data[\"successor_steps\"]) - len(step_ids) + i] = step_ids[i+1]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Successfully generated {len(df)} batch step records for {len(batch_recipes)} recipes.\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def display_statistics(recipes_df, batch_steps_df=None):\n",
    "    \"\"\"\n",
    "    Display basic statistics about the generated recipes and batch steps data\n",
    "    \n",
    "    Parameters:\n",
    "    - recipes_df: DataFrame containing recipes data\n",
    "    - batch_steps_df: DataFrame containing batch steps data (optional)\n",
    "    \"\"\"\n",
    "    if recipes_df is None or len(recipes_df) == 0:\n",
    "        print(\"No recipes data to analyze.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nRecipes Statistics:\")\n",
    "    print(f\"Total recipes: {len(recipes_df)}\")\n",
    "    \n",
    "    print(\"\\nRecipe Type Distribution:\")\n",
    "    type_counts = recipes_df['recipe_type'].value_counts()\n",
    "    for recipe_type, count in type_counts.items():\n",
    "        print(f\"  {recipe_type}: {count} ({count/len(recipes_df)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nStatus Distribution:\")\n",
    "    status_counts = recipes_df['status'].value_counts()\n",
    "    for status, count in status_counts.items():\n",
    "        print(f\"  {status}: {count} ({count/len(recipes_df)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nEquipment Requirement Distribution:\")\n",
    "    equip_counts = recipes_df['equipment_requirement'].value_counts().head(10)\n",
    "    for equip, count in equip_counts.items():\n",
    "        print(f\"  {equip}: {count} ({count/len(recipes_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Product association\n",
    "    product_count = recipes_df['product_id'].apply(lambda x: x != \"\").sum()\n",
    "    print(f\"\\nRecipes with product association: {product_count} ({product_count/len(recipes_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Duration statistics\n",
    "    durations = recipes_df['expected_duration_minutes'].astype(float)\n",
    "    print(f\"\\nDuration Statistics:\")\n",
    "    print(f\"  Average duration: {durations.mean():.1f} minutes\")\n",
    "    print(f\"  Minimum duration: {durations.min()} minutes\")\n",
    "    print(f\"  Maximum duration: {durations.max()} minutes\")\n",
    "    \n",
    "    # Batch steps statistics\n",
    "    if batch_steps_df is not None and len(batch_steps_df) > 0:\n",
    "        print(\"\\nBatch Steps Statistics:\")\n",
    "        print(f\"Total batch steps: {len(batch_steps_df)}\")\n",
    "        \n",
    "        # Steps per recipe\n",
    "        steps_per_recipe = batch_steps_df.groupby('recipe_id').size()\n",
    "        print(f\"Average steps per recipe: {steps_per_recipe.mean():.1f}\")\n",
    "        print(f\"Minimum steps per recipe: {steps_per_recipe.min()}\")\n",
    "        print(f\"Maximum steps per recipe: {steps_per_recipe.max()}\")\n",
    "        \n",
    "        print(\"\\nStep Type Distribution:\")\n",
    "        step_type_counts = batch_steps_df['step_type'].value_counts()\n",
    "        for step_type, count in step_type_counts.items():\n",
    "            print(f\"  {step_type}: {count} ({count/len(batch_steps_df)*100:.1f}%)\")\n",
    "        \n",
    "        # Step duration statistics\n",
    "        step_durations = batch_steps_df['expected_duration_minutes'].astype(float)\n",
    "        print(f\"\\nStep Duration Statistics:\")\n",
    "        print(f\"  Average step duration: {step_durations.mean():.1f} minutes\")\n",
    "        print(f\"  Minimum step duration: {step_durations.min()} minutes\")\n",
    "        print(f\"  Maximum step duration: {step_durations.max()} minutes\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Load the equipment data\n",
    "    equipment_df = load_equipment_data()\n",
    "    \n",
    "    # Try to load products and personnel data if available\n",
    "    products_df = load_products_data()\n",
    "    personnel_df = load_personnel_data()\n",
    "    \n",
    "    if equipment_df is not None:\n",
    "        # Generate recipes data\n",
    "        recipes_df = generate_recipes_data(\n",
    "            equipment_df,\n",
    "            products_df,\n",
    "            personnel_df,\n",
    "            num_recipes=50,  # Generate 50 recipe records\n",
    "            output_file=\"data/recipes.csv\"\n",
    "        )\n",
    "        \n",
    "        # Generate batch steps data\n",
    "        if recipes_df is not None:\n",
    "            batch_steps_df = generate_batch_steps(\n",
    "                recipes_df,\n",
    "                num_steps_per_recipe=10,  # Average 10 steps per recipe\n",
    "                output_file=\"data/batch_steps.csv\"\n",
    "            )\n",
    "        else:\n",
    "            batch_steps_df = None\n",
    "        \n",
    "        # Display sample data and statistics\n",
    "        if recipes_df is not None:\n",
    "            print(\"\\nSample recipes data (first 5 records):\")\n",
    "            print(recipes_df.head())\n",
    "            \n",
    "            if batch_steps_df is not None:\n",
    "                print(\"\\nSample batch steps data (first 5 records):\")\n",
    "                print(batch_steps_df.head())\n",
    "            \n",
    "            # Display statistics\n",
    "            display_statistics(recipes_df, batch_steps_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89cf850",
   "metadata": {},
   "source": [
    "BatchesStepExecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15f434e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Personnel data file data/personnel.csv not found.\n",
      "Batches will be generated with synthetic personnel IDs.\n",
      "Generating synthetic personnel IDs...\n",
      "Successfully generated 100 batch records.\n",
      "Data saved to data/batches.csv\n",
      "Generating synthetic personnel IDs...\n",
      "Generating batch step execution data...\n",
      "Successfully generated 1027 batch execution records.\n",
      "Data saved to data/batch_execution.csv\n",
      "\n",
      "Sample batch execution data (first 5 records):\n",
      "        execution_id        batch_id        step_id equipment_id  \\\n",
      "0  EXEC-D1ED5F702FF4  BATCH-24435A1C  STEP-A62B6D4D  EQ-AC717F77   \n",
      "1  EXEC-4A4AA96AF9F5  BATCH-24435A1C  STEP-F7B325E1  EQ-AC717F77   \n",
      "2  EXEC-A1C41BA39017  BATCH-24435A1C  STEP-7BE3E876  EQ-AC717F77   \n",
      "3  EXEC-57249B7FD9AF  BATCH-24435A1C  STEP-87DEA6AC  EQ-AC717F77   \n",
      "4  EXEC-45F1552FADD0  BATCH-24435A1C  STEP-538490E3  EQ-AC717F77   \n",
      "\n",
      "            start_time             end_time     status  operator_id  \\\n",
      "0  2025-06-23 02:06:27  2025-06-23 02:17:55  Completed  OP-4DCFD75A   \n",
      "1  2025-06-23 02:17:55  2025-06-23 02:28:25  Completed  OP-4DCFD75A   \n",
      "2  2025-06-23 02:28:25  2025-06-23 03:12:38  Completed  OP-4DCFD75A   \n",
      "3  2025-06-23 03:12:38  2025-06-23 03:41:32  Completed  OP-25D74480   \n",
      "4  2025-06-23 03:41:32  2025-06-23 04:27:01  Completed  OP-4DCFD75A   \n",
      "\n",
      "   actual_duration_minutes  deviation_reason  \\\n",
      "0                     11.0               NaN   \n",
      "1                     11.0               NaN   \n",
      "2                     44.0  Material quality   \n",
      "3                     29.0               NaN   \n",
      "4                     45.0   Equipment issue   \n",
      "\n",
      "                                     step_parameters  \n",
      "0  {\"Parameter1\": \"16.46\", \"Parameter2\": \"62.56\",...  \n",
      "1  {\"Material ID\": \"M-9203\", \"Quantity\": \"456.7 k...  \n",
      "2  {\"Material ID\": \"M-5202\", \"Quantity\": \"456.0 k...  \n",
      "3  {\"Temperature\": \"21.7 \\u00b0C\", \"Pressure\": \"2...  \n",
      "4  {\"Parameter1\": \"62.16\", \"Parameter2\": \"39.56\",...  \n",
      "\n",
      "Batches Statistics:\n",
      "Total batches: 100\n",
      "\n",
      "Batch Status Distribution:\n",
      "  Completed: 42 (42.0%)\n",
      "  In Progress: 25 (25.0%)\n",
      "  Planned: 23 (23.0%)\n",
      "  On Hold: 5 (5.0%)\n",
      "  Rejected: 3 (3.0%)\n",
      "  Aborted: 2 (2.0%)\n",
      "\n",
      "Batch Size Statistics:\n",
      "  Average batch size: 1062.0\n",
      "  Min batch size: 25.0\n",
      "  Max batch size: 5988.7\n",
      "\n",
      "Recipe Usage:\n",
      "  RECIPE-E8818CC9: 12 batches\n",
      "  RECIPE-45C2D7EF: 10 batches\n",
      "  RECIPE-81169765: 9 batches\n",
      "  RECIPE-5131FEA5: 8 batches\n",
      "  RECIPE-01913CAE: 7 batches\n",
      "\n",
      "Batches with parent: 100 (100.0%)\n",
      "\n",
      "Batch Execution Statistics (from sample):\n",
      "Sample size: 1027 execution records\n",
      "\n",
      "Execution Status Distribution:\n",
      "  Completed: 595 (57.9%)\n",
      "  Pending: 362 (35.2%)\n",
      "  In Progress: 40 (3.9%)\n",
      "  Skipped: 13 (1.3%)\n",
      "  Paused: 8 (0.8%)\n",
      "  Completed with Issues: 4 (0.4%)\n",
      "  Verified: 3 (0.3%)\n",
      "  Reworked: 1 (0.1%)\n",
      "  Aborted: 1 (0.1%)\n",
      "\n",
      "Step Duration Statistics:\n",
      "  Average step duration: 1606.5 minutes\n",
      "  Min step duration: -155.0 minutes\n",
      "  Max step duration: 42513.0 minutes\n",
      "\n",
      "Steps with deviation reasons: 1027 (100.0%)\n",
      "\n",
      "Equipment Usage (top 5):\n",
      "  EQ-6EA91277: 90 steps\n",
      "  EQ-5306C737: 80 steps\n",
      "  EQ-1D0C311E: 72 steps\n",
      "  EQ-38DD265D: 71 steps\n",
      "  EQ-6304B673: 69 steps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "import csv \n",
    "\n",
    "def load_equipment_data(equipment_file=\"data/equipment.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated equipment data\n",
    "    \n",
    "    Parameters:\n",
    "    - equipment_file: CSV file containing equipment data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the equipment data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(equipment_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Equipment data file {equipment_file} not found.\")\n",
    "        print(\"Please run the equipment data generation script first.\")\n",
    "        return None\n",
    "\n",
    "def load_recipes_data(recipes_file=\"data/recipes.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated recipes data\n",
    "    \n",
    "    Parameters:\n",
    "    - recipes_file: CSV file containing recipes data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the recipes data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(recipes_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Recipes data file {recipes_file} not found.\")\n",
    "        print(\"Please run the recipes data generation script first.\")\n",
    "        return None\n",
    "\n",
    "def load_batch_steps_data(batch_steps_file=\"data/batch_steps.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated batch steps data\n",
    "    \n",
    "    Parameters:\n",
    "    - batch_steps_file: CSV file containing batch steps data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the batch steps data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(batch_steps_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Batch steps data file {batch_steps_file} not found.\")\n",
    "        print(\"Please run the batch steps data generation script first.\")\n",
    "        return None\n",
    "\n",
    "def load_personnel_data(personnel_file=\"data/personnel.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated personnel data if available\n",
    "    \n",
    "    Parameters:\n",
    "    - personnel_file: CSV file containing personnel data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the personnel data or None if not available\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(personnel_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Note: Personnel data file {personnel_file} not found.\")\n",
    "        print(\"Batches will be generated with synthetic personnel IDs.\")\n",
    "        return None\n",
    "\n",
    "def generate_batches(recipes_df, equipment_df, personnel_df=None, num_batches=100, \n",
    "                    start_time=None, end_time=None, output_file=\"data/batches.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic batch data based on the recipes table\n",
    "    \n",
    "    Parameters:\n",
    "    - recipes_df: DataFrame containing recipes data\n",
    "    - equipment_df: DataFrame containing equipment data\n",
    "    - personnel_df: DataFrame containing personnel data (optional)\n",
    "    - num_batches: Number of batch records to generate\n",
    "    - start_time: Start time for batch history (defaults to 30 days ago)\n",
    "    - end_time: End time for batch history (defaults to now)\n",
    "    - output_file: CSV file to save the batches data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the generated batches data\n",
    "    \"\"\"\n",
    "    if recipes_df is None or len(recipes_df) == 0:\n",
    "        print(\"Error: No recipes data available.\")\n",
    "        return None\n",
    "        \n",
    "    if equipment_df is None or len(equipment_df) == 0:\n",
    "        print(\"Error: No equipment data available.\")\n",
    "        return None\n",
    "    \n",
    "    # Set default time range if not provided\n",
    "    if start_time is None:\n",
    "        start_time = datetime.now() - timedelta(days=30)\n",
    "    if end_time is None:\n",
    "        end_time = datetime.now()\n",
    "    \n",
    "    # Filter recipes to include only batch and discrete recipes\n",
    "    batch_recipes = recipes_df[recipes_df['recipe_type'].isin(['Batch', 'Discrete'])]\n",
    "    \n",
    "    if len(batch_recipes) == 0:\n",
    "        print(\"Warning: No batch recipes found. Using all available recipes.\")\n",
    "        batch_recipes = recipes_df\n",
    "    \n",
    "    # Generate work order IDs (to be used as foreign keys)\n",
    "    work_order_ids = [f\"WO-{uuid.uuid4().hex[:8].upper()}\" for _ in range(int(num_batches * 0.7))]\n",
    "    \n",
    "    # Generate product IDs if not present in recipes\n",
    "    product_ids = []\n",
    "    for _, recipe in batch_recipes.iterrows():\n",
    "        if pd.notna(recipe['product_id']) and recipe['product_id'] != \"\":\n",
    "            product_ids.append(recipe['product_id'])\n",
    "    \n",
    "    if not product_ids:\n",
    "        print(\"Warning: No product IDs found in recipes. Generating synthetic product IDs.\")\n",
    "        product_ids = [f\"PROD-{uuid.uuid4().hex[:8].upper()}\" for _ in range(20)]\n",
    "    \n",
    "    # Generate personnel IDs if not provided\n",
    "    if personnel_df is None or len(personnel_df) == 0:\n",
    "        print(\"Generating synthetic personnel IDs...\")\n",
    "        operator_ids = [f\"OP-{uuid.uuid4().hex[:8].upper()}\" for _ in range(15)]\n",
    "    else:\n",
    "        operator_ids = personnel_df['personnel_id'].unique().tolist()\n",
    "    \n",
    "    # Define batch statuses and their probabilities\n",
    "    batch_statuses = [\n",
    "        \"Planned\", \"In Progress\", \"Completed\", \"Aborted\", \"On Hold\", \"Rejected\"\n",
    "    ]\n",
    "    \n",
    "    status_weights = [0.15, 0.25, 0.45, 0.05, 0.05, 0.05]  # Higher weights for active and completed\n",
    "    \n",
    "    # Get possible equipment for batches\n",
    "    equipment_by_type = {}\n",
    "    for _, equip in equipment_df.iterrows():\n",
    "        eq_type = equip['equipment_type']\n",
    "        if eq_type not in equipment_by_type:\n",
    "            equipment_by_type[eq_type] = []\n",
    "        equipment_by_type[eq_type].append(equip['equipment_id'])\n",
    "    \n",
    "    # Generate batch data\n",
    "    data = {\n",
    "        \"batch_id\": [f\"BATCH-{uuid.uuid4().hex[:8].upper()}\" for _ in range(num_batches)],\n",
    "        \"recipe_id\": [],\n",
    "        \"work_order_id\": [],\n",
    "        \"product_id\": [],\n",
    "        \"batch_size\": [],\n",
    "        \"batch_size_unit\": [],\n",
    "        \"planned_start_time\": [],\n",
    "        \"actual_start_time\": [],\n",
    "        \"planned_end_time\": [],\n",
    "        \"actual_end_time\": [],\n",
    "        \"batch_status\": [],\n",
    "        \"equipment_id\": [],\n",
    "        \"operator_id\": [],\n",
    "        \"parent_batch_id\": []\n",
    "    }\n",
    "    \n",
    "    # Create a dictionary to track parent-child relationships\n",
    "    batch_hierarchy = {}\n",
    "    potential_parents = random.sample(data[\"batch_id\"], int(num_batches * 0.2))  # 20% can be parents\n",
    "    \n",
    "    # Units of measurement based on product type\n",
    "    units = [\"kg\", \"L\", \"units\", \"gal\", \"mÂ³\", \"tons\"]\n",
    "    \n",
    "    # Generate data for each batch\n",
    "    for i in range(num_batches):\n",
    "        batch_id = data[\"batch_id\"][i]\n",
    "        \n",
    "        # Select recipe (weighted toward active recipes)\n",
    "        active_recipes = batch_recipes[batch_recipes['status'] == 'Active']\n",
    "        if len(active_recipes) > 0 and random.random() < 0.8:  # 80% chance of using active recipe\n",
    "            recipe = active_recipes.sample(1).iloc[0]\n",
    "        else:\n",
    "            recipe = batch_recipes.sample(1).iloc[0]\n",
    "        \n",
    "        data[\"recipe_id\"].append(recipe['recipe_id'])\n",
    "        \n",
    "        # Assign work order (some batches may not be associated with a work order)\n",
    "        if random.random() < 0.9:  # 90% chance of having a work order\n",
    "            data[\"work_order_id\"].append(random.choice(work_order_ids))\n",
    "        else:\n",
    "            data[\"work_order_id\"].append(\"\")\n",
    "        \n",
    "        # Assign product (use product from recipe if available)\n",
    "        if pd.notna(recipe['product_id']) and recipe['product_id'] != \"\":\n",
    "            data[\"product_id\"].append(recipe['product_id'])\n",
    "        else:\n",
    "            data[\"product_id\"].append(random.choice(product_ids))\n",
    "        \n",
    "        # Generate batch size (random but realistic)\n",
    "        if recipe['recipe_type'] == 'Batch':\n",
    "            # Batch sizes tend to be in specific ranges depending on industry\n",
    "            size_options = [50, 100, 200, 500, 1000, 2000, 5000]\n",
    "            batch_size = random.choice(size_options) * random.uniform(0.8, 1.2)  # Add some variation\n",
    "            batch_size = round(batch_size, 1)\n",
    "        elif recipe['recipe_type'] == 'Discrete':\n",
    "            # Discrete manufacturing typically produces in lot sizes\n",
    "            size_options = [10, 25, 50, 100, 250, 500, 1000]\n",
    "            batch_size = random.choice(size_options)\n",
    "        else:\n",
    "            # Default size range for other recipe types\n",
    "            batch_size = random.randint(50, 5000)\n",
    "        \n",
    "        data[\"batch_size\"].append(batch_size)\n",
    "        \n",
    "        # Assign appropriate unit\n",
    "        unit = random.choice(units)\n",
    "        data[\"batch_size_unit\"].append(unit)\n",
    "        \n",
    "        # Generate batch timing\n",
    "        # Create a random start time within the specified range\n",
    "        time_range_minutes = int((end_time - start_time).total_seconds() / 60)\n",
    "        random_minutes_offset = random.randint(0, time_range_minutes)\n",
    "        planned_start_time = start_time + timedelta(minutes=random_minutes_offset)\n",
    "        \n",
    "        # Get expected duration from recipe\n",
    "        if pd.notna(recipe['expected_duration_minutes']):\n",
    "            expected_duration = float(recipe['expected_duration_minutes'])\n",
    "        else:\n",
    "            expected_duration = random.randint(60, 480)  # Default 1-8 hours\n",
    "        \n",
    "        # Add some variation to the duration for planned vs actual\n",
    "        planned_duration = expected_duration * random.uniform(0.9, 1.1)  # +/- 10%\n",
    "        planned_end_time = planned_start_time + timedelta(minutes=planned_duration)\n",
    "        \n",
    "        data[\"planned_start_time\"].append(planned_start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        data[\"planned_end_time\"].append(planned_end_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        \n",
    "        # Determine batch status (weighted random)\n",
    "        batch_status = random.choices(batch_statuses, weights=status_weights)[0]\n",
    "        data[\"batch_status\"].append(batch_status)\n",
    "        \n",
    "        # Set actual times based on status\n",
    "        if batch_status == \"Planned\":\n",
    "            # Hasn't started yet\n",
    "            data[\"actual_start_time\"].append(\"\")\n",
    "            data[\"actual_end_time\"].append(\"\")\n",
    "        elif batch_status == \"In Progress\":\n",
    "            # Started but not finished\n",
    "            # Actual start time might have some deviation from planned\n",
    "            start_deviation_minutes = random.randint(-60, 60)  # +/- 1 hour\n",
    "            actual_start_time = planned_start_time + timedelta(minutes=start_deviation_minutes)\n",
    "            \n",
    "            # Ensure actual start time is not in the future\n",
    "            if actual_start_time > end_time:\n",
    "                actual_start_time = end_time - timedelta(minutes=random.randint(0, 60))\n",
    "                \n",
    "            data[\"actual_start_time\"].append(actual_start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            data[\"actual_end_time\"].append(\"\")  # Still in progress\n",
    "        elif batch_status in [\"Completed\", \"Aborted\", \"Rejected\"]:\n",
    "            # Both started and finished\n",
    "            start_deviation_minutes = random.randint(-60, 60)  # +/- 1 hour\n",
    "            actual_start_time = planned_start_time + timedelta(minutes=start_deviation_minutes)\n",
    "            \n",
    "            # For actual duration, completed batches are typically close to planned\n",
    "            # Aborted/rejected batches may be shorter\n",
    "            if batch_status == \"Completed\":\n",
    "                actual_duration = planned_duration * random.uniform(0.9, 1.2)  # +/- 20%\n",
    "            else:\n",
    "                # Aborted/rejected batches often finish early\n",
    "                actual_duration = planned_duration * random.uniform(0.2, 0.8)  # 20-80% of planned\n",
    "            \n",
    "            actual_end_time = actual_start_time + timedelta(minutes=actual_duration)\n",
    "            \n",
    "            # Ensure times are within overall time range\n",
    "            if actual_start_time > end_time:\n",
    "                actual_start_time = end_time - timedelta(minutes=int(actual_duration) + 1)\n",
    "            if actual_end_time > end_time:\n",
    "                actual_end_time = end_time\n",
    "                \n",
    "            data[\"actual_start_time\"].append(actual_start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            data[\"actual_end_time\"].append(actual_end_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        else:  # On Hold\n",
    "            # Started but paused\n",
    "            start_deviation_minutes = random.randint(-60, 60)  # +/- 1 hour\n",
    "            actual_start_time = planned_start_time + timedelta(minutes=start_deviation_minutes)\n",
    "            \n",
    "            # Ensure actual start time is not in the future\n",
    "            if actual_start_time > end_time:\n",
    "                actual_start_time = end_time - timedelta(minutes=random.randint(0, 60))\n",
    "                \n",
    "            data[\"actual_start_time\"].append(actual_start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            data[\"actual_end_time\"].append(\"\")  # Not finished\n",
    "        \n",
    "        # Assign equipment based on recipe requirement\n",
    "        equipment_requirement = recipe['equipment_requirement']\n",
    "        if equipment_requirement in equipment_by_type:\n",
    "            # Use equipment of the required type\n",
    "            data[\"equipment_id\"].append(random.choice(equipment_by_type[equipment_requirement]))\n",
    "        elif len(equipment_by_type) > 0:\n",
    "            # Use any available equipment\n",
    "            random_type = random.choice(list(equipment_by_type.keys()))\n",
    "            data[\"equipment_id\"].append(random.choice(equipment_by_type[random_type]))\n",
    "        else:\n",
    "            data[\"equipment_id\"].append(\"\")\n",
    "        \n",
    "        # Assign operator\n",
    "        data[\"operator_id\"].append(random.choice(operator_ids))\n",
    "        \n",
    "        # Determine parent batch (if any)\n",
    "        # About 10% of batches will have a parent\n",
    "        if batch_id not in potential_parents and random.random() < 0.1:\n",
    "            # Ensure we don't create circular references\n",
    "            available_parents = [p for p in potential_parents if p != batch_id and p not in batch_hierarchy.get(batch_id, [])]\n",
    "            if available_parents:\n",
    "                parent_id = random.choice(available_parents)\n",
    "                data[\"parent_batch_id\"].append(parent_id)\n",
    "                \n",
    "                # Update hierarchy\n",
    "                if parent_id not in batch_hierarchy:\n",
    "                    batch_hierarchy[parent_id] = []\n",
    "                batch_hierarchy[parent_id].append(batch_id)\n",
    "            else:\n",
    "                data[\"parent_batch_id\"].append(\"\")\n",
    "        else:\n",
    "            data[\"parent_batch_id\"].append(\"\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Successfully generated {len(df)} batch records.\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_batch_execution(batches_df, batch_steps_df, equipment_df, personnel_df=None, \n",
    "                           output_file=\"data/batch_execution.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic batch step execution data based on the batches and batch steps tables\n",
    "    \n",
    "    Parameters:\n",
    "    - batches_df: DataFrame containing batches data\n",
    "    - batch_steps_df: DataFrame containing batch steps data\n",
    "    - equipment_df: DataFrame containing equipment data\n",
    "    - personnel_df: DataFrame containing personnel data (optional)\n",
    "    - output_file: CSV file to save the batch execution data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing a sample of the generated batch execution data\n",
    "    \"\"\"\n",
    "    if batches_df is None or len(batches_df) == 0:\n",
    "        print(\"Error: No batches data available.\")\n",
    "        return None\n",
    "        \n",
    "    if batch_steps_df is None or len(batch_steps_df) == 0:\n",
    "        print(\"Error: No batch steps data available.\")\n",
    "        return None\n",
    "        \n",
    "    if equipment_df is None or len(equipment_df) == 0:\n",
    "        print(\"Error: No equipment data available.\")\n",
    "        return None\n",
    "    \n",
    "    # Generate personnel IDs if not provided\n",
    "    if personnel_df is None or len(personnel_df) == 0:\n",
    "        print(\"Generating synthetic personnel IDs...\")\n",
    "        operator_ids = [f\"OP-{uuid.uuid4().hex[:8].upper()}\" for _ in range(15)]\n",
    "    else:\n",
    "        operator_ids = personnel_df['personnel_id'].unique().tolist()\n",
    "    \n",
    "    # Define step execution statuses\n",
    "    step_statuses = [\"Completed\", \"In Progress\", \"Pending\", \"Aborted\", \"Skipped\", \"Paused\"]\n",
    "    \n",
    "    # Prepare the output file with CSV writer for memory efficiency\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        fieldnames = [\n",
    "            'execution_id', 'batch_id', 'step_id', 'equipment_id', \n",
    "            'start_time', 'end_time', 'status', 'operator_id',\n",
    "            'actual_duration_minutes', 'deviation_reason', 'step_parameters'\n",
    "        ]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        print(f\"Generating batch step execution data...\")\n",
    "        execution_count = 0\n",
    "        \n",
    "        # Group batch steps by recipe\n",
    "        recipe_steps = {}\n",
    "        for _, step in batch_steps_df.iterrows():\n",
    "            recipe_id = step['recipe_id']\n",
    "            if recipe_id not in recipe_steps:\n",
    "                recipe_steps[recipe_id] = []\n",
    "            recipe_steps[recipe_id].append(step)\n",
    "        \n",
    "        # Process each batch\n",
    "        for _, batch in batches_df.iterrows():\n",
    "            batch_id = batch['batch_id']\n",
    "            recipe_id = batch['recipe_id']\n",
    "            batch_status = batch['batch_status']\n",
    "            \n",
    "            # Skip if no steps for this recipe\n",
    "            if recipe_id not in recipe_steps or not recipe_steps[recipe_id]:\n",
    "                continue\n",
    "            \n",
    "            # Get all steps for this recipe\n",
    "            steps = recipe_steps[recipe_id]\n",
    "            \n",
    "            # Sort steps by step number\n",
    "            steps = sorted(steps, key=lambda x: x['step_number'])\n",
    "            \n",
    "            # Get batch timing\n",
    "            if pd.notna(batch['planned_start_time']) and batch['planned_start_time']:\n",
    "                planned_start_time = datetime.strptime(batch['planned_start_time'], \"%Y-%m-%d %H:%M:%S\")\n",
    "            else:\n",
    "                planned_start_time = datetime.now() - timedelta(days=random.randint(1, 30))\n",
    "                \n",
    "            if pd.notna(batch['actual_start_time']) and batch['actual_start_time']:\n",
    "                batch_start_time = datetime.strptime(batch['actual_start_time'], \"%Y-%m-%d %H:%M:%S\")\n",
    "            else:\n",
    "                # For planned batches, use a future start time\n",
    "                batch_start_time = None\n",
    "                \n",
    "            if pd.notna(batch['actual_end_time']) and batch['actual_end_time']:\n",
    "                batch_end_time = datetime.strptime(batch['actual_end_time'], \"%Y-%m-%d %H:%M:%S\")\n",
    "            else:\n",
    "                batch_end_time = None\n",
    "            \n",
    "            # Get the equipment assigned to this batch\n",
    "            batch_equipment_id = batch['equipment_id'] if pd.notna(batch['equipment_id']) else None\n",
    "            \n",
    "            # Generate step execution records for this batch\n",
    "            current_time = batch_start_time if batch_start_time else planned_start_time\n",
    "            \n",
    "            for i, step in enumerate(steps):\n",
    "                step_id = step['step_id']\n",
    "                expected_duration = step['expected_duration_minutes']\n",
    "                \n",
    "                # Create a unique execution ID\n",
    "                execution_id = f\"EXEC-{uuid.uuid4().hex[:12].upper()}\"\n",
    "                \n",
    "                # Assign the same operator as the batch or a random one\n",
    "                if random.random() < 0.7:  # 70% chance of same operator as batch\n",
    "                    operator_id = batch['operator_id']\n",
    "                else:\n",
    "                    operator_id = random.choice(operator_ids)\n",
    "                \n",
    "                # Determine equipment (use batch equipment if possible)\n",
    "                if batch_equipment_id:\n",
    "                    equipment_id = batch_equipment_id\n",
    "                else:\n",
    "                    # Try to find equipment of required type\n",
    "                    equipment_type = step['equipment_requirement']\n",
    "                    matching_equipment = equipment_df[equipment_df['equipment_type'] == equipment_type]\n",
    "                    if len(matching_equipment) > 0:\n",
    "                        equipment_id = matching_equipment.sample(1).iloc[0]['equipment_id']\n",
    "                    else:\n",
    "                        equipment_id = equipment_df.sample(1).iloc[0]['equipment_id']\n",
    "                \n",
    "                # Determine step execution status based on batch status\n",
    "                if batch_status == \"Planned\":\n",
    "                    # All steps are pending for planned batches\n",
    "                    status = \"Pending\"\n",
    "                    start_time = \"\"\n",
    "                    end_time = \"\"\n",
    "                    actual_duration = 0\n",
    "                elif batch_status == \"In Progress\":\n",
    "                    # Steps before current point are completed, current step in progress, rest pending\n",
    "                    if i < len(steps) / 3:  # First third of steps\n",
    "                        status = \"Completed\"\n",
    "                        # Add some variation to actual duration\n",
    "                        actual_duration = expected_duration * random.uniform(0.8, 1.2)  # +/- 20%\n",
    "                        start_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        end_time = (current_time + timedelta(minutes=actual_duration)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        current_time = current_time + timedelta(minutes=actual_duration)\n",
    "                    elif i < len(steps) / 2:  # Middle\n",
    "                        status = \"In Progress\"\n",
    "                        start_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        end_time = \"\"\n",
    "                        actual_duration = (datetime.now() - current_time).total_seconds() / 60\n",
    "                    else:  # Remaining steps\n",
    "                        status = \"Pending\"\n",
    "                        start_time = \"\"\n",
    "                        end_time = \"\"\n",
    "                        actual_duration = 0\n",
    "                elif batch_status == \"Completed\":\n",
    "                    # All steps are completed for completed batches\n",
    "                    status = \"Completed\"\n",
    "                    # Add some variation to actual duration\n",
    "                    actual_duration = expected_duration * random.uniform(0.8, 1.2)  # +/- 20%\n",
    "                    start_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    end_time = (current_time + timedelta(minutes=actual_duration)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    current_time = current_time + timedelta(minutes=actual_duration)\n",
    "                elif batch_status == \"Aborted\":\n",
    "                    # Steps before abort point are completed, abort step is aborted, rest are skipped\n",
    "                    abort_point = random.randint(0, len(steps) - 1)\n",
    "                    if i < abort_point:\n",
    "                        status = \"Completed\"\n",
    "                        actual_duration = expected_duration * random.uniform(0.8, 1.2)\n",
    "                    elif i == abort_point:\n",
    "                        status = \"Aborted\"\n",
    "                        actual_duration = expected_duration * random.uniform(0.1, 0.5)  # Aborted early\n",
    "                    else:\n",
    "                        status = \"Skipped\"\n",
    "                        actual_duration = 0\n",
    "                        \n",
    "                    if i <= abort_point:\n",
    "                        start_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        end_time = (current_time + timedelta(minutes=actual_duration)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        current_time = current_time + timedelta(minutes=actual_duration)\n",
    "                    else:\n",
    "                        start_time = \"\"\n",
    "                        end_time = \"\"\n",
    "                elif batch_status == \"On Hold\":\n",
    "                    # Some steps completed, current step paused\n",
    "                    hold_point = random.randint(1, len(steps) - 1)\n",
    "                    if i < hold_point:\n",
    "                        status = \"Completed\"\n",
    "                        actual_duration = expected_duration * random.uniform(0.8, 1.2)\n",
    "                        start_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        end_time = (current_time + timedelta(minutes=actual_duration)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        current_time = current_time + timedelta(minutes=actual_duration)\n",
    "                    elif i == hold_point:\n",
    "                        status = \"Paused\"\n",
    "                        actual_duration = expected_duration * random.uniform(0.1, 0.8)  # Partially complete\n",
    "                        start_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        end_time = \"\"\n",
    "                    else:\n",
    "                        status = \"Pending\"\n",
    "                        actual_duration = 0\n",
    "                        start_time = \"\"\n",
    "                        end_time = \"\"\n",
    "                else:  # Rejected or other statuses\n",
    "                    # Similar to completed but some steps might have issues\n",
    "                    if random.random() < 0.8:  # 80% chance of normal completion\n",
    "                        status = \"Completed\"\n",
    "                    else:\n",
    "                        status = random.choice([\"Completed with Issues\", \"Reworked\", \"Verified\"])\n",
    "                        \n",
    "                    actual_duration = expected_duration * random.uniform(0.8, 1.2)\n",
    "                    start_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    end_time = (current_time + timedelta(minutes=actual_duration)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    current_time = current_time + timedelta(minutes=actual_duration)\n",
    "                \n",
    "                # Check if we've exceeded the batch end time (if known)\n",
    "                if batch_end_time and current_time > batch_end_time:\n",
    "                    # Adjust the end time and duration\n",
    "                    if status in [\"Completed\", \"Aborted\"]:\n",
    "                        end_time = batch_end_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        if start_time:\n",
    "                            start_datetime = datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\")\n",
    "                            actual_duration = (batch_end_time - start_datetime).total_seconds() / 60\n",
    "                \n",
    "                # Generate deviation reason (only for some steps)\n",
    "                if status in [\"Completed\", \"Aborted\", \"Paused\"] and abs(actual_duration - expected_duration) > expected_duration * 0.1:\n",
    "                    deviation_reasons = [\n",
    "                        \"Process variation\", \"Equipment issue\", \"Material quality\", \"Operator intervention\",\n",
    "                        \"Quality check\", \"Parameter adjustment\", \"Waiting for upstream process\",\n",
    "                        \"Environmental factors\", \"Power fluctuation\", \"Scheduled break\"\n",
    "                    ]\n",
    "                    deviation_reason = random.choice(deviation_reasons)\n",
    "                else:\n",
    "                    deviation_reason = \"\"\n",
    "                \n",
    "                # Generate step parameters (JSON string with key process parameters)\n",
    "                if status in [\"Completed\", \"In Progress\", \"Paused\", \"Aborted\"]:\n",
    "                    # Create parameter names based on step type\n",
    "                    step_type = step['step_type'] if 'step_type' in step else \"Standard\"\n",
    "                    \n",
    "                    if step_type == \"Material Handling\":\n",
    "                        param_names = [\"Material ID\", \"Quantity\", \"Container ID\", \"Verification\"]\n",
    "                    elif step_type == \"Process\":\n",
    "                        param_names = [\"Temperature\", \"Pressure\", \"Time\", \"Agitation\", \"pH\"]\n",
    "                    elif step_type == \"Quality\":\n",
    "                        param_names = [\"Sample ID\", \"Result\", \"Specification\", \"Deviation\"]\n",
    "                    elif step_type == \"Operation\":\n",
    "                        param_names = [\"Speed\", \"Duration\", \"Power\", \"Mode\"]\n",
    "                    elif step_type == \"Cleaning\":\n",
    "                        param_names = [\"Agent\", \"Concentration\", \"Temperature\", \"Time\"]\n",
    "                    else:\n",
    "                        param_names = [\"Parameter1\", \"Parameter2\", \"Parameter3\"]\n",
    "                    \n",
    "                    # Generate random parameter values\n",
    "                    params = {}\n",
    "                    for param in param_names:\n",
    "                        if \"Temperature\" in param:\n",
    "                            params[param] = f\"{random.uniform(20, 100):.1f} Â°C\"\n",
    "                        elif \"Pressure\" in param:\n",
    "                            params[param] = f\"{random.uniform(1, 10):.2f} bar\"\n",
    "                        elif \"Time\" in param:\n",
    "                            params[param] = f\"{random.randint(5, 120)} min\"\n",
    "                        elif \"Quantity\" in param:\n",
    "                            params[param] = f\"{random.uniform(10, 1000):.1f} kg\"\n",
    "                        elif \"Speed\" in param:\n",
    "                            params[param] = f\"{random.randint(50, 1000)} rpm\"\n",
    "                        elif \"Concentration\" in param:\n",
    "                            params[param] = f\"{random.uniform(1, 5):.2f} %\"\n",
    "                        elif \"pH\" in param:\n",
    "                            params[param] = f\"{random.uniform(2, 12):.1f}\"\n",
    "                        elif \"ID\" in param:\n",
    "                            params[param] = f\"{param[0]}-{random.randint(1000, 9999)}\"\n",
    "                        elif \"Result\" in param or \"Verification\" in param:\n",
    "                            params[param] = random.choice([\"Pass\", \"Within Spec\", \"Acceptable\"])\n",
    "                        elif \"Mode\" in param:\n",
    "                            params[param] = random.choice([\"Auto\", \"Manual\", \"Semi-Auto\"])\n",
    "                        elif \"Agent\" in param:\n",
    "                            params[param] = random.choice([\"CIP-100\", \"Caustic\", \"Acid\", \"Water\"])\n",
    "                        else:\n",
    "                            params[param] = f\"{random.uniform(0, 100):.2f}\"\n",
    "                    \n",
    "                    # Convert to JSON string\n",
    "                    import json\n",
    "                    step_parameters = json.dumps(params)\n",
    "                else:\n",
    "                    step_parameters = \"{}\"\n",
    "                \n",
    "                # Write the execution record to the CSV\n",
    "                writer.writerow({\n",
    "                    'execution_id': execution_id,\n",
    "                    'batch_id': batch_id,\n",
    "                    'step_id': step_id,\n",
    "                    'equipment_id': equipment_id,\n",
    "                    'start_time': start_time,\n",
    "                    'end_time': end_time,\n",
    "                    'status': status,\n",
    "                    'operator_id': operator_id,\n",
    "                    'actual_duration_minutes': round(actual_duration) if actual_duration else \"\",\n",
    "                    'deviation_reason': deviation_reason,\n",
    "                    'step_parameters': step_parameters\n",
    "                })\n",
    "                \n",
    "                execution_count += 1\n",
    "                if execution_count % 10000 == 0:\n",
    "                    print(f\"Generated {execution_count} batch execution records so far...\")\n",
    "    \n",
    "    print(f\"Successfully generated {execution_count} batch execution records.\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    # Return a sample of the data (first 1000 rows) for preview\n",
    "    return pd.read_csv(output_file, nrows=1000)\n",
    "\n",
    "def get_sample_statistics(batches_file, batch_execution_file):\n",
    "    \"\"\"\n",
    "    Get basic statistics about the generated batches and batch execution data\n",
    "    \n",
    "    Parameters:\n",
    "    - batches_file: CSV file containing the batches data\n",
    "    - batch_execution_file: CSV file containing the batch execution data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read batches data\n",
    "        batches_df = pd.read_csv(batches_file)\n",
    "        \n",
    "        print(\"\\nBatches Statistics:\")\n",
    "        print(f\"Total batches: {len(batches_df)}\")\n",
    "        \n",
    "        print(\"\\nBatch Status Distribution:\")\n",
    "        status_counts = batches_df['batch_status'].value_counts()\n",
    "        for status, count in status_counts.items():\n",
    "            print(f\"  {status}: {count} ({count/len(batches_df)*100:.1f}%)\")\n",
    "        \n",
    "        # Batch size statistics\n",
    "        print(\"\\nBatch Size Statistics:\")\n",
    "        print(f\"  Average batch size: {batches_df['batch_size'].mean():.1f}\")\n",
    "        print(f\"  Min batch size: {batches_df['batch_size'].min()}\")\n",
    "        print(f\"  Max batch size: {batches_df['batch_size'].max()}\")\n",
    "        \n",
    "        # Recipe usage\n",
    "        print(\"\\nRecipe Usage:\")\n",
    "        recipe_counts = batches_df['recipe_id'].value_counts().head(5)\n",
    "        for recipe_id, count in recipe_counts.items():\n",
    "            print(f\"  {recipe_id}: {count} batches\")\n",
    "        \n",
    "        # Parent-child relationships\n",
    "        parent_count = batches_df['parent_batch_id'].apply(lambda x: x != \"\").sum()\n",
    "        print(f\"\\nBatches with parent: {parent_count} ({parent_count/len(batches_df)*100:.1f}%)\")\n",
    "        \n",
    "        # Read batch execution data (sample for efficiency)\n",
    "        execution_df = pd.read_csv(batch_execution_file, nrows=10000)\n",
    "        \n",
    "        print(\"\\nBatch Execution Statistics (from sample):\")\n",
    "        print(f\"Sample size: {len(execution_df)} execution records\")\n",
    "        \n",
    "        print(\"\\nExecution Status Distribution:\")\n",
    "        exec_status_counts = execution_df['status'].value_counts()\n",
    "        for status, count in exec_status_counts.items():\n",
    "            print(f\"  {status}: {count} ({count/len(execution_df)*100:.1f}%)\")\n",
    "        \n",
    "        # Duration statistics (only for records with duration)\n",
    "        duration_df = execution_df[execution_df['actual_duration_minutes'] != \"\"]\n",
    "        if len(duration_df) > 0:\n",
    "            duration_df['actual_duration_minutes'] = duration_df['actual_duration_minutes'].astype(float)\n",
    "            print(\"\\nStep Duration Statistics:\")\n",
    "            print(f\"  Average step duration: {duration_df['actual_duration_minutes'].mean():.1f} minutes\")\n",
    "            print(f\"  Min step duration: {duration_df['actual_duration_minutes'].min()} minutes\")\n",
    "            print(f\"  Max step duration: {duration_df['actual_duration_minutes'].max()} minutes\")\n",
    "        \n",
    "        # Deviation reasons\n",
    "        deviation_count = execution_df['deviation_reason'].apply(lambda x: x != \"\").sum()\n",
    "        print(f\"\\nSteps with deviation reasons: {deviation_count} ({deviation_count/len(execution_df)*100:.1f}%)\")\n",
    "        \n",
    "        # Equipment usage\n",
    "        print(\"\\nEquipment Usage (top 5):\")\n",
    "        equipment_counts = execution_df['equipment_id'].value_counts().head(5)\n",
    "        for equipment_id, count in equipment_counts.items():\n",
    "            print(f\"  {equipment_id}: {count} steps\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting statistics: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Load required data\n",
    "    recipes_df = load_recipes_data()\n",
    "    equipment_df = load_equipment_data()\n",
    "    batch_steps_df = load_batch_steps_data()\n",
    "    personnel_df = load_personnel_data()\n",
    "    \n",
    "    if recipes_df is not None and equipment_df is not None:\n",
    "        # Generate batches data\n",
    "        batches_df = generate_batches(\n",
    "            recipes_df,\n",
    "            equipment_df,\n",
    "            personnel_df,\n",
    "            num_batches=100,  # Generate 100 batch records\n",
    "            output_file=\"data/batches.csv\"\n",
    "        )\n",
    "        \n",
    "        # Generate batch execution data if we have batches and steps\n",
    "        if batches_df is not None and batch_steps_df is not None:\n",
    "            sample_df = generate_batch_execution(\n",
    "                batches_df,\n",
    "                batch_steps_df,\n",
    "                equipment_df,\n",
    "                personnel_df,\n",
    "                output_file=\"data/batch_execution.csv\"\n",
    "            )\n",
    "            \n",
    "            # Display a sample of the data\n",
    "            if sample_df is not None:\n",
    "                print(\"\\nSample batch execution data (first 5 records):\")\n",
    "                print(sample_df.head())\n",
    "                \n",
    "                # Get statistics\n",
    "                get_sample_statistics(\"data/batches.csv\", \"data/batch_execution.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184ac0ee",
   "metadata": {},
   "source": [
    "Process Areas Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b36bbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Personnel data file data/personnel.csv not found.\n",
      "Process areas will be generated with synthetic personnel IDs.\n",
      "Successfully generated 5 facility records.\n",
      "Data saved to data/facilities.csv\n",
      "Generating synthetic personnel IDs...\n",
      "Successfully generated 37 process area records.\n",
      "Data saved to data/process_areas.csv\n",
      "Successfully updated 150 equipment records with area assignments.\n",
      "Updated data saved to data/equipment_updated.csv\n",
      "\n",
      "Facilities Statistics:\n",
      "Total facilities: 5\n",
      "\n",
      "Facility Type Distribution:\n",
      "  Distribution Center: 2 (40.0%)\n",
      "  Assembly Plant: 2 (40.0%)\n",
      "  Warehouse: 1 (20.0%)\n",
      "\n",
      "Facility Status Distribution:\n",
      "  Operational: 4 (80.0%)\n",
      "  Reduced Capacity: 1 (20.0%)\n",
      "\n",
      "Facilities with parent: 0 (0.0%)\n",
      "\n",
      "Process Areas Statistics:\n",
      "Total process areas: 37\n",
      "\n",
      "Areas per Facility:\n",
      "  Average: 7.4\n",
      "  Minimum: 2\n",
      "  Maximum: 15\n",
      "\n",
      "Area Type Distribution:\n",
      "  Quality Control: 5 (13.5%)\n",
      "  Granulation: 4 (10.8%)\n",
      "  Tableting: 4 (10.8%)\n",
      "  Utilities: 4 (10.8%)\n",
      "  Filling: 3 (8.1%)\n",
      "  Maintenance: 3 (8.1%)\n",
      "  Production: 3 (8.1%)\n",
      "  Packaging: 3 (8.1%)\n",
      "  Filtration: 2 (5.4%)\n",
      "  Drying: 2 (5.4%)\n",
      "\n",
      "Environmental Classification Distribution:\n",
      "  Controlled Humidity: 14 (37.8%)\n",
      "  Controlled Temperature: 9 (24.3%)\n",
      "  General Manufacturing: 8 (21.6%)\n",
      "  Clean Room Class 100,000: 4 (10.8%)\n",
      "  High Temperature: 1 (2.7%)\n",
      "  Clean Room Class 10,000: 1 (2.7%)\n",
      "\n",
      "Areas with parent: 9 (24.3%)\n",
      "\n",
      "Equipment Distribution:\n",
      "Total equipment: 150\n",
      "  Areas with equipment: 34 of 37\n",
      "  Average equipment per area: 4.4\n",
      "  Minimum equipment per area: 1\n",
      "  Maximum equipment per area: 12\n",
      "\n",
      "Sample facilities data (first 3 records):\n",
      "    facility_id                   facility_name        facility_type  \\\n",
      "0  FAC-2B0BE767  Charlotte Industrial Warehouse            Warehouse   \n",
      "1  FAC-E91E49C1  Columbus Distribution Center 2  Distribution Center   \n",
      "2  FAC-80A0687B     Philadelphia Assembly Plant       Assembly Plant   \n",
      "\n",
      "                                address manager_id  \\\n",
      "0     6095 Technology Dr, Charlotte, NC              \n",
      "1      8600 Technology Dr, Columbus, OH              \n",
      "2  8114 Enterprise Rd, Philadelphia, PA              \n",
      "\n",
      "                                     operating_hours            status  \\\n",
      "0  Three Shifts: 06:00-14:00, 14:00-22:00, 22:00-...       Operational   \n",
      "1                               Mon-Fri: 06:00-22:00       Operational   \n",
      "2  Three Shifts: 06:00-14:00, 14:00-22:00, 22:00-...  Reduced Capacity   \n",
      "\n",
      "  parent_facility_id  \n",
      "0                     \n",
      "1                     \n",
      "2                     \n",
      "\n",
      "Sample process areas data (first 3 records):\n",
      "         area_id           area_name   facility_id        area_type  \\\n",
      "0  AREA-4EF43D2E      Filling Area 1  FAC-2B0BE767          Filling   \n",
      "1  AREA-83BFA135   Quality Control 2  FAC-2B0BE767  Quality Control   \n",
      "2  AREA-2A728FB1  Granulation Area 3  FAC-2B0BE767      Granulation   \n",
      "\n",
      "  area_manager_id environmental_classification parent_area_id  \n",
      "0   PERS-803DA54D          Controlled Humidity                 \n",
      "1   PERS-803DA54D     Clean Room Class 100,000  AREA-4EF43D2E  \n",
      "2   PERS-4D331A0E        General Manufacturing                 \n",
      "\n",
      "Sample updated equipment data (first 3 records):\n",
      "  equipment_id               equipment_name     equipment_type        area_id  \\\n",
      "0  EQ-9A644928  Falling Film Evaporator 715         Evaporator  AREA-4EF43D2E   \n",
      "1  EQ-8953C760              Case Packer 398  Packaging Machine  AREA-22738870   \n",
      "2  EQ-9F6621AF             Vacuum Dryer 654              Dryer  AREA-F99F9A6D   \n",
      "\n",
      "  manufacturer model_number serial_number installation_date  \\\n",
      "0        Eaton   EAT-EV9056      SN516340        2023-10-15   \n",
      "1     Yokogawa   YOK-PA6751      SN932707        2024-04-01   \n",
      "2    Flowserve   FLO-DR5102      SN615451        2016-12-31   \n",
      "\n",
      "  last_maintenance_date next_maintenance_date equipment_status  \\\n",
      "0            2025-02-01            2025-12-25          Running   \n",
      "1            2025-07-11            2025-10-22          Running   \n",
      "2            2025-05-14            2025-08-21          Running   \n",
      "\n",
      "  parent_equipment_id  \n",
      "0                 NaN  \n",
      "1                 NaN  \n",
      "2         EQ-6809A01E  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "\n",
    "def load_equipment_data(equipment_file=\"data/equipment.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated equipment data\n",
    "    \n",
    "    Parameters:\n",
    "    - equipment_file: CSV file containing equipment data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the equipment data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(equipment_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Equipment data file {equipment_file} not found.\")\n",
    "        print(\"Please run the equipment data generation script first.\")\n",
    "        return None\n",
    "\n",
    "def load_personnel_data(personnel_file=\"data/personnel.csv\"):\n",
    "    \"\"\"\n",
    "    Load the previously generated personnel data if available\n",
    "    \n",
    "    Parameters:\n",
    "    - personnel_file: CSV file containing personnel data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the personnel data or None if not available\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(personnel_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Note: Personnel data file {personnel_file} not found.\")\n",
    "        print(\"Process areas will be generated with synthetic personnel IDs.\")\n",
    "        return None\n",
    "\n",
    "def generate_facilities_data(num_facilities=5, output_file=\"data/facilities.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic data for the Facilities table\n",
    "    \n",
    "    Parameters:\n",
    "    - num_facilities: Number of facility records to generate\n",
    "    - output_file: CSV file to save the data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the generated facilities data\n",
    "    \"\"\"\n",
    "    # Define possible values for categorical fields\n",
    "    facility_types = [\"Manufacturing Plant\", \"Warehouse\", \"Distribution Center\", \n",
    "                    \"R&D Center\", \"Processing Plant\", \"Assembly Plant\", \"Packaging Facility\"]\n",
    "    \n",
    "    facility_statuses = [\"Operational\", \"Under Maintenance\", \"Expanding\", \"Reduced Capacity\", \"Shutdown\"]\n",
    "    status_weights = [0.8, 0.1, 0.05, 0.03, 0.02]  # Mostly operational\n",
    "    \n",
    "    operating_hours = [\"24/7\", \"Mon-Fri: 06:00-22:00\", \"Mon-Sat: 08:00-20:00\", \n",
    "                      \"Three Shifts: 06:00-14:00, 14:00-22:00, 22:00-06:00\",\n",
    "                      \"Two Shifts: 07:00-19:00, 19:00-07:00\"]\n",
    "    \n",
    "    # City locations (for address generation)\n",
    "    cities = [\"Chicago, IL\", \"Houston, TX\", \"Phoenix, AZ\", \"Philadelphia, PA\", \n",
    "             \"San Antonio, TX\", \"San Diego, CA\", \"Dallas, TX\", \"San Jose, CA\",\n",
    "             \"Indianapolis, IN\", \"Jacksonville, FL\", \"Columbus, OH\", \"Charlotte, NC\"]\n",
    "    \n",
    "    # Generate facility data\n",
    "    data = {\n",
    "        \"facility_id\": [f\"FAC-{uuid.uuid4().hex[:8].upper()}\" for _ in range(num_facilities)],\n",
    "        \"facility_name\": [],\n",
    "        \"facility_type\": [],\n",
    "        \"address\": [],\n",
    "        \"manager_id\": [],  # Will be filled in later if personnel data is available\n",
    "        \"operating_hours\": [],\n",
    "        \"status\": [],\n",
    "        \"parent_facility_id\": []\n",
    "    }\n",
    "    \n",
    "    # Create a hierarchy with some facilities having parent facilities\n",
    "    # First, identify which facilities will be parents (about 20%)\n",
    "    potential_parents = []\n",
    "    if num_facilities > 1:\n",
    "        potential_parents = random.sample(data[\"facility_id\"], max(1, int(num_facilities * 0.2)))\n",
    "    \n",
    "    # Generate facility names and other data\n",
    "    for i in range(num_facilities):\n",
    "        facility_id = data[\"facility_id\"][i]\n",
    "        \n",
    "        # Generate facility type\n",
    "        facility_type = random.choice(facility_types)\n",
    "        data[\"facility_type\"].append(facility_type)\n",
    "        \n",
    "        # Generate facility name (based on type and location)\n",
    "        city = random.choice(cities)\n",
    "        city_short = city.split(',')[0]  # Just the city name, not state\n",
    "        \n",
    "        name_formats = [\n",
    "            f\"{city_short} {facility_type}\",\n",
    "            f\"{city_short} {facility_type} {i+1}\",\n",
    "            f\"Plant {i+1} - {city_short}\",\n",
    "            f\"{random.choice(['North', 'South', 'East', 'West'])} {city_short} {facility_type}\",\n",
    "            f\"{city_short} Industrial {facility_type}\"\n",
    "        ]\n",
    "        \n",
    "        facility_name = random.choice(name_formats)\n",
    "        data[\"facility_name\"].append(facility_name)\n",
    "        \n",
    "        # Generate address\n",
    "        street_number = random.randint(100, 9999)\n",
    "        street_names = [\"Main St\", \"Industrial Pkwy\", \"Commerce Dr\", \"Manufacturing Blvd\", \n",
    "                        \"Technology Dr\", \"Innovation Way\", \"Production Ave\", \"Enterprise Rd\"]\n",
    "        street_name = random.choice(street_names)\n",
    "        address = f\"{street_number} {street_name}, {city}\"\n",
    "        data[\"address\"].append(address)\n",
    "        \n",
    "        # Operating hours\n",
    "        data[\"operating_hours\"].append(random.choice(operating_hours))\n",
    "        \n",
    "        # Status (weighted random)\n",
    "        data[\"status\"].append(random.choices(facility_statuses, weights=status_weights)[0])\n",
    "        \n",
    "        # Manager ID (will be filled in later)\n",
    "        data[\"manager_id\"].append(\"\")\n",
    "        \n",
    "        # Determine parent facility (if any)\n",
    "        # Top-level facilities have no parent\n",
    "        if facility_id not in potential_parents and len(potential_parents) > 0 and random.random() < 0.3:\n",
    "            # 30% chance of having a parent if not a potential parent itself\n",
    "            parent_id = random.choice(potential_parents)\n",
    "            data[\"parent_facility_id\"].append(parent_id)\n",
    "        else:\n",
    "            data[\"parent_facility_id\"].append(\"\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Successfully generated {len(df)} facility records.\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_process_areas(equipment_df, facilities_df, personnel_df=None, output_file=\"data/process_areas.csv\"):\n",
    "    \"\"\"\n",
    "    Generate synthetic data for the ProcessAreas table from ISA-95 Level 2.\n",
    "    \n",
    "    Parameters:\n",
    "    - equipment_df: DataFrame containing equipment data\n",
    "    - facilities_df: DataFrame containing facilities data\n",
    "    - personnel_df: DataFrame containing personnel data (optional)\n",
    "    - output_file: CSV file to save the data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the generated process areas data\n",
    "    \"\"\"\n",
    "    if equipment_df is None or len(equipment_df) == 0:\n",
    "        print(\"Error: No equipment data available.\")\n",
    "        return None\n",
    "        \n",
    "    if facilities_df is None or len(facilities_df) == 0:\n",
    "        print(\"Error: No facilities data available.\")\n",
    "        return None\n",
    "    \n",
    "    # Define possible values for categorical fields\n",
    "    area_types = [\n",
    "        \"Production\", \"Packaging\", \"Filling\", \"Mixing\", \"Reaction\", \"Distillation\",\n",
    "        \"Fermentation\", \"Filtration\", \"Drying\", \"Granulation\", \"Tableting\", \"Assembly\",\n",
    "        \"Testing\", \"Quality Control\", \"Warehousing\", \"Utilities\", \"Maintenance\"\n",
    "    ]\n",
    "    \n",
    "    environmental_classifications = [\n",
    "        \"General Manufacturing\", \"Clean Room Class 100,000\", \"Clean Room Class 10,000\", \n",
    "        \"Clean Room Class 1,000\", \"Clean Room Class 100\", \"Controlled Humidity\",\n",
    "        \"Controlled Temperature\", \"Explosion Proof\", \"Corrosive Environment\", \n",
    "        \"High Temperature\", \"Cold Storage\", \"Sterile\", \"Aseptic\", \"Hazardous Material\"\n",
    "    ]\n",
    "    \n",
    "    # Group equipment by facility\n",
    "    # Since we don't have facility_id in equipment directly, we'll assign equipment to facilities\n",
    "    equipment_by_facility = {}\n",
    "    for facility_id in facilities_df['facility_id']:\n",
    "        equipment_by_facility[facility_id] = []\n",
    "    \n",
    "    # Randomly assign equipment to facilities\n",
    "    for _, equipment in equipment_df.iterrows():\n",
    "        facility_id = random.choice(facilities_df['facility_id'].tolist())\n",
    "        equipment_by_facility[facility_id].append(equipment['equipment_id'])\n",
    "    \n",
    "    # Generate personnel IDs if not provided\n",
    "    if personnel_df is None or len(personnel_df) == 0:\n",
    "        print(\"Generating synthetic personnel IDs...\")\n",
    "        area_manager_ids = [f\"PERS-{uuid.uuid4().hex[:8].upper()}\" for _ in range(20)]\n",
    "    else:\n",
    "        area_manager_ids = personnel_df['personnel_id'].unique().tolist()\n",
    "    \n",
    "    # Now generate process areas for each facility\n",
    "    data = {\n",
    "        \"area_id\": [],\n",
    "        \"area_name\": [],\n",
    "        \"facility_id\": [],\n",
    "        \"area_type\": [],\n",
    "        \"area_manager_id\": [],\n",
    "        \"environmental_classification\": [],\n",
    "        \"parent_area_id\": []\n",
    "    }\n",
    "    \n",
    "    # Track areas for potential parent-child relationships\n",
    "    all_areas = []\n",
    "    \n",
    "    # Process each facility\n",
    "    for _, facility in facilities_df.iterrows():\n",
    "        facility_id = facility['facility_id']\n",
    "        facility_type = facility['facility_type']\n",
    "        \n",
    "        # Determine how many areas to create for this facility (based on facility type)\n",
    "        if \"Plant\" in facility_type or \"Manufacturing\" in facility_type:\n",
    "            num_areas = random.randint(5, 15)  # Larger facilities have more areas\n",
    "        else:\n",
    "            num_areas = random.randint(2, 8)  # Smaller facilities have fewer areas\n",
    "        \n",
    "        # Get equipment assigned to this facility\n",
    "        facility_equipment = equipment_by_facility.get(facility_id, [])\n",
    "        \n",
    "        # Generate area data for this facility\n",
    "        facility_areas = []\n",
    "        \n",
    "        for i in range(num_areas):\n",
    "            area_id = f\"AREA-{uuid.uuid4().hex[:8].upper()}\"\n",
    "            all_areas.append(area_id)\n",
    "            facility_areas.append(area_id)\n",
    "            \n",
    "            data[\"area_id\"].append(area_id)\n",
    "            data[\"facility_id\"].append(facility_id)\n",
    "            \n",
    "            # Determine area type (with some weighting toward production areas)\n",
    "            if random.random() < 0.6:  # 60% chance of production-related area\n",
    "                area_type = random.choice([\n",
    "                    \"Production\", \"Packaging\", \"Filling\", \"Mixing\", \"Reaction\", \n",
    "                    \"Distillation\", \"Fermentation\", \"Filtration\", \"Drying\", \n",
    "                    \"Granulation\", \"Tableting\", \"Assembly\"\n",
    "                ])\n",
    "            else:\n",
    "                area_type = random.choice([\n",
    "                    \"Testing\", \"Quality Control\", \"Warehousing\", \"Utilities\", \"Maintenance\"\n",
    "                ])\n",
    "            \n",
    "            data[\"area_type\"].append(area_type)\n",
    "            \n",
    "            # Generate area name\n",
    "            area_name = f\"{area_type} Area {i+1}\" if random.random() < 0.5 else f\"{area_type} {i+1}\"\n",
    "            data[\"area_name\"].append(area_name)\n",
    "            \n",
    "            # Assign area manager\n",
    "            data[\"area_manager_id\"].append(random.choice(area_manager_ids))\n",
    "            \n",
    "            # Determine environmental classification (based on area type)\n",
    "            if area_type in [\"Quality Control\", \"Testing\", \"Production\", \"Filling\"]:\n",
    "                # More likely to have controlled environments\n",
    "                env_class = random.choice([\n",
    "                    \"Clean Room Class 100,000\", \"Clean Room Class 10,000\", \n",
    "                    \"Controlled Humidity\", \"Controlled Temperature\"\n",
    "                ])\n",
    "            elif area_type in [\"Reaction\", \"Distillation\", \"Fermentation\"]:\n",
    "                # More likely to have hazardous environments\n",
    "                env_class = random.choice([\n",
    "                    \"Explosion Proof\", \"Corrosive Environment\", \"High Temperature\", \n",
    "                    \"Hazardous Material\"\n",
    "                ])\n",
    "            elif area_type == \"Packaging\":\n",
    "                # Packaging areas often have controlled conditions\n",
    "                env_class = random.choice([\n",
    "                    \"Controlled Humidity\", \"Controlled Temperature\", \"General Manufacturing\"\n",
    "                ])\n",
    "            else:\n",
    "                # Other areas more likely to be general\n",
    "                env_class = random.choice([\n",
    "                    \"General Manufacturing\", \"Controlled Humidity\", \"Controlled Temperature\"\n",
    "                ])\n",
    "            \n",
    "            data[\"environmental_classification\"].append(env_class)\n",
    "            \n",
    "            # Initially no parent area\n",
    "            data[\"parent_area_id\"].append(\"\")\n",
    "        \n",
    "        # Now create hierarchical relationships within this facility's areas\n",
    "        # About 40% of areas will have a parent\n",
    "        if len(facility_areas) > 1:\n",
    "            potential_parents = random.sample(facility_areas, max(1, int(len(facility_areas) * 0.3)))\n",
    "            \n",
    "            for i, area_id in enumerate(facility_areas):\n",
    "                # Skip areas that are potential parents\n",
    "                if area_id in potential_parents:\n",
    "                    continue\n",
    "                \n",
    "                # 40% chance of having a parent\n",
    "                if random.random() < 0.4:\n",
    "                    parent_id = random.choice(potential_parents)\n",
    "                    \n",
    "                    # Update the parent_area_id (need to find the index in the main data list)\n",
    "                    idx = data[\"area_id\"].index(area_id)\n",
    "                    data[\"parent_area_id\"][idx] = parent_id\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Successfully generated {len(df)} process area records.\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def update_equipment_with_areas(equipment_df, process_areas_df, output_file=\"data/equipment_updated.csv\"):\n",
    "    \"\"\"\n",
    "    Update equipment data with area assignments\n",
    "    \n",
    "    Parameters:\n",
    "    - equipment_df: DataFrame containing equipment data\n",
    "    - process_areas_df: DataFrame containing process areas data\n",
    "    - output_file: CSV file to save the updated equipment data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the updated equipment data\n",
    "    \"\"\"\n",
    "    if equipment_df is None or len(equipment_df) == 0:\n",
    "        print(\"Error: No equipment data available.\")\n",
    "        return None\n",
    "        \n",
    "    if process_areas_df is None or len(process_areas_df) == 0:\n",
    "        print(\"Error: No process areas data available.\")\n",
    "        return None\n",
    "    \n",
    "    # Create a copy of the equipment data\n",
    "    updated_equipment = equipment_df.copy()\n",
    "    \n",
    "    # Check if area_id column already exists\n",
    "    if 'area_id' not in updated_equipment.columns:\n",
    "        updated_equipment['area_id'] = \"\"\n",
    "    \n",
    "    # Group areas by facility\n",
    "    areas_by_facility = {}\n",
    "    for _, area in process_areas_df.iterrows():\n",
    "        facility_id = area['facility_id']\n",
    "        if facility_id not in areas_by_facility:\n",
    "            areas_by_facility[facility_id] = []\n",
    "        areas_by_facility[facility_id].append(area['area_id'])\n",
    "    \n",
    "    # Group equipment by facility\n",
    "    equipment_by_facility = {}\n",
    "    for i, equipment in updated_equipment.iterrows():\n",
    "        # Since we don't have facility_id in equipment, assign randomly\n",
    "        facility_id = random.choice(list(areas_by_facility.keys()))\n",
    "        if facility_id not in equipment_by_facility:\n",
    "            equipment_by_facility[facility_id] = []\n",
    "        equipment_by_facility[facility_id].append(i)\n",
    "    \n",
    "    # Assign process areas to equipment\n",
    "    for facility_id, equipment_indices in equipment_by_facility.items():\n",
    "        facility_areas = areas_by_facility.get(facility_id, [])\n",
    "        \n",
    "        if not facility_areas:\n",
    "            continue\n",
    "        \n",
    "        # Distribute equipment across areas\n",
    "        for idx in equipment_indices:\n",
    "            area_id = random.choice(facility_areas)\n",
    "            updated_equipment.at[idx, 'area_id'] = area_id\n",
    "    \n",
    "    # Save updated equipment data\n",
    "    updated_equipment.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Successfully updated {len(updated_equipment)} equipment records with area assignments.\")\n",
    "    print(f\"Updated data saved to {output_file}\")\n",
    "    \n",
    "    return updated_equipment\n",
    "\n",
    "def display_statistics(facilities_df, process_areas_df, updated_equipment_df=None):\n",
    "    \"\"\"\n",
    "    Display basic statistics about the generated data\n",
    "    \n",
    "    Parameters:\n",
    "    - facilities_df: DataFrame containing facilities data\n",
    "    - process_areas_df: DataFrame containing process areas data\n",
    "    - updated_equipment_df: DataFrame containing updated equipment data (optional)\n",
    "    \"\"\"\n",
    "    if facilities_df is None or len(facilities_df) == 0:\n",
    "        print(\"No facilities data to analyze.\")\n",
    "        return\n",
    "        \n",
    "    if process_areas_df is None or len(process_areas_df) == 0:\n",
    "        print(\"No process areas data to analyze.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nFacilities Statistics:\")\n",
    "    print(f\"Total facilities: {len(facilities_df)}\")\n",
    "    \n",
    "    print(\"\\nFacility Type Distribution:\")\n",
    "    type_counts = facilities_df['facility_type'].value_counts()\n",
    "    for facility_type, count in type_counts.items():\n",
    "        print(f\"  {facility_type}: {count} ({count/len(facilities_df)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nFacility Status Distribution:\")\n",
    "    status_counts = facilities_df['status'].value_counts()\n",
    "    for status, count in status_counts.items():\n",
    "        print(f\"  {status}: {count} ({count/len(facilities_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Parent-child relationships\n",
    "    parent_count = facilities_df['parent_facility_id'].apply(lambda x: x != \"\").sum()\n",
    "    print(f\"\\nFacilities with parent: {parent_count} ({parent_count/len(facilities_df)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nProcess Areas Statistics:\")\n",
    "    print(f\"Total process areas: {len(process_areas_df)}\")\n",
    "    \n",
    "    print(\"\\nAreas per Facility:\")\n",
    "    areas_per_facility = process_areas_df.groupby('facility_id').size()\n",
    "    print(f\"  Average: {areas_per_facility.mean():.1f}\")\n",
    "    print(f\"  Minimum: {areas_per_facility.min()}\")\n",
    "    print(f\"  Maximum: {areas_per_facility.max()}\")\n",
    "    \n",
    "    print(\"\\nArea Type Distribution:\")\n",
    "    area_type_counts = process_areas_df['area_type'].value_counts().head(10)\n",
    "    for area_type, count in area_type_counts.items():\n",
    "        print(f\"  {area_type}: {count} ({count/len(process_areas_df)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nEnvironmental Classification Distribution:\")\n",
    "    env_counts = process_areas_df['environmental_classification'].value_counts().head(10)\n",
    "    for env_class, count in env_counts.items():\n",
    "        print(f\"  {env_class}: {count} ({count/len(process_areas_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Parent-child relationships\n",
    "    area_parent_count = process_areas_df['parent_area_id'].apply(lambda x: x != \"\").sum()\n",
    "    print(f\"\\nAreas with parent: {area_parent_count} ({area_parent_count/len(process_areas_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Equipment distribution (if updated equipment data is available)\n",
    "    if updated_equipment_df is not None and len(updated_equipment_df) > 0:\n",
    "        print(\"\\nEquipment Distribution:\")\n",
    "        print(f\"Total equipment: {len(updated_equipment_df)}\")\n",
    "        \n",
    "        # Count equipment per area\n",
    "        equipment_per_area = updated_equipment_df.groupby('area_id').size()\n",
    "        if len(equipment_per_area) > 0:\n",
    "            print(f\"  Areas with equipment: {len(equipment_per_area)} of {len(process_areas_df)}\")\n",
    "            print(f\"  Average equipment per area: {equipment_per_area.mean():.1f}\")\n",
    "            print(f\"  Minimum equipment per area: {equipment_per_area.min()}\")\n",
    "            print(f\"  Maximum equipment per area: {equipment_per_area.max()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Load required data\n",
    "    equipment_df = load_equipment_data()\n",
    "    personnel_df = load_personnel_data()\n",
    "    \n",
    "    if equipment_df is not None:\n",
    "        # First, generate facilities data\n",
    "        facilities_df = generate_facilities_data(\n",
    "            num_facilities=5,  # Generate 5 facility records\n",
    "            output_file=\"data/facilities.csv\"\n",
    "        )\n",
    "        \n",
    "        if facilities_df is not None:\n",
    "            # Generate process areas data\n",
    "            process_areas_df = generate_process_areas(\n",
    "                equipment_df,\n",
    "                facilities_df,\n",
    "                personnel_df,\n",
    "                output_file=\"data/process_areas.csv\"\n",
    "            )\n",
    "            \n",
    "            if process_areas_df is not None:\n",
    "                # Update equipment with area assignments\n",
    "                updated_equipment_df = update_equipment_with_areas(\n",
    "                    equipment_df,\n",
    "                    process_areas_df,\n",
    "                    output_file=\"data/equipment_updated.csv\"\n",
    "                )\n",
    "                \n",
    "                # Display statistics\n",
    "                display_statistics(facilities_df, process_areas_df, updated_equipment_df)\n",
    "                \n",
    "                # Display sample data\n",
    "                print(\"\\nSample facilities data (first 3 records):\")\n",
    "                print(facilities_df.head(3))\n",
    "                \n",
    "                print(\"\\nSample process areas data (first 3 records):\")\n",
    "                print(process_areas_df.head(3))\n",
    "                \n",
    "                if updated_equipment_df is not None:\n",
    "                    print(\"\\nSample updated equipment data (first 3 records):\")\n",
    "                    print(updated_equipment_df.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
