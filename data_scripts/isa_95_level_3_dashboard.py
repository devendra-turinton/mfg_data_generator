import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import dash
from dash import dcc, html, Input, Output
import dash_bootstrap_components as dbc
from datetime import datetime, timedelta
import os
import warnings
warnings.filterwarnings('ignore')

# Function to load all datasets
def load_all_data():
    """Load all available ISA-95 Level 3 datasets and return a dictionary of dataframes"""
    data_path = "data/"
    datasets = {}
    
    # List of all potential Level 3 datasets generated by the ISA95Level3DataGenerator
    dataset_files = [
        "work_orders.csv",
        "material_lots.csv",
        "material_transactions.csv",
        "material_consumption.csv",
        "quality_tests.csv",
        "quality_events.csv",
        "resource_utilization.csv",
        "maintenance_activities.csv",
        "production_performance.csv",
        # Additional files that might be referenced from Level 2
        "equipment.csv",
        "facilities.csv",
        "process_areas.csv",
        "batches.csv"
    ]
    
    # Load each dataset if it exists
    for file in dataset_files:
        file_path = os.path.join(data_path, file)
        if os.path.exists(file_path):
            try:
                # Extract dataset name from filename (remove .csv extension)
                dataset_name = file.split('.')[0]
                # Load the dataset
                df = pd.read_csv(file_path)
                # Convert date columns to datetime
                for col in df.columns:
                    if 'date' in col.lower() or 'time' in col.lower() or col == 'timestamp':
                        try:
                            df[col] = pd.to_datetime(df[col], errors='coerce')
                        except:
                            pass  # Skip if conversion fails
                # Store in dictionary
                datasets[dataset_name] = df
                print(f"Loaded {dataset_name} with {len(df)} records")
            except Exception as e:
                print(f"Error loading {file}: {e}")
    
    return datasets

# Calculate key metrics for dashboard
def calculate_metrics(datasets):
    """Calculate key metrics from the datasets for the dashboard"""
    metrics = {}
    
    # 1. Work Order Metrics
    if 'work_orders' in datasets:
        work_orders = datasets['work_orders']
        
        # Work order status distribution
        if 'status' in work_orders.columns:
            wo_status = work_orders['status'].value_counts().reset_index()
            wo_status.columns = ['status', 'count']
            metrics['work_order_status'] = wo_status
            
            # Active work orders count
            active_statuses = ['In Progress', 'Released', 'Planned', 'On Hold', 'Rework']
            active_wo_count = work_orders[work_orders['status'].isin(active_statuses)].shape[0]
            metrics['active_work_orders'] = active_wo_count
        
        # Work order timing metrics
        if 'planned_start_date' in work_orders.columns and 'actual_start_date' in work_orders.columns:
            # Filter work orders that have both planned and actual dates
            filtered_wo = work_orders.dropna(subset=['planned_start_date', 'actual_start_date'])
            
            if len(filtered_wo) > 0:
                # Convert to datetime if not already
                if not pd.api.types.is_datetime64_dtype(filtered_wo['planned_start_date']):
                    filtered_wo['planned_start_date'] = pd.to_datetime(filtered_wo['planned_start_date'])
                if not pd.api.types.is_datetime64_dtype(filtered_wo['actual_start_date']):
                    filtered_wo['actual_start_date'] = pd.to_datetime(filtered_wo['actual_start_date'])
                
                # Calculate start date variance (negative means early start, positive means late start)
                filtered_wo['start_variance_days'] = (filtered_wo['actual_start_date'] - 
                                                     filtered_wo['planned_start_date']).dt.total_seconds() / (24 * 3600)
                avg_start_variance = filtered_wo['start_variance_days'].mean()
                metrics['avg_start_variance_days'] = avg_start_variance
                
                # Create start variance distribution
                start_variance_dist = filtered_wo.groupby(pd.cut(filtered_wo['start_variance_days'], 
                                                                bins=[-10, -5, -2, 0, 2, 5, 10])).size().reset_index()
                start_variance_dist.columns = ['variance_range', 'count']
                metrics['start_variance_distribution'] = start_variance_dist
        
        if 'planned_end_date' in work_orders.columns and 'actual_end_date' in work_orders.columns:
            # Filter work orders that have both planned and actual dates
            filtered_wo = work_orders.dropna(subset=['planned_end_date', 'actual_end_date'])
            
            if len(filtered_wo) > 0:
                # Convert to datetime if not already
                if not pd.api.types.is_datetime64_dtype(filtered_wo['planned_end_date']):
                    filtered_wo['planned_end_date'] = pd.to_datetime(filtered_wo['planned_end_date'])
                if not pd.api.types.is_datetime64_dtype(filtered_wo['actual_end_date']):
                    filtered_wo['actual_end_date'] = pd.to_datetime(filtered_wo['actual_end_date'])
                
                # Calculate completion variance (negative means early completion, positive means late completion)
                filtered_wo['completion_variance_days'] = (filtered_wo['actual_end_date'] - 
                                                         filtered_wo['planned_end_date']).dt.total_seconds() / (24 * 3600)
                avg_completion_variance = filtered_wo['completion_variance_days'].mean()
                metrics['avg_completion_variance_days'] = avg_completion_variance
                
                # On-time completion rate
                on_time_wo = filtered_wo[filtered_wo['completion_variance_days'] <= 0]
                on_time_rate = len(on_time_wo) / len(filtered_wo) * 100
                metrics['on_time_completion_rate'] = on_time_rate
        
        # Work order by type
        if 'work_order_type' in work_orders.columns:
            wo_type = work_orders['work_order_type'].value_counts().reset_index()
            wo_type.columns = ['type', 'count']
            metrics['work_order_by_type'] = wo_type
    
    # 2. Material Lots Metrics
    if 'material_lots' in datasets:
        material_lots = datasets['material_lots']
        
        # Material status distribution
        if 'status' in material_lots.columns:
            material_status = material_lots['status'].value_counts().reset_index()
            material_status.columns = ['status', 'count']
            metrics['material_status'] = material_status
            
            # Active materials count
            active_statuses = ['Active', 'Reserved', 'In Process']
            active_material_count = material_lots[material_lots['status'].isin(active_statuses)].shape[0]
            metrics['active_materials'] = active_material_count
        
        # Material shelf life metrics
        if 'remaining_days' in material_lots.columns:
            # Calculate average remaining shelf life
            material_lots['remaining_days_num'] = pd.to_numeric(material_lots['remaining_days'], errors='coerce')
            avg_remaining_days = material_lots['remaining_days_num'].mean()
            metrics['avg_remaining_shelf_life'] = avg_remaining_days
            
            # Calculate expiring soon count (less than 30 days)
            expiring_soon = material_lots[material_lots['remaining_days_num'] < 30].shape[0]
            metrics['expiring_soon_count'] = expiring_soon
        
        # Material cost metrics
        if 'cost_per_unit' in material_lots.columns and 'lot_quantity' in material_lots.columns:
            # Calculate total inventory value
            material_lots['cost_per_unit_num'] = pd.to_numeric(material_lots['cost_per_unit'], errors='coerce')
            material_lots['lot_quantity_num'] = pd.to_numeric(material_lots['lot_quantity'], errors='coerce')
            material_lots['total_value'] = material_lots['cost_per_unit_num'] * material_lots['lot_quantity_num']
            total_inventory_value = material_lots['total_value'].sum()
            metrics['total_inventory_value'] = total_inventory_value
    
    # 3. Quality Metrics
    if 'quality_tests' in datasets:
        quality_tests = datasets['quality_tests']
        
        # Test result distribution
        if 'test_result' in quality_tests.columns:
            test_result = quality_tests['test_result'].value_counts().reset_index()
            test_result.columns = ['result', 'count']
            metrics['test_result'] = test_result
            
            # Calculate pass rate
            if 'Pass' in test_result['result'].values:
                pass_count = test_result[test_result['result'] == 'Pass']['count'].iloc[0]
                pass_rate = pass_count / quality_tests.shape[0] * 100
                metrics['quality_pass_rate'] = pass_rate
        
        # Test type distribution
        if 'test_type' in quality_tests.columns:
            test_type = quality_tests['test_type'].value_counts().reset_index()
            test_type.columns = ['type', 'count']
            metrics['test_type'] = test_type
    
    if 'quality_events' in datasets:
        quality_events = datasets['quality_events']
        
        # Event type distribution
        if 'event_type' in quality_events.columns:
            event_type = quality_events['event_type'].value_counts().reset_index()
            event_type.columns = ['type', 'count']
            metrics['quality_event_type'] = event_type
        
        # Event severity distribution
        if 'severity' in quality_events.columns:
            severity = quality_events['severity'].value_counts().reset_index()
            severity.columns = ['severity', 'count']
            metrics['quality_event_severity'] = severity
            
        # Event status distribution
        if 'status' in quality_events.columns:
            event_status = quality_events['status'].value_counts().reset_index()
            event_status.columns = ['status', 'count']
            metrics['quality_event_status'] = event_status
            
            # Open events count
            open_statuses = ['Open', 'Under Investigation', 'Corrective Action']
            open_events = quality_events[quality_events['status'].isin(open_statuses)].shape[0]
            metrics['open_quality_events'] = open_events
    
    # 4. Production Performance Metrics
    if 'production_performance' in datasets:
        performance = datasets['production_performance']
        
        # OEE (Overall Equipment Effectiveness) metrics
        oee_components = ['availability_percent', 'performance_percent', 'quality_percent', 'oee_percent']
        
        for component in oee_components:
            if component in performance.columns:
                performance[f'{component}_num'] = pd.to_numeric(performance[component], errors='coerce')
                avg_value = performance[f'{component}_num'].mean()
                metrics[f'avg_{component}'] = avg_value
        
        # Production counts
        if 'production_count' in performance.columns and 'reject_count' in performance.columns:
            performance['production_count_num'] = pd.to_numeric(performance['production_count'], errors='coerce')
            performance['reject_count_num'] = pd.to_numeric(performance['reject_count'], errors='coerce')
            
            total_production = performance['production_count_num'].sum()
            total_rejects = performance['reject_count_num'].sum()
            
            metrics['total_production'] = total_production
            metrics['total_rejects'] = total_rejects
            
            if total_production > 0:
                yield_rate = (total_production - total_rejects) / total_production * 100
                metrics['first_pass_yield'] = yield_rate
        
        # Equipment performance comparison
        if 'equipment_id' in performance.columns and 'oee_percent' in performance.columns:
            equipment_oee = performance.groupby('equipment_id')['oee_percent_num'].mean().reset_index()
            metrics['equipment_oee'] = equipment_oee
    
    # 5. Resource Utilization Metrics
    if 'resource_utilization' in datasets:
        resource_util = datasets['resource_utilization']
        
        # Resource type distribution
        if 'resource_type' in resource_util.columns:
            resource_type = resource_util['resource_type'].value_counts().reset_index()
            resource_type.columns = ['type', 'count']
            metrics['resource_type'] = resource_type
        
        # Average utilization by resource type
        if 'resource_type' in resource_util.columns and 'utilization_percentage' in resource_util.columns:
            resource_util['utilization_percentage_num'] = pd.to_numeric(resource_util['utilization_percentage'], errors='coerce')
            avg_util_by_type = resource_util.groupby('resource_type')['utilization_percentage_num'].mean().reset_index()
            metrics['avg_utilization_by_type'] = avg_util_by_type
            
        # Downtime analysis
        if 'downtime' in resource_util.columns and 'downtime' in resource_util.columns:
            resource_util['downtime_num'] = pd.to_numeric(resource_util['downtime'], errors='coerce')
            total_downtime = resource_util['downtime_num'].sum()
            metrics['total_resource_downtime'] = total_downtime
            
            # Downtime reasons
            if 'downtime_reason' in resource_util.columns:
                downtime_reasons = resource_util.groupby('downtime_reason')['downtime_num'].sum().reset_index()
                downtime_reasons = downtime_reasons.sort_values('downtime_num', ascending=False).head(10)
                metrics['downtime_reasons'] = downtime_reasons
    
    # 6. Maintenance Metrics
    if 'maintenance_activities' in datasets:
        maintenance = datasets['maintenance_activities']
        
        # Maintenance type distribution
        if 'activity_type' in maintenance.columns:
            activity_type = maintenance['activity_type'].value_counts().reset_index()
            activity_type.columns = ['type', 'count']
            metrics['maintenance_by_type'] = activity_type
        
        # Maintenance status distribution
        if 'status' in maintenance.columns:
            maintenance_status = maintenance['status'].value_counts().reset_index()
            maintenance_status.columns = ['status', 'count']
            metrics['maintenance_status'] = maintenance_status
            
            # Active maintenance count
            active_statuses = ['Planned', 'Scheduled', 'In Progress']
            active_maintenance = maintenance[maintenance['status'].isin(active_statuses)].shape[0]
            metrics['active_maintenance'] = active_maintenance
        
        # Maintenance downtime metrics
        if 'actual_downtime_minutes' in maintenance.columns:
            maintenance['downtime_hours'] = pd.to_numeric(maintenance['actual_downtime_minutes'], 
                                                        errors='coerce') / 60
            total_downtime = maintenance['downtime_hours'].sum()
            metrics['total_maintenance_downtime'] = total_downtime
    
    # 7. Material Transactions Metrics
    if 'material_transactions' in datasets:
        transactions = datasets['material_transactions']
        
        # Transaction type distribution
        if 'transaction_type' in transactions.columns:
            transaction_type = transactions['transaction_type'].value_counts().reset_index()
            transaction_type.columns = ['type', 'count']
            metrics['transaction_by_type'] = transaction_type
        
        # Transaction quantity analysis
        if 'quantity' in transactions.columns:
            transactions['quantity_num'] = pd.to_numeric(transactions['quantity'], errors='coerce')
            total_transaction_qty = transactions['quantity_num'].sum()
            metrics['total_transaction_quantity'] = total_transaction_qty
            
            # Transactions by month
            if 'month' in transactions.columns:
                transactions_by_month = transactions.groupby('month')['quantity_num'].sum().reset_index()
                metrics['transactions_by_month'] = transactions_by_month
    
    # 8. Material Consumption Metrics
    if 'material_consumption' in datasets:
        consumption = datasets['material_consumption']
        
        # Consumption variance analysis
        if 'consumption_variance' in consumption.columns:
            consumption['variance_num'] = pd.to_numeric(consumption['consumption_variance'], errors='coerce')
            avg_variance = consumption['variance_num'].mean()
            metrics['avg_consumption_variance'] = avg_variance
            
            # Variance by equipment
            if 'equipment_id' in consumption.columns:
                variance_by_equip = consumption.groupby('equipment_id')['variance_num'].mean().reset_index()
                metrics['variance_by_equipment'] = variance_by_equip
        
        # Consumption by month
        if 'month' in consumption.columns and 'quantity' in consumption.columns:
            consumption['quantity_num'] = pd.to_numeric(consumption['quantity'], errors='coerce')
            consumption_by_month = consumption.groupby('month')['quantity_num'].sum().reset_index()
            metrics['consumption_by_month'] = consumption_by_month
    
    return metrics

# Set up the Dash application
def create_dashboard(datasets, metrics):
    """Create a Dash dashboard to visualize the metrics"""
    # Initialize the Dash app
    app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])
    
    # Define the layout
    app.layout = dbc.Container([
        # Header
        dbc.Row([
            dbc.Col([
                html.H1("Manufacturing Operations Management Dashboard", className="text-center mb-4"),
                html.H5("ISA-95 Level 3 Manufacturing Operations", className="text-center text-muted mb-5")
            ], width=12)
        ]),
        
        # Top metrics cards - Row 1
        dbc.Row([
            # Active Work Orders
            dbc.Col([
                dbc.Card([
                    dbc.CardBody([
                        html.H5("Active Work Orders", className="card-title"),
                        html.H3(f"{metrics.get('active_work_orders', 0)}", className="card-text text-primary")
                    ])
                ], className="mb-4 text-center")
            ], width=3),
            
            # Active Materials
            dbc.Col([
                dbc.Card([
                    dbc.CardBody([
                        html.H5("Active Material Lots", className="card-title"),
                        html.H3(f"{metrics.get('active_materials', 0)}", className="card-text text-primary")
                    ])
                ], className="mb-4 text-center")
            ], width=3),
            
            # Open Quality Events
            dbc.Col([
                dbc.Card([
                    dbc.CardBody([
                        html.H5("Open Quality Events", className="card-title"),
                        html.H3(f"{metrics.get('open_quality_events', 0)}", className="card-text text-primary")
                    ])
                ], className="mb-4 text-center")
            ], width=3),
            
            # Overall OEE
            dbc.Col([
                dbc.Card([
                    dbc.CardBody([
                        html.H5("Overall OEE", className="card-title"),
                        html.H3(f"{metrics.get('avg_oee_percent', 0):.1f}%", className="card-text text-primary")
                    ])
                ], className="mb-4 text-center")
            ], width=3)
        ]),
        
        # Top metrics cards - Row 2
        dbc.Row([
            # On-Time Completion Rate
            dbc.Col([
                dbc.Card([
                    dbc.CardBody([
                        html.H5("On-Time Completion", className="card-title"),
                        html.H3(f"{metrics.get('on_time_completion_rate', 0):.1f}%", className="card-text text-primary")
                    ])
                ], className="mb-4 text-center")
            ], width=3),
            
            # Quality Pass Rate
            dbc.Col([
                dbc.Card([
                    dbc.CardBody([
                        html.H5("Quality Pass Rate", className="card-title"),
                        html.H3(f"{metrics.get('quality_pass_rate', 0):.1f}%", className="card-text text-primary")
                    ])
                ], className="mb-4 text-center")
            ], width=3),
            
            # First Pass Yield
            dbc.Col([
                dbc.Card([
                    dbc.CardBody([
                        html.H5("First Pass Yield", className="card-title"),
                        html.H3(f"{metrics.get('first_pass_yield', 0):.1f}%", className="card-text text-primary")
                    ])
                ], className="mb-4 text-center")
            ], width=3),
            
            # Total Production
            dbc.Col([
                dbc.Card([
                    dbc.CardBody([
                        html.H5("Total Production", className="card-title"),
                        html.H3(f"{metrics.get('total_production', 0):,.0f} units", className="card-text text-primary")
                    ])
                ], className="mb-4 text-center")
            ], width=3)
        ]),
        
        # Work Order Analysis
        dbc.Row([
            # Work Order Status
            dbc.Col([
                dbc.Card([
                    dbc.CardHeader("Work Order Status Distribution"),
                    dbc.CardBody(
                        dcc.Graph(id='work-order-status', figure=create_work_order_status_chart(metrics))
                    )
                ], className="mb-4")
            ], width=6),
            
            # Work Order by Type
            dbc.Col([
                dbc.Card([
                    dbc.CardHeader("Work Orders by Type"),
                    dbc.CardBody(
                        dcc.Graph(id='work-order-type', figure=create_work_order_type_chart(metrics))
                    )
                ], className="mb-4")
            ], width=6)
        ]),
        
        # OEE and Quality Analysis
        dbc.Row([
            # OEE Components
            dbc.Col([
                dbc.Card([
                    dbc.CardHeader("OEE Components Analysis"),
                    dbc.CardBody(
                        dcc.Graph(id='oee-components', figure=create_oee_components_chart(metrics))
                    )
                ], className="mb-4")
            ], width=6),
            
            # Quality Test Results
            dbc.Col([
                dbc.Card([
                    dbc.CardHeader("Quality Test Results"),
                    dbc.CardBody(
                        dcc.Graph(id='quality-test-status', figure=create_quality_test_chart(metrics))
                    )
                ], className="mb-4")
            ], width=6)
        ]),
        
        # Material and Maintenance Analysis
        dbc.Row([
            # Material Status
            dbc.Col([
                dbc.Card([
                    dbc.CardHeader("Material Status Distribution"),
                    dbc.CardBody(
                        dcc.Graph(id='material-status', figure=create_material_status_chart(metrics))
                    )
                ], className="mb-4")
            ], width=6),
            
            # Maintenance by Type
            dbc.Col([
                dbc.Card([
                    dbc.CardHeader("Maintenance Activities by Type"),
                    dbc.CardBody(
                        dcc.Graph(id='maintenance-type', figure=create_maintenance_type_chart(metrics))
                    )
                ], className="mb-4")
            ], width=6)
        ]),
        
        # Resource Utilization and Material Consumption
        dbc.Row([
            # Resource Utilization by Type
            dbc.Col([
                dbc.Card([
                    dbc.CardHeader("Resource Utilization by Type"),
                    dbc.CardBody(
                        dcc.Graph(id='resource-utilization', figure=create_resource_utilization_chart(metrics))
                    )
                ], className="mb-4")
            ], width=6),
            
            # Material Consumption Variance
            dbc.Col([
                dbc.Card([
                    dbc.CardHeader("Material Consumption Variance"),
                    dbc.CardBody(
                        dcc.Graph(id='consumption-variance', figure=create_consumption_variance_chart(metrics))
                    )
                ], className="mb-4")
            ], width=6)
        ]),
        
        # Quality Events and Transactions
        dbc.Row([
            # Quality Event Severity
            dbc.Col([
                dbc.Card([
                    dbc.CardHeader("Quality Events by Severity"),
                    dbc.CardBody(
                        dcc.Graph(id='quality-severity', figure=create_quality_severity_chart(metrics))
                    )
                ], className="mb-4")
            ], width=6),
            
            # Material Transactions by Type
            dbc.Col([
                dbc.Card([
                    dbc.CardHeader("Material Transactions by Type"),
                    dbc.CardBody(
                        dcc.Graph(id='transaction-type', figure=create_transaction_type_chart(metrics))
                    )
                ], className="mb-4")
            ], width=6)
        ]),
        
        # Footer
        dbc.Row([
            dbc.Col([
                html.Hr(),
                html.P("ISA-95 Level 3 Manufacturing Operations Management Dashboard", className="text-center text-muted")
            ], width=12)
        ])
    ], fluid=True)
    
    return app

# Chart creation functions
def create_work_order_status_chart(metrics):
    """Create work order status distribution chart"""
    if 'work_order_status' not in metrics:
        return go.Figure()
    
    wo_status = metrics['work_order_status']
    
    fig = px.pie(wo_status, values='count', names='status', 
                 color_discrete_sequence=px.colors.qualitative.Plotly)
    
    fig.update_layout(
        title="Work Order Status Distribution",
        legend=dict(orientation="h", yanchor="bottom", y=-0.1),
        margin=dict(t=40, b=40, l=10, r=10),
        height=400
    )
    
    return fig

def create_work_order_type_chart(metrics):
    """Create work order by type chart"""
    if 'work_order_by_type' not in metrics:
        return go.Figure()
    
    wo_type = metrics['work_order_by_type']
    
    fig = px.bar(wo_type, x='type', y='count', 
                 color='type', color_discrete_sequence=px.colors.qualitative.Plotly,
                 labels={'type': 'Work Order Type', 'count': 'Count'})
    
    fig.update_layout(
        title="Work Orders by Type",
        xaxis_title="Work Order Type",
        yaxis_title="Count",
        legend_title="Type",
        margin=dict(t=40, b=40, l=10, r=10),
        height=400,
        showlegend=False
    )
    
    return fig

def create_oee_components_chart(metrics):
    """Create OEE components chart"""
    components = ['avg_availability_percent', 'avg_performance_percent', 'avg_quality_percent', 'avg_oee_percent']
    labels = ['Availability', 'Performance', 'Quality', 'OEE']
    
    values = []
    for component in components:
        if component in metrics:
            values.append(metrics[component])
        else:
            values.append(0)
    
    fig = go.Figure()
    
    # Add bars for each component
    fig.add_trace(go.Bar(
        x=labels,
        y=values,
        marker_color=['#1F77B4', '#FF7F0E', '#2CA02C', '#D62728'],
        text=[f"{v:.1f}%" for v in values],
        textposition='auto'
    ))
    
    # Add target line at 85%
    fig.add_shape(
        type="line",
        x0=-0.5,
        y0=85,
        x1=3.5,
        y1=85,
        line=dict(
            color="red",
            width=2,
            dash="dash",
        )
    )
    
    fig.add_annotation(
        x=3.2,
        y=87,
        text="Target: 85%",
        showarrow=False,
        font=dict(color="red")
    )
    
    fig.update_layout(
        title="OEE Components Analysis",
        xaxis_title="Component",
        yaxis_title="Percentage (%)",
        yaxis=dict(range=[0, 100]),
        margin=dict(t=40, b=40, l=10, r=10),
        height=400
    )
    
    return fig

def create_quality_test_chart(metrics):
    """Create quality test result chart"""
    if 'test_result' not in metrics:
        return go.Figure()
    
    test_result = metrics['test_result']
    
    colors = {'Pass': '#2CA02C', 'Fail': '#D62728'}
    color_sequence = [colors.get(result, '#1F77B4') for result in test_result['result']]
    
    fig = px.bar(test_result, x='result', y='count',
                 color='result', color_discrete_sequence=color_sequence,
                 labels={'result': 'Test Result', 'count': 'Count'})
    
    # Calculate pass rate
    total_tests = test_result['count'].sum()
    pass_count = test_result[test_result['result'] == 'Pass']['count'].sum() if 'Pass' in test_result['result'].values else 0
    pass_rate = pass_count / total_tests * 100 if total_tests > 0 else 0
    
    fig.add_annotation(
        x=0.5,
        y=0.9,
        xref="paper",
        yref="paper",
        text=f"Pass Rate: {pass_rate:.1f}%",
        showarrow=False,
        font=dict(size=14, color="#2CA02C"),
        align="center",
        bgcolor="rgba(255, 255, 255, 0.8)",
        bordercolor="#2CA02C",
        borderwidth=2,
        borderpad=4
    )
    
    fig.update_layout(
        title="Quality Test Results",
        xaxis_title="Test Result",
        yaxis_title="Count",
        margin=dict(t=40, b=40, l=10, r=10),
        height=400,
        showlegend=False
    )
    
    return fig

def create_material_status_chart(metrics):
    """Create material status chart"""
    if 'material_status' not in metrics:
        return go.Figure()
    
    material_status = metrics['material_status']
    
    fig = px.pie(material_status, values='count', names='status',
                 color_discrete_sequence=px.colors.qualitative.Plotly)
    
    fig.update_layout(
        title="Material Status Distribution",
        legend=dict(orientation="h", yanchor="bottom", y=-0.1),
        margin=dict(t=40, b=40, l=10, r=10),
        height=400
    )
    
    return fig

def create_maintenance_type_chart(metrics):
    """Create maintenance by type chart"""
    if 'maintenance_by_type' not in metrics:
        return go.Figure()
    
    maintenance_type = metrics['maintenance_by_type']
    
    fig = px.bar(maintenance_type, x='type', y='count',
                 color='type', color_discrete_sequence=px.colors.qualitative.Plotly,
                 labels={'type': 'Maintenance Type', 'count': 'Count'})
    
    fig.update_layout(
        title="Maintenance Activities by Type",
        xaxis_title="Maintenance Type",
        yaxis_title="Count",
        margin=dict(t=40, b=40, l=10, r=10),
        height=400,
        showlegend=False
    )
    
    return fig

def create_resource_utilization_chart(metrics):
    """Create resource utilization by type chart"""
    if 'avg_utilization_by_type' not in metrics:
        return go.Figure()
    
    util_by_type = metrics['avg_utilization_by_type']
    
    fig = px.bar(util_by_type, x='resource_type', y='utilization_percentage_num',
                 color='resource_type', color_discrete_sequence=px.colors.qualitative.Plotly,
                 labels={'resource_type': 'Resource Type', 'utilization_percentage_num': 'Avg. Utilization %'})
    
    fig.update_layout(
        title="Average Resource Utilization by Type",
        xaxis_title="Resource Type",
        yaxis_title="Average Utilization (%)",
        margin=dict(t=40, b=40, l=10, r=10),
        height=400,
        showlegend=False
    )
    
    return fig

def create_consumption_variance_chart(metrics):
    """Create material consumption variance chart"""
    if 'variance_by_equipment' not in metrics:
        return go.Figure()
    
    variance_by_equip = metrics['variance_by_equipment']
    
    # Limit to top 10 equipment by absolute variance
    variance_by_equip['abs_variance'] = abs(variance_by_equip['variance_num'])
    top_variance = variance_by_equip.sort_values('abs_variance', ascending=False).head(10)
    
    # Color code: red for negative variance (under consumption), green for positive (over consumption)
    colors = ['#D62728' if v < 0 else '#2CA02C' for v in top_variance['variance_num']]
    
    fig = px.bar(top_variance, x='equipment_id', y='variance_num',
                 labels={'equipment_id': 'Equipment ID', 'variance_num': 'Avg. Consumption Variance'})
    
    fig.update_traces(marker_color=colors)
    
    fig.update_layout(
        title="Average Material Consumption Variance by Equipment",
        xaxis_title="Equipment ID",
        yaxis_title="Average Variance",
        margin=dict(t=40, b=40, l=10, r=10),
        height=400
    )
    
    return fig

def create_quality_severity_chart(metrics):
    """Create quality event severity chart"""
    if 'quality_event_severity' not in metrics:
        return go.Figure()
    
    severity = metrics['quality_event_severity']
    
    # Sort by severity
    severity['severity_num'] = pd.to_numeric(severity['severity'], errors='coerce')
    severity = severity.sort_values('severity_num')
    
    # Create a color scale: higher severity = darker red
    max_severity = severity['severity_num'].max()
    colors = [f'rgba(214, 39, 40, {s/max_severity})' for s in severity['severity_num']]
    
    fig = px.bar(severity, x='severity', y='count',
                 labels={'severity': 'Severity Level', 'count': 'Number of Events'})
    
    fig.update_traces(marker_color=colors)
    
    fig.update_layout(
        title="Quality Events by Severity Level",
        xaxis_title="Severity Level",
        yaxis_title="Number of Events",
        margin=dict(t=40, b=40, l=10, r=10),
        height=400
    )
    
    return fig

def create_transaction_type_chart(metrics):
    """Create material transaction by type chart"""
    if 'transaction_by_type' not in metrics:
        return go.Figure()
    
    transaction_type = metrics['transaction_by_type']
    
    fig = px.pie(transaction_type, values='count', names='type',
                 color_discrete_sequence=px.colors.qualitative.Plotly)
    
    fig.update_layout(
        title="Material Transactions by Type",
        legend=dict(orientation="h", yanchor="bottom", y=-0.1),
        margin=dict(t=40, b=40, l=10, r=10),
        height=400
    )
    
    return fig

# Main function to run the dashboard
def main():
    # Load all data
    print("Loading data...")
    datasets = load_all_data()
    
    # Calculate metrics
    print("Calculating metrics...")
    metrics = calculate_metrics(datasets)
    
    # Create and run the dashboard
    print("Creating dashboard...")
    app = create_dashboard(datasets, metrics)
    
    print("Dashboard ready! Running on http://127.0.0.1:8062/")
    app.run_server(debug=True, port=8062)

if __name__ == "__main__":
    main()