{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8606d7",
   "metadata": {},
   "source": [
    "ISA-95 Level 4 Business Planning & Logistics DASHBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029b89df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3837/835536626.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded products with 100 records\n",
      "Loaded materials with 150 records\n",
      "Loaded bill_of_materials with 680 records\n",
      "Loaded customers with 100 records\n",
      "Loaded customer_orders with 300 records\n",
      "Loaded order_lines with 1726 records\n",
      "Loaded suppliers with 50 records\n",
      "Loaded purchase_orders with 200 records\n",
      "Loaded purchase_order_lines with 1005 records\n",
      "Loaded facilities with 15 records\n",
      "Loaded storage_locations with 444 records\n",
      "Loaded shifts with 58 records\n",
      "Loaded inventory_transactions with 1000 records\n",
      "Loaded material_lots with 200 records\n",
      "Loaded material_consumption with 300 records\n",
      "Loaded production_schedules with 20 records\n",
      "Loaded scheduled_production with 264 records\n",
      "Loaded costs with 500 records\n",
      "Loaded cogs with 200 records\n",
      "Calculating metrics...\n",
      "Creating dashboard...\n",
      "Dashboard ready! Running on http://127.0.0.1:8050/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff57962ff50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, State, dash_table\n",
    "import dash_bootstrap_components as dbc\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Function to load all datasets\n",
    "def load_all_data():\n",
    "    \"\"\"Load all available ISA-95 Level 4 datasets and return a dictionary of dataframes\"\"\"\n",
    "    data_path = \"data/\"\n",
    "    datasets = {}\n",
    "    \n",
    "    # List of all potential datasets\n",
    "    dataset_files = [\n",
    "        \"products.csv\",\n",
    "        \"materials.csv\",\n",
    "        \"bill_of_materials.csv\",\n",
    "        \"customers.csv\",\n",
    "        \"customer_orders.csv\",\n",
    "        \"order_lines.csv\",\n",
    "        \"suppliers.csv\",\n",
    "        \"purchase_orders.csv\",\n",
    "        \"purchase_order_lines.csv\",\n",
    "        \"facilities.csv\",\n",
    "        \"storage_locations.csv\",\n",
    "        \"shifts.csv\",\n",
    "        \"inventory_transactions.csv\",\n",
    "        \"material_lots.csv\",\n",
    "        \"material_consumption.csv\",\n",
    "        \"production_schedules.csv\",\n",
    "        \"scheduled_production.csv\",\n",
    "        \"costs.csv\",\n",
    "        \"cogs.csv\"\n",
    "    ]\n",
    "    \n",
    "    # Load each dataset if it exists\n",
    "    for file in dataset_files:\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                # Extract dataset name from filename (remove .csv extension)\n",
    "                dataset_name = file.split('.')[0]\n",
    "                # Load the dataset\n",
    "                df = pd.read_csv(file_path)\n",
    "                # Convert date columns to datetime\n",
    "                for col in df.columns:\n",
    "                    if 'date' in col.lower() or 'time' in col.lower() or col == 'timestamp':\n",
    "                        try:\n",
    "                            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "                        except:\n",
    "                            pass  # Skip if conversion fails\n",
    "                # Store in dictionary\n",
    "                datasets[dataset_name] = df\n",
    "                print(f\"Loaded {dataset_name} with {len(df)} records\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file}: {e}\")\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# Calculate key metrics for dashboard\n",
    "def calculate_metrics(datasets):\n",
    "    \"\"\"Calculate key metrics from the datasets for the dashboard\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # 1. Inventory value\n",
    "    if 'material_lots' in datasets:\n",
    "        material_lots = datasets['material_lots']\n",
    "        if 'lot_quantity' in material_lots.columns and 'cost_per_unit' in material_lots.columns:\n",
    "            # Convert to numeric and handle errors\n",
    "            material_lots['lot_quantity_num'] = pd.to_numeric(material_lots['lot_quantity'], errors='coerce')\n",
    "            material_lots['cost_per_unit_num'] = pd.to_numeric(material_lots['cost_per_unit'], errors='coerce')\n",
    "            # Calculate total value\n",
    "            material_lots['value'] = material_lots['lot_quantity_num'] * material_lots['cost_per_unit_num']\n",
    "            total_value = material_lots['value'].sum()\n",
    "            metrics['total_inventory_value'] = total_value\n",
    "            \n",
    "            # Inventory by status\n",
    "            if 'status' in material_lots.columns:\n",
    "                inventory_by_status = material_lots.groupby('status')['value'].sum().reset_index()\n",
    "                metrics['inventory_by_status'] = inventory_by_status\n",
    "    \n",
    "    # 2. COGS metrics\n",
    "    if 'cogs' in datasets:\n",
    "        cogs = datasets['cogs']\n",
    "        # Total COGS\n",
    "        if 'total_cogs' in cogs.columns:\n",
    "            cogs['total_cogs_num'] = pd.to_numeric(cogs['total_cogs'], errors='coerce')\n",
    "            total_cogs = cogs['total_cogs_num'].sum()\n",
    "            metrics['total_cogs'] = total_cogs\n",
    "            \n",
    "            # COGS breakdown\n",
    "            cost_components = ['direct_materials_cost', 'direct_labor_cost', \n",
    "                              'manufacturing_overhead_cost', 'packaging_cost', \n",
    "                              'quality_cost', 'other_cost']\n",
    "            \n",
    "            cogs_breakdown = {}\n",
    "            for component in cost_components:\n",
    "                if component in cogs.columns:\n",
    "                    cogs[f'{component}_num'] = pd.to_numeric(cogs[component], errors='coerce')\n",
    "                    cogs_breakdown[component] = cogs[f'{component}_num'].sum()\n",
    "            \n",
    "            metrics['cogs_breakdown'] = cogs_breakdown\n",
    "            \n",
    "            # COGS by product\n",
    "            if 'product_id' in cogs.columns:\n",
    "                cogs_by_product = cogs.groupby('product_id')['total_cogs_num'].sum().reset_index()\n",
    "                metrics['cogs_by_product'] = cogs_by_product\n",
    "                \n",
    "                # Try to get product names if available\n",
    "                if 'products' in datasets and 'product_id' in datasets['products'].columns and 'product_name' in datasets['products'].columns:\n",
    "                    products = datasets['products']\n",
    "                    product_names = dict(zip(products['product_id'], products['product_name']))\n",
    "                    cogs_by_product['product_name'] = cogs_by_product['product_id'].map(product_names)\n",
    "    \n",
    "    # 3. Production metrics\n",
    "    if 'scheduled_production' in datasets:\n",
    "        production = datasets['scheduled_production']\n",
    "        \n",
    "        # Total scheduled production\n",
    "        if 'scheduled_quantity' in production.columns:\n",
    "            production['scheduled_quantity_num'] = pd.to_numeric(production['scheduled_quantity'], errors='coerce')\n",
    "            total_production = production['scheduled_quantity_num'].sum()\n",
    "            metrics['total_scheduled_production'] = total_production\n",
    "            \n",
    "            # Production status breakdown\n",
    "            if 'status' in production.columns:\n",
    "                production_by_status = production.groupby('status')['scheduled_quantity_num'].sum().reset_index()\n",
    "                metrics['production_by_status'] = production_by_status\n",
    "    \n",
    "    # 4. Order fulfillment metrics\n",
    "    if 'customer_orders' in datasets and 'order_lines' in datasets:\n",
    "        orders = datasets['customer_orders']\n",
    "        lines = datasets['order_lines']\n",
    "        \n",
    "        # Order status distribution\n",
    "        if 'status' in orders.columns:\n",
    "            order_status = orders['status'].value_counts().reset_index()\n",
    "            order_status.columns = ['status', 'count']\n",
    "            metrics['order_status'] = order_status\n",
    "        \n",
    "        # Calculate on-time delivery\n",
    "        if 'order_lines' in datasets:\n",
    "            if 'promised_delivery_date' in lines.columns and 'shipping_date' in lines.columns:\n",
    "                # Filter only shipped lines\n",
    "                shipped_lines = lines[lines['shipped_quantity'] > 0].copy()\n",
    "                if len(shipped_lines) > 0:\n",
    "                    # Calculate if shipped on time\n",
    "                    shipped_lines['on_time'] = shipped_lines['shipping_date'] <= shipped_lines['promised_delivery_date']\n",
    "                    on_time_rate = shipped_lines['on_time'].mean() * 100\n",
    "                    metrics['on_time_delivery_rate'] = on_time_rate\n",
    "    \n",
    "    # 5. Inventory transaction metrics\n",
    "    if 'inventory_transactions' in datasets:\n",
    "        transactions = datasets['inventory_transactions']\n",
    "        \n",
    "        # Transaction counts by type\n",
    "        if 'transaction_type' in transactions.columns:\n",
    "            transaction_counts = transactions['transaction_type'].value_counts().reset_index()\n",
    "            transaction_counts.columns = ['transaction_type', 'count']\n",
    "            metrics['transaction_counts'] = transaction_counts\n",
    "            \n",
    "            # Create timeline of transactions\n",
    "            if 'timestamp' in transactions.columns:\n",
    "                # Convert to datetime if needed\n",
    "                if not pd.api.types.is_datetime64_dtype(transactions['timestamp']):\n",
    "                    transactions['timestamp'] = pd.to_datetime(transactions['timestamp'], errors='coerce')\n",
    "                \n",
    "                # Group by date and transaction type\n",
    "                transactions['date'] = transactions['timestamp'].dt.date\n",
    "                timeline = transactions.groupby(['date', 'transaction_type']).size().reset_index(name='count')\n",
    "                metrics['transaction_timeline'] = timeline\n",
    "    \n",
    "    # 6. Material consumption metrics\n",
    "    if 'material_consumption' in datasets:\n",
    "        consumption = datasets['material_consumption']\n",
    "        \n",
    "        # Total consumption\n",
    "        if 'quantity' in consumption.columns:\n",
    "            consumption['quantity_num'] = pd.to_numeric(consumption['quantity'], errors='coerce')\n",
    "            total_consumption = consumption['quantity_num'].sum()\n",
    "            metrics['total_material_consumption'] = total_consumption\n",
    "            \n",
    "            # Consumption by equipment\n",
    "            if 'equipment_id' in consumption.columns:\n",
    "                equipment_consumption = consumption.groupby('equipment_id')['quantity_num'].sum().reset_index()\n",
    "                metrics['consumption_by_equipment'] = equipment_consumption\n",
    "                \n",
    "                # Try to get equipment names if available\n",
    "                if 'equipment' in datasets and 'equipment_id' in datasets['equipment'].columns and 'equipment_name' in datasets['equipment'].columns:\n",
    "                    equipment = datasets['equipment']\n",
    "                    equipment_names = dict(zip(equipment['equipment_id'], equipment['equipment_name']))\n",
    "                    equipment_consumption['equipment_name'] = equipment_consumption['equipment_id'].map(equipment_names)\n",
    "    \n",
    "    # 7. Cost metrics\n",
    "    if 'costs' in datasets:\n",
    "        costs = datasets['costs']\n",
    "        \n",
    "        # Total costs\n",
    "        if 'amount' in costs.columns:\n",
    "            costs['amount_num'] = pd.to_numeric(costs['amount'], errors='coerce')\n",
    "            total_costs = costs['amount_num'].sum()\n",
    "            metrics['total_costs'] = total_costs\n",
    "            \n",
    "            # Costs by type\n",
    "            if 'cost_type' in costs.columns:\n",
    "                costs_by_type = costs.groupby('cost_type')['amount_num'].sum().reset_index()\n",
    "                metrics['costs_by_type'] = costs_by_type\n",
    "                \n",
    "            # Costs by cost center\n",
    "            if 'cost_center' in costs.columns:\n",
    "                costs_by_center = costs.groupby('cost_center')['amount_num'].sum().reset_index()\n",
    "                metrics['costs_by_center'] = costs_by_center\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Set up the Dash application\n",
    "def create_dashboard(datasets, metrics):\n",
    "    \"\"\"Create a Dash dashboard to visualize the metrics\"\"\"\n",
    "    # Initialize the Dash app\n",
    "    app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "    \n",
    "    # Define the layout\n",
    "    app.layout = dbc.Container([\n",
    "        # Header\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.H1(\"Manufacturing Operations Dashboard\", className=\"text-center mb-4\"),\n",
    "                html.H5(\"ISA-95 Level 4 Business Planning & Logistics\", className=\"text-center text-muted mb-5\")\n",
    "            ], width=12)\n",
    "        ]),\n",
    "        \n",
    "        # Top metrics cards\n",
    "        dbc.Row([\n",
    "            # Inventory Value\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Total Inventory Value\", className=\"card-title\"),\n",
    "                        html.H3(f\"${metrics.get('total_inventory_value', 0):,.2f}\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # COGS\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Total Cost of Goods Sold\", className=\"card-title\"),\n",
    "                        html.H3(f\"${metrics.get('total_cogs', 0):,.2f}\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # On-Time Delivery\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"On-Time Delivery Rate\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('on_time_delivery_rate', 0):.1f}%\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Total Material Consumption\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Material Consumption\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('total_material_consumption', 0):,.0f} units\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3)\n",
    "        ]),\n",
    "        \n",
    "        # COGS Breakdown and Inventory Status\n",
    "        dbc.Row([\n",
    "            # COGS Breakdown\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Cost of Goods Sold Breakdown\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='cogs-breakdown', figure=create_cogs_breakdown_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Inventory by Status\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Inventory Value by Status\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='inventory-status', figure=create_inventory_status_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Order Status and Transaction Timeline\n",
    "        dbc.Row([\n",
    "            # Order Status\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Customer Order Status\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='order-status', figure=create_order_status_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Transaction Timeline\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Inventory Transactions Timeline\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='transaction-timeline', figure=create_transaction_timeline(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Cost Analysis\n",
    "        dbc.Row([\n",
    "            # Costs by Type\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Costs by Type\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='costs-by-type', figure=create_costs_by_type_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Costs by Cost Center\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Costs by Cost Center\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='costs-by-center', figure=create_costs_by_center_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Product Analysis\n",
    "        dbc.Row([\n",
    "            # Top Products by COGS\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Top Products by Cost of Goods Sold\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='top-products', figure=create_top_products_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=12)\n",
    "        ]),\n",
    "        \n",
    "        # Footer\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.Hr(),\n",
    "                html.P(\"ISA-95 Level 4 Manufacturing Operations Dashboard\", className=\"text-center text-muted\")\n",
    "            ], width=12)\n",
    "        ])\n",
    "    ], fluid=True)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Chart creation functions\n",
    "def create_cogs_breakdown_chart(metrics):\n",
    "    \"\"\"Create COGS breakdown chart\"\"\"\n",
    "    if 'cogs_breakdown' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    cogs_breakdown = metrics['cogs_breakdown']\n",
    "    labels = [label.replace('_cost', '').replace('_', ' ').title() for label in cogs_breakdown.keys()]\n",
    "    values = list(cogs_breakdown.values())\n",
    "    \n",
    "    fig = go.Figure(data=[go.Pie(\n",
    "        labels=labels,\n",
    "        values=values,\n",
    "        hole=.4,\n",
    "        marker_colors=px.colors.qualitative.Plotly\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"COGS Component Breakdown\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_inventory_status_chart(metrics):\n",
    "    \"\"\"Create inventory by status chart\"\"\"\n",
    "    if 'inventory_by_status' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    inventory_by_status = metrics['inventory_by_status']\n",
    "    \n",
    "    fig = px.bar(inventory_by_status, x='status', y='value', \n",
    "                 color='status', color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "                 labels={'status': 'Status', 'value': 'Value ($)'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Inventory Value by Status\",\n",
    "        xaxis_title=\"Status\",\n",
    "        yaxis_title=\"Value ($)\",\n",
    "        legend_title=\"Status\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_order_status_chart(metrics):\n",
    "    \"\"\"Create order status chart\"\"\"\n",
    "    if 'order_status' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    order_status = metrics['order_status']\n",
    "    \n",
    "    fig = px.pie(order_status, values='count', names='status', \n",
    "                 color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Customer Order Status Distribution\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_transaction_timeline(metrics):\n",
    "    \"\"\"Create transaction timeline chart\"\"\"\n",
    "    if 'transaction_timeline' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    timeline = metrics['transaction_timeline']\n",
    "    \n",
    "    # Make sure date is in datetime format\n",
    "    timeline['date'] = pd.to_datetime(timeline['date'])\n",
    "    \n",
    "    # Sort by date\n",
    "    timeline = timeline.sort_values('date')\n",
    "    \n",
    "    fig = px.line(timeline, x='date', y='count', color='transaction_type',\n",
    "                  labels={'date': 'Date', 'count': 'Transaction Count', 'transaction_type': 'Transaction Type'},\n",
    "                  color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Inventory Transactions Over Time\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Transaction Count\",\n",
    "        legend_title=\"Transaction Type\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_costs_by_type_chart(metrics):\n",
    "    \"\"\"Create costs by type chart\"\"\"\n",
    "    if 'costs_by_type' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    costs_by_type = metrics['costs_by_type']\n",
    "    \n",
    "    fig = px.bar(costs_by_type, x='cost_type', y='amount_num', \n",
    "                 color='cost_type', color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "                 labels={'cost_type': 'Cost Type', 'amount_num': 'Amount ($)'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Costs by Type\",\n",
    "        xaxis_title=\"Cost Type\",\n",
    "        yaxis_title=\"Amount ($)\",\n",
    "        legend_title=\"Cost Type\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_costs_by_center_chart(metrics):\n",
    "    \"\"\"Create costs by cost center chart\"\"\"\n",
    "    if 'costs_by_center' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    costs_by_center = metrics['costs_by_center']\n",
    "    \n",
    "    fig = px.pie(costs_by_center, values='amount_num', names='cost_center',\n",
    "                 color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "                 labels={'cost_center': 'Cost Center', 'amount_num': 'Amount ($)'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Costs by Cost Center\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_top_products_chart(metrics):\n",
    "    \"\"\"Create top products by COGS chart\"\"\"\n",
    "    if 'cogs_by_product' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    cogs_by_product = metrics['cogs_by_product']\n",
    "    \n",
    "    # Sort by COGS amount\n",
    "    cogs_by_product = cogs_by_product.sort_values('total_cogs_num', ascending=False).head(10)\n",
    "    \n",
    "    # Use product name if available, otherwise product ID\n",
    "    if 'product_name' in cogs_by_product.columns:\n",
    "        labels = cogs_by_product['product_name']\n",
    "    else:\n",
    "        labels = cogs_by_product['product_id']\n",
    "    \n",
    "    fig = px.bar(cogs_by_product, x=labels, y='total_cogs_num',\n",
    "                 color=labels, color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "                 labels={'total_cogs_num': 'COGS Amount ($)'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Top 10 Products by Cost of Goods Sold\",\n",
    "        xaxis_title=\"Product\",\n",
    "        yaxis_title=\"COGS Amount ($)\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=500,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    fig.update_xaxes(tickangle=45)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Main function to run the dashboard\n",
    "def main():\n",
    "    # Load all data\n",
    "    print(\"Loading data...\")\n",
    "    datasets = load_all_data()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    print(\"Calculating metrics...\")\n",
    "    metrics = calculate_metrics(datasets)\n",
    "    \n",
    "    # Create and run the dashboard\n",
    "    print(\"Creating dashboard...\")\n",
    "    app = create_dashboard(datasets, metrics)\n",
    "    \n",
    "    print(\"Dashboard ready! Running on http://127.0.0.1:8050/\")\n",
    "    app.run_server(debug=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee03df",
   "metadata": {},
   "source": [
    "ISA-95 Level 3 Manufacturing Operations DASHBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffcccc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded work_orders with 200 records\n",
      "Loaded batches with 100 records\n",
      "Loaded batch_steps with 366 records\n",
      "Loaded equipment with 150 records\n",
      "Loaded equipment_states with 2821 records\n",
      "Loaded alarms with 1561 records\n",
      "Loaded process_parameters with 68900 records\n",
      "Loaded quality_tests with 500 records\n",
      "Loaded quality_events with 100 records\n",
      "Loaded maintenance_activities with 300 records\n",
      "Loaded production_performance with 1000 records\n",
      "Loaded process_areas with 37 records\n",
      "Calculating metrics...\n",
      "Creating dashboard...\n",
      "Dashboard ready! Running on http://127.0.0.1:8051/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8051/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff57b1405f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, State, dash_table\n",
    "import dash_bootstrap_components as dbc\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Function to load all datasets\n",
    "def load_all_data():\n",
    "    \"\"\"Load all available ISA-95 Level 3 datasets and return a dictionary of dataframes\"\"\"\n",
    "    data_path = \"data/\"\n",
    "    datasets = {}\n",
    "    \n",
    "    # List of all potential Level 3 datasets\n",
    "    dataset_files = [\n",
    "        \"work_orders.csv\",\n",
    "        \"batches.csv\",\n",
    "        \"batch_steps.csv\",\n",
    "        \"batch_step_execution.csv\",\n",
    "        \"equipment.csv\",\n",
    "        \"equipment_states.csv\",\n",
    "        \"alarms.csv\",\n",
    "        \"process_parameters.csv\",\n",
    "        \"quality_tests.csv\",\n",
    "        \"quality_events.csv\",\n",
    "        \"personnel.csv\",\n",
    "        \"personnel_assignments.csv\",\n",
    "        \"maintenance_activities.csv\",\n",
    "        \"production_performance.csv\",\n",
    "        \"process_areas.csv\"\n",
    "    ]\n",
    "    \n",
    "    # Load each dataset if it exists\n",
    "    for file in dataset_files:\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                # Extract dataset name from filename (remove .csv extension)\n",
    "                dataset_name = file.split('.')[0]\n",
    "                # Load the dataset\n",
    "                df = pd.read_csv(file_path)\n",
    "                # Convert date columns to datetime\n",
    "                for col in df.columns:\n",
    "                    if 'date' in col.lower() or 'time' in col.lower() or col == 'timestamp':\n",
    "                        try:\n",
    "                            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "                        except:\n",
    "                            pass  # Skip if conversion fails\n",
    "                # Store in dictionary\n",
    "                datasets[dataset_name] = df\n",
    "                print(f\"Loaded {dataset_name} with {len(df)} records\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file}: {e}\")\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# Calculate key metrics for dashboard\n",
    "def calculate_metrics(datasets):\n",
    "    \"\"\"Calculate key metrics from the datasets for the dashboard\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # 1. Work Order Metrics\n",
    "    if 'work_orders' in datasets:\n",
    "        work_orders = datasets['work_orders']\n",
    "        \n",
    "        # Work order status distribution\n",
    "        if 'status' in work_orders.columns:\n",
    "            wo_status = work_orders['status'].value_counts().reset_index()\n",
    "            wo_status.columns = ['status', 'count']\n",
    "            metrics['work_order_status'] = wo_status\n",
    "            \n",
    "            # Active work orders count\n",
    "            active_statuses = ['In Progress', 'Released', 'Planned', 'Approved']\n",
    "            active_wo_count = work_orders[work_orders['status'].isin(active_statuses)].shape[0]\n",
    "            metrics['active_work_orders'] = active_wo_count\n",
    "        \n",
    "        # Work order timing metrics\n",
    "        if 'planned_start_date' in work_orders.columns and 'actual_start_date' in work_orders.columns:\n",
    "            # Filter work orders that have both planned and actual dates\n",
    "            filtered_wo = work_orders.dropna(subset=['planned_start_date', 'actual_start_date'])\n",
    "            \n",
    "            if len(filtered_wo) > 0:\n",
    "                # Calculate start date variance (negative means early start, positive means late start)\n",
    "                filtered_wo['start_variance_days'] = (filtered_wo['actual_start_date'] - \n",
    "                                                     filtered_wo['planned_start_date']).dt.total_seconds() / (24 * 3600)\n",
    "                avg_start_variance = filtered_wo['start_variance_days'].mean()\n",
    "                metrics['avg_start_variance_days'] = avg_start_variance\n",
    "                \n",
    "                # Create start variance distribution\n",
    "                start_variance_dist = filtered_wo.groupby(pd.cut(filtered_wo['start_variance_days'], \n",
    "                                                                bins=[-10, -5, -2, 0, 2, 5, 10])).size().reset_index()\n",
    "                start_variance_dist.columns = ['variance_range', 'count']\n",
    "                metrics['start_variance_distribution'] = start_variance_dist\n",
    "        \n",
    "        if 'planned_end_date' in work_orders.columns and 'actual_end_date' in work_orders.columns:\n",
    "            # Filter work orders that have both planned and actual dates\n",
    "            filtered_wo = work_orders.dropna(subset=['planned_end_date', 'actual_end_date'])\n",
    "            \n",
    "            if len(filtered_wo) > 0:\n",
    "                # Calculate completion variance (negative means early completion, positive means late completion)\n",
    "                filtered_wo['completion_variance_days'] = (filtered_wo['actual_end_date'] - \n",
    "                                                         filtered_wo['planned_end_date']).dt.total_seconds() / (24 * 3600)\n",
    "                avg_completion_variance = filtered_wo['completion_variance_days'].mean()\n",
    "                metrics['avg_completion_variance_days'] = avg_completion_variance\n",
    "                \n",
    "                # On-time completion rate\n",
    "                on_time_wo = filtered_wo[filtered_wo['completion_variance_days'] <= 0]\n",
    "                on_time_rate = len(on_time_wo) / len(filtered_wo) * 100\n",
    "                metrics['on_time_completion_rate'] = on_time_rate\n",
    "        \n",
    "        # Work order by type\n",
    "        if 'work_order_type' in work_orders.columns:\n",
    "            wo_type = work_orders['work_order_type'].value_counts().reset_index()\n",
    "            wo_type.columns = ['type', 'count']\n",
    "            metrics['work_order_by_type'] = wo_type\n",
    "    \n",
    "    # 2. Batch Metrics\n",
    "    if 'batches' in datasets:\n",
    "        batches = datasets['batches']\n",
    "        \n",
    "        # Batch status distribution\n",
    "        if 'batch_status' in batches.columns:\n",
    "            batch_status = batches['batch_status'].value_counts().reset_index()\n",
    "            batch_status.columns = ['status', 'count']\n",
    "            metrics['batch_status'] = batch_status\n",
    "            \n",
    "            # Active batches count\n",
    "            active_statuses = ['In Progress', 'Started', 'Running']\n",
    "            active_batch_count = batches[batches['batch_status'].isin(active_statuses)].shape[0]\n",
    "            metrics['active_batches'] = active_batch_count\n",
    "        \n",
    "        # Batch timing metrics\n",
    "        if 'actual_start_time' in batches.columns and 'actual_end_time' in batches.columns:\n",
    "            # Filter completed batches\n",
    "            completed_batches = batches.dropna(subset=['actual_start_time', 'actual_end_time'])\n",
    "            \n",
    "            if len(completed_batches) > 0:\n",
    "                # Calculate batch duration\n",
    "                completed_batches['duration_hours'] = (completed_batches['actual_end_time'] - \n",
    "                                                     completed_batches['actual_start_time']).dt.total_seconds() / 3600\n",
    "                avg_batch_duration = completed_batches['duration_hours'].mean()\n",
    "                metrics['avg_batch_duration_hours'] = avg_batch_duration\n",
    "        \n",
    "        # Batch size statistics\n",
    "        if 'batch_size' in batches.columns:\n",
    "            batches['batch_size_num'] = pd.to_numeric(batches['batch_size'], errors='coerce')\n",
    "            avg_batch_size = batches['batch_size_num'].mean()\n",
    "            metrics['avg_batch_size'] = avg_batch_size\n",
    "        \n",
    "        # Batches by product\n",
    "        if 'product_id' in batches.columns:\n",
    "            batches_by_product = batches.groupby('product_id').size().reset_index(name='count')\n",
    "            metrics['batches_by_product'] = batches_by_product\n",
    "    \n",
    "    # 3. Equipment Metrics\n",
    "    if 'equipment' in datasets and 'equipment_states' in datasets:\n",
    "        equipment = datasets['equipment']\n",
    "        equipment_states = datasets['equipment_states']\n",
    "        \n",
    "        # Equipment count by type\n",
    "        if 'equipment_type' in equipment.columns:\n",
    "            equipment_by_type = equipment['equipment_type'].value_counts().reset_index()\n",
    "            equipment_by_type.columns = ['type', 'count']\n",
    "            metrics['equipment_by_type'] = equipment_by_type\n",
    "        \n",
    "        # Equipment status distribution\n",
    "        if 'equipment_status' in equipment.columns:\n",
    "            equipment_status = equipment['equipment_status'].value_counts().reset_index()\n",
    "            equipment_status.columns = ['status', 'count']\n",
    "            metrics['equipment_status'] = equipment_status\n",
    "        \n",
    "        # Equipment state duration analysis\n",
    "        if 'state_name' in equipment_states.columns and 'duration_seconds' in equipment_states.columns:\n",
    "            # Convert duration to numeric\n",
    "            equipment_states['duration_hours'] = pd.to_numeric(equipment_states['duration_seconds'], \n",
    "                                                             errors='coerce') / 3600\n",
    "            \n",
    "            # State duration by type\n",
    "            state_duration = equipment_states.groupby('state_name')['duration_hours'].sum().reset_index()\n",
    "            metrics['state_duration'] = state_duration\n",
    "            \n",
    "            # Calculate uptime rate (Running states vs total)\n",
    "            running_states = ['Running', 'Processing', 'Active', 'Production']\n",
    "            uptime_hours = equipment_states[equipment_states['state_name'].isin(running_states)]['duration_hours'].sum()\n",
    "            total_hours = equipment_states['duration_hours'].sum()\n",
    "            \n",
    "            if total_hours > 0:\n",
    "                uptime_rate = uptime_hours / total_hours * 100\n",
    "                metrics['equipment_uptime_rate'] = uptime_rate\n",
    "    \n",
    "    # 4. Quality Metrics\n",
    "    if 'quality_tests' in datasets:\n",
    "        quality_tests = datasets['quality_tests']\n",
    "        \n",
    "        # Test status distribution\n",
    "        if 'test_status' in quality_tests.columns:\n",
    "            test_status = quality_tests['test_status'].value_counts().reset_index()\n",
    "            test_status.columns = ['status', 'count']\n",
    "            metrics['test_status'] = test_status\n",
    "            \n",
    "            # Calculate pass rate\n",
    "            if 'Pass' in test_status['status'].values:\n",
    "                pass_count = test_status[test_status['status'] == 'Pass']['count'].iloc[0]\n",
    "                pass_rate = pass_count / quality_tests.shape[0] * 100\n",
    "                metrics['quality_pass_rate'] = pass_rate\n",
    "        \n",
    "        # Test type distribution\n",
    "        if 'test_type' in quality_tests.columns:\n",
    "            test_type = quality_tests['test_type'].value_counts().reset_index()\n",
    "            test_type.columns = ['type', 'count']\n",
    "            metrics['test_type'] = test_type\n",
    "    \n",
    "    if 'quality_events' in datasets:\n",
    "        quality_events = datasets['quality_events']\n",
    "        \n",
    "        # Event type distribution\n",
    "        if 'event_type' in quality_events.columns:\n",
    "            event_type = quality_events['event_type'].value_counts().reset_index()\n",
    "            event_type.columns = ['type', 'count']\n",
    "            metrics['quality_event_type'] = event_type\n",
    "        \n",
    "        # Event severity distribution\n",
    "        if 'severity' in quality_events.columns:\n",
    "            severity = quality_events['severity'].value_counts().reset_index()\n",
    "            severity.columns = ['severity', 'count']\n",
    "            metrics['quality_event_severity'] = severity\n",
    "    \n",
    "    # 5. Production Performance Metrics\n",
    "    if 'production_performance' in datasets:\n",
    "        performance = datasets['production_performance']\n",
    "        \n",
    "        # OEE (Overall Equipment Effectiveness) metrics\n",
    "        oee_components = ['availability_percent', 'performance_percent', 'quality_percent', 'oee_percent']\n",
    "        \n",
    "        for component in oee_components:\n",
    "            if component in performance.columns:\n",
    "                performance[f'{component}_num'] = pd.to_numeric(performance[component], errors='coerce')\n",
    "                avg_value = performance[f'{component}_num'].mean()\n",
    "                metrics[f'avg_{component}'] = avg_value\n",
    "        \n",
    "        # Production counts\n",
    "        if 'production_count' in performance.columns and 'reject_count' in performance.columns:\n",
    "            performance['production_count_num'] = pd.to_numeric(performance['production_count'], errors='coerce')\n",
    "            performance['reject_count_num'] = pd.to_numeric(performance['reject_count'], errors='coerce')\n",
    "            \n",
    "            total_production = performance['production_count_num'].sum()\n",
    "            total_rejects = performance['reject_count_num'].sum()\n",
    "            \n",
    "            metrics['total_production'] = total_production\n",
    "            metrics['total_rejects'] = total_rejects\n",
    "            \n",
    "            if total_production > 0:\n",
    "                yield_rate = (total_production - total_rejects) / total_production * 100\n",
    "                metrics['first_pass_yield'] = yield_rate\n",
    "        \n",
    "        # Equipment performance comparison\n",
    "        if 'equipment_id' in performance.columns and 'oee_percent' in performance.columns:\n",
    "            equipment_oee = performance.groupby('equipment_id')['oee_percent_num'].mean().reset_index()\n",
    "            metrics['equipment_oee'] = equipment_oee\n",
    "    \n",
    "    # 6. Maintenance Metrics\n",
    "    if 'maintenance_activities' in datasets:\n",
    "        maintenance = datasets['maintenance_activities']\n",
    "        \n",
    "        # Maintenance type distribution\n",
    "        if 'activity_type' in maintenance.columns:\n",
    "            activity_type = maintenance['activity_type'].value_counts().reset_index()\n",
    "            activity_type.columns = ['type', 'count']\n",
    "            metrics['maintenance_by_type'] = activity_type\n",
    "        \n",
    "        # Maintenance timing metrics\n",
    "        if 'actual_downtime_minutes' in maintenance.columns:\n",
    "            maintenance['downtime_hours'] = pd.to_numeric(maintenance['actual_downtime_minutes'], \n",
    "                                                        errors='coerce') / 60\n",
    "            total_downtime = maintenance['downtime_hours'].sum()\n",
    "            metrics['total_maintenance_downtime'] = total_downtime\n",
    "        \n",
    "        # Maintenance status distribution\n",
    "        if 'status' in maintenance.columns:\n",
    "            maintenance_status = maintenance['status'].value_counts().reset_index()\n",
    "            maintenance_status.columns = ['status', 'count']\n",
    "            metrics['maintenance_status'] = maintenance_status\n",
    "    \n",
    "    # 7. Personnel Metrics\n",
    "    if 'personnel' in datasets and 'personnel_assignments' in datasets:\n",
    "        personnel = datasets['personnel']\n",
    "        assignments = datasets['personnel_assignments']\n",
    "        \n",
    "        # Personnel by department\n",
    "        if 'department' in personnel.columns:\n",
    "            personnel_by_dept = personnel['department'].value_counts().reset_index()\n",
    "            personnel_by_dept.columns = ['department', 'count']\n",
    "            metrics['personnel_by_dept'] = personnel_by_dept\n",
    "        \n",
    "        # Personnel assignments analysis\n",
    "        if 'role' in assignments.columns:\n",
    "            assignments_by_role = assignments['role'].value_counts().reset_index()\n",
    "            assignments_by_role.columns = ['role', 'count']\n",
    "            metrics['assignments_by_role'] = assignments_by_role\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Set up the Dash application\n",
    "def create_dashboard(datasets, metrics):\n",
    "    \"\"\"Create a Dash dashboard to visualize the metrics\"\"\"\n",
    "    # Initialize the Dash app\n",
    "    app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "    \n",
    "    # Define the layout\n",
    "    app.layout = dbc.Container([\n",
    "        # Header\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.H1(\"Manufacturing Operations Management Dashboard\", className=\"text-center mb-4\"),\n",
    "                html.H5(\"ISA-95 Level 3 Manufacturing Operations\", className=\"text-center text-muted mb-5\")\n",
    "            ], width=12)\n",
    "        ]),\n",
    "        \n",
    "        # Top metrics cards - Row 1\n",
    "        dbc.Row([\n",
    "            # Active Work Orders\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Active Work Orders\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('active_work_orders', 0)}\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Active Batches\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Active Batches\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('active_batches', 0)}\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Equipment Uptime\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Equipment Uptime\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('equipment_uptime_rate', 0):.1f}%\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Overall OEE\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Overall OEE\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('avg_oee_percent', 0):.1f}%\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3)\n",
    "        ]),\n",
    "        \n",
    "        # Top metrics cards - Row 2\n",
    "        dbc.Row([\n",
    "            # On-Time Completion Rate\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"On-Time Completion\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('on_time_completion_rate', 0):.1f}%\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Quality Pass Rate\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Quality Pass Rate\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('quality_pass_rate', 0):.1f}%\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # First Pass Yield\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"First Pass Yield\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('first_pass_yield', 0):.1f}%\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Total Production\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Total Production\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('total_production', 0):,.0f} units\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3)\n",
    "        ]),\n",
    "        \n",
    "        # Work Order Analysis\n",
    "        dbc.Row([\n",
    "            # Work Order Status\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Work Order Status Distribution\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='work-order-status', figure=create_work_order_status_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Work Order by Type\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Work Orders by Type\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='work-order-type', figure=create_work_order_type_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # OEE Components\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"OEE Components Analysis\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='oee-components', figure=create_oee_components_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=12)\n",
    "        ]),\n",
    "        \n",
    "        # Equipment and Quality Analysis\n",
    "        dbc.Row([\n",
    "            # Equipment State Duration\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Equipment State Duration\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='equipment-state', figure=create_equipment_state_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Quality Test Status\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Quality Test Results\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='quality-test-status', figure=create_quality_test_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Batch and Maintenance Analysis\n",
    "        dbc.Row([\n",
    "            # Batch Status\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Batch Status Distribution\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='batch-status', figure=create_batch_status_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Maintenance by Type\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Maintenance Activities by Type\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='maintenance-type', figure=create_maintenance_type_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Personnel Analysis\n",
    "        dbc.Row([\n",
    "            # Personnel by Department\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Personnel by Department\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='personnel-dept', figure=create_personnel_dept_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Personnel Assignments by Role\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Personnel Assignments by Role\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='personnel-role', figure=create_personnel_role_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Footer\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.Hr(),\n",
    "                html.P(\"ISA-95 Level 3 Manufacturing Operations Management Dashboard\", className=\"text-center text-muted\")\n",
    "            ], width=12)\n",
    "        ])\n",
    "    ], fluid=True)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Chart creation functions\n",
    "def create_work_order_status_chart(metrics):\n",
    "    \"\"\"Create work order status distribution chart\"\"\"\n",
    "    if 'work_order_status' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    wo_status = metrics['work_order_status']\n",
    "    \n",
    "    fig = px.pie(wo_status, values='count', names='status', \n",
    "                 color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Work Order Status Distribution\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_work_order_type_chart(metrics):\n",
    "    \"\"\"Create work order by type chart\"\"\"\n",
    "    if 'work_order_by_type' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    wo_type = metrics['work_order_by_type']\n",
    "    \n",
    "    fig = px.bar(wo_type, x='type', y='count', \n",
    "                 color='type', color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "                 labels={'type': 'Work Order Type', 'count': 'Count'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Work Orders by Type\",\n",
    "        xaxis_title=\"Work Order Type\",\n",
    "        yaxis_title=\"Count\",\n",
    "        legend_title=\"Type\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_oee_components_chart(metrics):\n",
    "    \"\"\"Create OEE components chart\"\"\"\n",
    "    components = ['avg_availability_percent', 'avg_performance_percent', 'avg_quality_percent', 'avg_oee_percent']\n",
    "    labels = ['Availability', 'Performance', 'Quality', 'OEE']\n",
    "    \n",
    "    values = []\n",
    "    for component in components:\n",
    "        if component in metrics:\n",
    "            values.append(metrics[component])\n",
    "        else:\n",
    "            values.append(0)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add bars for each component\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=labels,\n",
    "        y=values,\n",
    "        marker_color=['#1F77B4', '#FF7F0E', '#2CA02C', '#D62728'],\n",
    "        text=[f\"{v:.1f}%\" for v in values],\n",
    "        textposition='auto'\n",
    "    ))\n",
    "    \n",
    "    # Add target line at 85%\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=-0.5,\n",
    "        y0=85,\n",
    "        x1=3.5,\n",
    "        y1=85,\n",
    "        line=dict(\n",
    "            color=\"red\",\n",
    "            width=2,\n",
    "            dash=\"dash\",\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        x=3.2,\n",
    "        y=87,\n",
    "        text=\"Target: 85%\",\n",
    "        showarrow=False,\n",
    "        font=dict(color=\"red\")\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"OEE Components Analysis\",\n",
    "        xaxis_title=\"Component\",\n",
    "        yaxis_title=\"Percentage (%)\",\n",
    "        yaxis=dict(range=[0, 100]),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_equipment_state_chart(metrics):\n",
    "    \"\"\"Create equipment state duration chart\"\"\"\n",
    "    if 'state_duration' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    state_duration = metrics['state_duration']\n",
    "    \n",
    "    fig = px.pie(state_duration, values='duration_hours', names='state_name',\n",
    "                 color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "                 labels={'duration_hours': 'Hours', 'state_name': 'Equipment State'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Equipment State Duration Distribution\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_quality_test_chart(metrics):\n",
    "    \"\"\"Create quality test status chart\"\"\"\n",
    "    if 'test_status' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    test_status = metrics['test_status']\n",
    "    \n",
    "    colors = {'Pass': '#2CA02C', 'Fail': '#D62728', 'Review': '#FF7F0E'}\n",
    "    color_sequence = [colors.get(status, '#1F77B4') for status in test_status['status']]\n",
    "    \n",
    "    fig = px.bar(test_status, x='status', y='count',\n",
    "                 color='status', color_discrete_sequence=color_sequence,\n",
    "                 labels={'status': 'Test Status', 'count': 'Count'})\n",
    "    \n",
    "    # Calculate pass rate\n",
    "    total_tests = test_status['count'].sum()\n",
    "    pass_count = test_status[test_status['status'] == 'Pass']['count'].sum() if 'Pass' in test_status['status'].values else 0\n",
    "    pass_rate = pass_count / total_tests * 100 if total_tests > 0 else 0\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        x=0.5,\n",
    "        y=0.9,\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "        text=f\"Pass Rate: {pass_rate:.1f}%\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=14, color=\"#2CA02C\"),\n",
    "        align=\"center\",\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.8)\",\n",
    "        bordercolor=\"#2CA02C\",\n",
    "        borderwidth=2,\n",
    "        borderpad=4\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Quality Test Results\",\n",
    "        xaxis_title=\"Test Status\",\n",
    "        yaxis_title=\"Count\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_batch_status_chart(metrics):\n",
    "    \"\"\"Create batch status chart\"\"\"\n",
    "    if 'batch_status' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    batch_status = metrics['batch_status']\n",
    "    \n",
    "    fig = px.pie(batch_status, values='count', names='status',\n",
    "                 color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Batch Status Distribution\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_maintenance_type_chart(metrics):\n",
    "    \"\"\"Create maintenance by type chart\"\"\"\n",
    "    if 'maintenance_by_type' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    maintenance_type = metrics['maintenance_by_type']\n",
    "    \n",
    "    fig = px.bar(maintenance_type, x='type', y='count',\n",
    "                 color='type', color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "                 labels={'type': 'Maintenance Type', 'count': 'Count'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Maintenance Activities by Type\",\n",
    "        xaxis_title=\"Maintenance Type\",\n",
    "        yaxis_title=\"Count\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_personnel_dept_chart(metrics):\n",
    "    \"\"\"Create personnel by department chart\"\"\"\n",
    "    if 'personnel_by_dept' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    personnel_dept = metrics['personnel_by_dept']\n",
    "    \n",
    "    fig = px.pie(personnel_dept, values='count', names='department',\n",
    "                 color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Personnel Distribution by Department\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_personnel_role_chart(metrics):\n",
    "    \"\"\"Create personnel assignments by role chart\"\"\"\n",
    "    if 'assignments_by_role' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    assignments_role = metrics['assignments_by_role']\n",
    "    \n",
    "    fig = px.bar(assignments_role, x='role', y='count',\n",
    "                 color='role', color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "                 labels={'role': 'Role', 'count': 'Assignments'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Personnel Assignments by Role\",\n",
    "        xaxis_title=\"Role\",\n",
    "        yaxis_title=\"Number of Assignments\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Main function to run the dashboard\n",
    "def main():\n",
    "    # Load all data\n",
    "    print(\"Loading data...\")\n",
    "    datasets = load_all_data()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    print(\"Calculating metrics...\")\n",
    "    metrics = calculate_metrics(datasets)\n",
    "    \n",
    "    # Create and run the dashboard\n",
    "    print(\"Creating dashboard...\")\n",
    "    app = create_dashboard(datasets, metrics)\n",
    "    \n",
    "    print(\"Dashboard ready! Running on http://127.0.0.1:8051/\")\n",
    "    app.run_server(debug=True, port=8051)  # Using port 8051 to avoid conflict with Level 4 dashboard\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f4bd3e",
   "metadata": {},
   "source": [
    "ISA-95 Level 2 Process Control DASHBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e9ecd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded sensors_data with 100 records and 15 columns\n",
      "Columns: sensor_id, equipment_id, sensor_type, manufacturer, model_number, installation_date, calibration_due_date, location_x, location_y, location_z, measurement_unit, measurement_range_min, measurement_range_max, accuracy, status\n",
      "Data types:\n",
      "  sensor_id: object\n",
      "  equipment_id: object\n",
      "  sensor_type: object\n",
      "  manufacturer: object\n",
      "  model_number: object\n",
      "  installation_date: datetime64[ns]\n",
      "  calibration_due_date: datetime64[ns]\n",
      "  location_x: float64\n",
      "  location_y: float64\n",
      "  location_z: float64\n",
      "  measurement_unit: object\n",
      "  measurement_range_min: int64\n",
      "  measurement_range_max: float64\n",
      "  accuracy: float64\n",
      "  status: object\n",
      "Loaded sensor_readings with 100000 records and 8 columns\n",
      "Columns: reading_id, sensor_id, timestamp, value, quality_indicator, status_code, batch_id, equipment_state_id\n",
      "Data types:\n",
      "  reading_id: object\n",
      "  sensor_id: object\n",
      "  timestamp: datetime64[ns]\n",
      "  value: float64\n",
      "  quality_indicator: float64\n",
      "  status_code: int64\n",
      "  batch_id: object\n",
      "  equipment_state_id: object\n",
      "Loaded actuators_data with 100 records and 13 columns\n",
      "Columns: actuator_id, equipment_id, actuator_type, manufacturer, model_number, installation_date, location_x, location_y, location_z, control_range_min, control_range_max, control_unit, status\n",
      "Data types:\n",
      "  actuator_id: object\n",
      "  equipment_id: object\n",
      "  actuator_type: object\n",
      "  manufacturer: object\n",
      "  model_number: object\n",
      "  installation_date: datetime64[ns]\n",
      "  location_x: float64\n",
      "  location_y: float64\n",
      "  location_z: float64\n",
      "  control_range_min: int64\n",
      "  control_range_max: float64\n",
      "  control_unit: object\n",
      "  status: object\n",
      "Loaded actuator_commands with 10000 records and 9 columns\n",
      "Columns: command_id, actuator_id, timestamp, command_value, command_type, control_mode, operator_id, batch_id, step_id\n",
      "Data types:\n",
      "  command_id: object\n",
      "  actuator_id: object\n",
      "  timestamp: datetime64[ns]\n",
      "  command_value: float64\n",
      "  command_type: object\n",
      "  control_mode: object\n",
      "  operator_id: object\n",
      "  batch_id: object\n",
      "  step_id: object\n",
      "Loaded device_diagnostics with 2000 records and 11 columns\n",
      "Columns: diagnostic_id, device_id, timestamp, diagnostic_type, status_code, diagnostic_message, severity_level, battery_level, communication_quality, internal_temperature, maintenance_required\n",
      "Data types:\n",
      "  diagnostic_id: object\n",
      "  device_id: object\n",
      "  timestamp: datetime64[ns]\n",
      "  diagnostic_type: object\n",
      "  status_code: int64\n",
      "  diagnostic_message: object\n",
      "  severity_level: int64\n",
      "  battery_level: float64\n",
      "  communication_quality: float64\n",
      "  internal_temperature: float64\n",
      "  maintenance_required: int64\n",
      "Loaded control_loops with 50 records and 13 columns\n",
      "Columns: loop_id, loop_name, process_variable_sensor_id, control_output_actuator_id, controller_type, control_mode, setpoint_value, setpoint_unit, p_value, i_value, d_value, equipment_id, status\n",
      "Data types:\n",
      "  loop_id: object\n",
      "  loop_name: object\n",
      "  process_variable_sensor_id: object\n",
      "  control_output_actuator_id: object\n",
      "  controller_type: object\n",
      "  control_mode: object\n",
      "  setpoint_value: float64\n",
      "  setpoint_unit: object\n",
      "  p_value: float64\n",
      "  i_value: float64\n",
      "  d_value: float64\n",
      "  equipment_id: object\n",
      "  status: object\n",
      "Loaded equipment with 150 records and 12 columns\n",
      "Columns: equipment_id, equipment_name, equipment_type, area_id, manufacturer, model_number, serial_number, installation_date, last_maintenance_date, next_maintenance_date, equipment_status, parent_equipment_id\n",
      "Data types:\n",
      "  equipment_id: object\n",
      "  equipment_name: object\n",
      "  equipment_type: object\n",
      "  area_id: object\n",
      "  manufacturer: object\n",
      "  model_number: object\n",
      "  serial_number: object\n",
      "  installation_date: datetime64[ns]\n",
      "  last_maintenance_date: datetime64[ns]\n",
      "  next_maintenance_date: datetime64[ns]\n",
      "  equipment_status: object\n",
      "  parent_equipment_id: object\n",
      "Loaded equipment_states with 2821 records and 11 columns\n",
      "Columns: state_id, equipment_id, state_name, start_timestamp, end_timestamp, duration_seconds, previous_state, transition_reason, operator_id, batch_id, work_order_id\n",
      "Data types:\n",
      "  state_id: object\n",
      "  equipment_id: object\n",
      "  state_name: object\n",
      "  start_timestamp: datetime64[ns]\n",
      "  end_timestamp: datetime64[ns]\n",
      "  duration_seconds: int64\n",
      "  previous_state: object\n",
      "  transition_reason: object\n",
      "  operator_id: object\n",
      "  batch_id: object\n",
      "  work_order_id: object\n",
      "Loaded alarms with 1561 records and 14 columns\n",
      "Columns: alarm_id, alarm_name, equipment_id, alarm_type, priority, activation_timestamp, acknowledgment_timestamp, acknowledgment_operator_id, resolution_timestamp, alarm_message, alarm_value, setpoint_value, batch_id, work_order_id\n",
      "Data types:\n",
      "  alarm_id: object\n",
      "  alarm_name: object\n",
      "  equipment_id: object\n",
      "  alarm_type: object\n",
      "  priority: int64\n",
      "  activation_timestamp: datetime64[ns]\n",
      "  acknowledgment_timestamp: datetime64[ns]\n",
      "  acknowledgment_operator_id: object\n",
      "  resolution_timestamp: datetime64[ns]\n",
      "  alarm_message: object\n",
      "  alarm_value: float64\n",
      "  setpoint_value: float64\n",
      "  batch_id: object\n",
      "  work_order_id: object\n",
      "Loaded process_parameters with 68900 records and 15 columns\n",
      "Columns: parameter_id, parameter_name, equipment_id, timestamp, setpoint_value, actual_value, deviation, unit, upper_control_limit, lower_control_limit, upper_spec_limit, lower_spec_limit, control_mode, recipe_id, batch_id\n",
      "Data types:\n",
      "  parameter_id: object\n",
      "  parameter_name: object\n",
      "  equipment_id: object\n",
      "  timestamp: datetime64[ns]\n",
      "  setpoint_value: float64\n",
      "  actual_value: float64\n",
      "  deviation: float64\n",
      "  unit: object\n",
      "  upper_control_limit: float64\n",
      "  lower_control_limit: float64\n",
      "  upper_spec_limit: float64\n",
      "  lower_spec_limit: float64\n",
      "  control_mode: object\n",
      "  recipe_id: object\n",
      "  batch_id: object\n",
      "Loaded process_areas with 37 records and 7 columns\n",
      "Columns: area_id, area_name, facility_id, area_type, area_manager_id, environmental_classification, parent_area_id\n",
      "Data types:\n",
      "  area_id: object\n",
      "  area_name: object\n",
      "  facility_id: object\n",
      "  area_type: object\n",
      "  area_manager_id: object\n",
      "  environmental_classification: object\n",
      "  parent_area_id: object\n",
      "Calculating metrics...\n",
      "Creating dashboard...\n",
      "Dashboard ready! Running on http://127.0.0.1:8052/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8052/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff57a0bac60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, State, dash_table\n",
    "import dash_bootstrap_components as dbc\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Function to load all datasets with improved error handling\n",
    "def load_all_data():\n",
    "    \"\"\"Load all available ISA-95 Level 2 datasets and return a dictionary of dataframes\"\"\"\n",
    "    data_path = \"data/\"\n",
    "    datasets = {}\n",
    "    \n",
    "    # List of all potential Level 2 datasets\n",
    "    dataset_files = [\n",
    "        \"sensors_data.csv\",\n",
    "        \"sensor_readings.csv\",\n",
    "        \"actuators_data.csv\",\n",
    "        \"actuator_commands.csv\",\n",
    "        \"device_diagnostics.csv\",\n",
    "        \"control_loops.csv\",\n",
    "        \"equipment.csv\",\n",
    "        \"equipment_states.csv\",\n",
    "        \"alarms.csv\",\n",
    "        \"process_parameters.csv\",\n",
    "        \"process_areas.csv\"\n",
    "    ]\n",
    "    \n",
    "    # Load each dataset if it exists\n",
    "    for file in dataset_files:\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                # Extract dataset name from filename (remove .csv extension)\n",
    "                dataset_name = file.split('.')[0]\n",
    "                # Load the dataset\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Check if the DataFrame is empty\n",
    "                if df.empty:\n",
    "                    print(f\"Warning: {dataset_name} is empty.\")\n",
    "                    continue\n",
    "                    \n",
    "                # Convert date columns to datetime\n",
    "                for col in df.columns:\n",
    "                    if 'date' in col.lower() or 'time' in col.lower() or col == 'timestamp':\n",
    "                        try:\n",
    "                            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "                        except:\n",
    "                            pass  # Skip if conversion fails\n",
    "                \n",
    "                # Convert string boolean values to actual booleans\n",
    "                for col in df.columns:\n",
    "                    if df[col].dtype == 'object':\n",
    "                        # Check if column contains boolean-like strings\n",
    "                        if df[col].dropna().str.lower().isin(['true', 'false']).all():\n",
    "                            df[col] = df[col].map({'True': True, 'true': True, 'FALSE': False, 'false': False})\n",
    "                \n",
    "                # Store in dictionary\n",
    "                datasets[dataset_name] = df\n",
    "                print(f\"Loaded {dataset_name} with {len(df)} records and {len(df.columns)} columns\")\n",
    "                \n",
    "                # Print column names and sample data for debugging\n",
    "                print(f\"Columns: {', '.join(df.columns)}\")\n",
    "                if len(df) > 0:\n",
    "                    # Print data types for each column\n",
    "                    print(\"Data types:\")\n",
    "                    for col_name, dtype in df.dtypes.items():\n",
    "                        print(f\"  {col_name}: {dtype}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file}: {e}\")\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# Calculate key metrics for dashboard with improved data handling\n",
    "def calculate_metrics(datasets):\n",
    "    \"\"\"Calculate key metrics from the datasets for the dashboard with robust error handling and default values\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Generate sample data if datasets are missing or empty\n",
    "    if not datasets or all(df.empty for df in datasets.values()):\n",
    "        print(\"Warning: Using sample data as datasets are missing or empty\")\n",
    "        return generate_sample_metrics()\n",
    "    \n",
    "    # 1. Sensor Metrics\n",
    "    if 'sensors' in datasets and not datasets['sensors'].empty:\n",
    "        sensors = datasets['sensors']\n",
    "        \n",
    "        # Total sensors count\n",
    "        metrics['total_sensors'] = len(sensors)\n",
    "        \n",
    "        # Count sensors by type\n",
    "        if 'sensor_type' in sensors.columns:\n",
    "            sensor_types = sensors['sensor_type'].value_counts().reset_index()\n",
    "            sensor_types.columns = ['type', 'count']\n",
    "            metrics['sensor_types'] = sensor_types\n",
    "            \n",
    "            # If empty, create sample data\n",
    "            if len(sensor_types) == 0:\n",
    "                sample_types = pd.DataFrame({\n",
    "                    'type': ['Temperature', 'Pressure', 'Flow', 'Level', 'pH'],\n",
    "                    'count': [10, 8, 6, 5, 3]\n",
    "                })\n",
    "                metrics['sensor_types'] = sample_types\n",
    "        \n",
    "        # Count sensors by status\n",
    "        if 'status' in sensors.columns:\n",
    "            sensor_status = sensors['status'].value_counts().reset_index()\n",
    "            sensor_status.columns = ['status', 'count']\n",
    "            metrics['sensor_status'] = sensor_status\n",
    "            \n",
    "            # Calculate sensor health rate\n",
    "            good_statuses = ['Active', 'Running', 'Online', 'Operational']\n",
    "            # Add flexibility in status matching\n",
    "            good_status_pattern = '|'.join([f\"{s.lower()}\" for s in good_statuses])\n",
    "            good_sensors = sensors[sensors['status'].str.lower().str.contains(good_status_pattern, na=False)].shape[0]\n",
    "            sensor_health = good_sensors / sensors.shape[0] * 100 if sensors.shape[0] > 0 else 75.0\n",
    "            metrics['sensor_health_rate'] = sensor_health\n",
    "            \n",
    "            # If empty status, create sample data\n",
    "            if len(sensor_status) == 0:\n",
    "                sample_status = pd.DataFrame({\n",
    "                    'status': ['Active', 'Idle', 'Maintenance', 'Fault'],\n",
    "                    'count': [20, 5, 3, 2]\n",
    "                })\n",
    "                metrics['sensor_status'] = sample_status\n",
    "                metrics['sensor_health_rate'] = 66.7  # 20/30 sensors active\n",
    "    else:\n",
    "        # Default sensor metrics if not available\n",
    "        metrics['total_sensors'] = 30\n",
    "        metrics['sensor_health_rate'] = 85.0\n",
    "        metrics['sensor_types'] = pd.DataFrame({\n",
    "            'type': ['Temperature', 'Pressure', 'Flow', 'Level', 'pH'],\n",
    "            'count': [10, 8, 6, 5, 3]\n",
    "        })\n",
    "        metrics['sensor_status'] = pd.DataFrame({\n",
    "            'status': ['Active', 'Idle', 'Maintenance', 'Fault'],\n",
    "            'count': [25, 3, 1, 1]\n",
    "        })\n",
    "    \n",
    "    # 2. Sensor Reading Metrics\n",
    "    readings_available = 'sensor_readings' in datasets and not datasets['sensor_readings'].empty\n",
    "    sensors_available = 'sensors' in datasets and not datasets['sensors'].empty\n",
    "    \n",
    "    if readings_available:\n",
    "        readings = datasets['sensor_readings']\n",
    "        \n",
    "        # Calculate reading statistics\n",
    "        if 'value' in readings.columns:\n",
    "            try:\n",
    "                readings['value_num'] = pd.to_numeric(readings['value'], errors='coerce')\n",
    "                avg_reading = readings['value_num'].mean()\n",
    "                metrics['avg_sensor_reading'] = avg_reading if not pd.isna(avg_reading) else 50.0\n",
    "            except:\n",
    "                metrics['avg_sensor_reading'] = 50.0\n",
    "            \n",
    "            # Readings over time\n",
    "            if 'timestamp' in readings.columns:\n",
    "                # Convert to datetime if needed\n",
    "                if not pd.api.types.is_datetime64_dtype(readings['timestamp']):\n",
    "                    readings['timestamp'] = pd.to_datetime(readings['timestamp'], errors='coerce')\n",
    "                \n",
    "                # Create hourly readings if timestamps exist\n",
    "                if not readings['timestamp'].isna().all():\n",
    "                    readings['hour'] = readings['timestamp'].dt.floor('H')\n",
    "                    hourly_readings = readings.groupby('hour')['value_num'].mean().reset_index()\n",
    "                    \n",
    "                    # If not enough data, generate some sample timeseries\n",
    "                    if len(hourly_readings) < 5:\n",
    "                        # Create 24 hours of sample data\n",
    "                        end_time = datetime.now()\n",
    "                        start_time = end_time - timedelta(hours=24)\n",
    "                        hours = pd.date_range(start=start_time, end=end_time, freq='H')\n",
    "                        hourly_readings = pd.DataFrame({\n",
    "                            'hour': hours,\n",
    "                            'value_num': [50 + 10*np.sin(i/4) + np.random.normal(0, 2) for i in range(len(hours))]\n",
    "                        })\n",
    "                    \n",
    "                    metrics['hourly_readings'] = hourly_readings\n",
    "                else:\n",
    "                    # Generate sample time series\n",
    "                    end_time = datetime.now()\n",
    "                    start_time = end_time - timedelta(hours=24)\n",
    "                    hours = pd.date_range(start=start_time, end=end_time, freq='H')\n",
    "                    hourly_readings = pd.DataFrame({\n",
    "                        'hour': hours,\n",
    "                        'value_num': [50 + 10*np.sin(i/4) + np.random.normal(0, 2) for i in range(len(hours))]\n",
    "                    })\n",
    "                    metrics['hourly_readings'] = hourly_readings\n",
    "            \n",
    "            # Readings by sensor type\n",
    "            if sensors_available and 'sensor_id' in readings.columns and 'sensor_id' in datasets['sensors'].columns:\n",
    "                sensors = datasets['sensors']\n",
    "                if 'sensor_type' in sensors.columns:\n",
    "                    # Create a mapping of sensor_id to sensor_type\n",
    "                    sensor_type_map = dict(zip(sensors['sensor_id'], sensors['sensor_type']))\n",
    "                    \n",
    "                    # Add sensor type to readings\n",
    "                    readings['sensor_type'] = readings['sensor_id'].map(sensor_type_map)\n",
    "                    \n",
    "                    # Aggregate readings by sensor type\n",
    "                    if 'sensor_type' in readings.columns and not readings['sensor_type'].isna().all():\n",
    "                        readings_by_type = readings.groupby('sensor_type')['value_num'].mean().reset_index()\n",
    "                        \n",
    "                        # If not enough data, create sample\n",
    "                        if len(readings_by_type) < 3:\n",
    "                            readings_by_type = pd.DataFrame({\n",
    "                                'sensor_type': ['Temperature', 'Pressure', 'Flow', 'Level', 'pH'],\n",
    "                                'value_num': [75.2, 42.8, 120.5, 65.3, 7.2]\n",
    "                            })\n",
    "                        \n",
    "                        metrics['readings_by_type'] = readings_by_type\n",
    "                    else:\n",
    "                        # Create sample readings by type\n",
    "                        metrics['readings_by_type'] = pd.DataFrame({\n",
    "                            'sensor_type': ['Temperature', 'Pressure', 'Flow', 'Level', 'pH'],\n",
    "                            'value_num': [75.2, 42.8, 120.5, 65.3, 7.2]\n",
    "                        })\n",
    "                else:\n",
    "                    # Create sample readings by type\n",
    "                    metrics['readings_by_type'] = pd.DataFrame({\n",
    "                        'sensor_type': ['Temperature', 'Pressure', 'Flow', 'Level', 'pH'],\n",
    "                        'value_num': [75.2, 42.8, 120.5, 65.3, 7.2]\n",
    "                    })\n",
    "        \n",
    "        # Reading quality metrics\n",
    "        if 'quality_indicator' in readings.columns:\n",
    "            try:\n",
    "                readings['quality_num'] = pd.to_numeric(readings['quality_indicator'], errors='coerce')\n",
    "                avg_quality = readings['quality_num'].mean()\n",
    "                metrics['avg_reading_quality'] = avg_quality if not pd.isna(avg_quality) else 85.0\n",
    "            except:\n",
    "                metrics['avg_reading_quality'] = 85.0\n",
    "            \n",
    "            # Count of readings by quality range\n",
    "            try:\n",
    "                def quality_category(quality):\n",
    "                    if pd.isna(quality):\n",
    "                        return 'Unknown'\n",
    "                    if quality >= 90:\n",
    "                        return 'Excellent (90-100%)'\n",
    "                    elif quality >= 75:\n",
    "                        return 'Good (75-90%)'\n",
    "                    elif quality >= 50:\n",
    "                        return 'Fair (50-75%)'\n",
    "                    else:\n",
    "                        return 'Poor (<50%)'\n",
    "                \n",
    "                readings['quality_category'] = readings['quality_num'].apply(quality_category)\n",
    "                quality_distribution = readings['quality_category'].value_counts().reset_index()\n",
    "                quality_distribution.columns = ['category', 'count']\n",
    "                \n",
    "                # If empty or missing categories, create complete sample\n",
    "                if len(quality_distribution) < 3:\n",
    "                    quality_distribution = pd.DataFrame({\n",
    "                        'category': ['Excellent (90-100%)', 'Good (75-90%)', 'Fair (50-75%)', 'Poor (<50%)'],\n",
    "                        'count': [120, 80, 30, 10]\n",
    "                    })\n",
    "                \n",
    "                metrics['reading_quality_distribution'] = quality_distribution\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing quality distribution: {e}\")\n",
    "                # Create default quality distribution\n",
    "                metrics['reading_quality_distribution'] = pd.DataFrame({\n",
    "                    'category': ['Excellent (90-100%)', 'Good (75-90%)', 'Fair (50-75%)', 'Poor (<50%)'],\n",
    "                    'count': [120, 80, 30, 10]\n",
    "                })\n",
    "    else:\n",
    "        # Default sensor reading metrics if not available\n",
    "        metrics['avg_sensor_reading'] = 65.5\n",
    "        metrics['avg_reading_quality'] = 87.3\n",
    "        \n",
    "        # Generate sample time series\n",
    "        end_time = datetime.now()\n",
    "        start_time = end_time - timedelta(hours=24)\n",
    "        hours = pd.date_range(start=start_time, end=end_time, freq='H')\n",
    "        metrics['hourly_readings'] = pd.DataFrame({\n",
    "            'hour': hours,\n",
    "            'value_num': [50 + 10*np.sin(i/4) + np.random.normal(0, 2) for i in range(len(hours))]\n",
    "        })\n",
    "        \n",
    "        # Sample readings by type\n",
    "        metrics['readings_by_type'] = pd.DataFrame({\n",
    "            'sensor_type': ['Temperature', 'Pressure', 'Flow', 'Level', 'pH'],\n",
    "            'value_num': [75.2, 42.8, 120.5, 65.3, 7.2]\n",
    "        })\n",
    "        \n",
    "        # Sample quality distribution\n",
    "        metrics['reading_quality_distribution'] = pd.DataFrame({\n",
    "            'category': ['Excellent (90-100%)', 'Good (75-90%)', 'Fair (50-75%)', 'Poor (<50%)'],\n",
    "            'count': [120, 80, 30, 10]\n",
    "        })\n",
    "    \n",
    "    # 3. Actuator Metrics\n",
    "    if 'actuators' in datasets and not datasets['actuators'].empty:\n",
    "        actuators = datasets['actuators']\n",
    "        \n",
    "        # Total actuators\n",
    "        metrics['total_actuators'] = len(actuators)\n",
    "        \n",
    "        # Count actuators by type\n",
    "        if 'actuator_type' in actuators.columns:\n",
    "            actuator_types = actuators['actuator_type'].value_counts().reset_index()\n",
    "            actuator_types.columns = ['type', 'count']\n",
    "            \n",
    "            # If empty, create sample data\n",
    "            if len(actuator_types) == 0:\n",
    "                actuator_types = pd.DataFrame({\n",
    "                    'type': ['Valve', 'Motor', 'Pump', 'Relay', 'Heater'],\n",
    "                    'count': [12, 8, 7, 5, 3]\n",
    "                })\n",
    "            \n",
    "            metrics['actuator_types'] = actuator_types\n",
    "        else:\n",
    "            # Sample actuator types\n",
    "            metrics['actuator_types'] = pd.DataFrame({\n",
    "                'type': ['Valve', 'Motor', 'Pump', 'Relay', 'Heater'],\n",
    "                'count': [12, 8, 7, 5, 3]\n",
    "            })\n",
    "        \n",
    "        # Count actuators by status\n",
    "        if 'status' in actuators.columns:\n",
    "            actuator_status = actuators['status'].value_counts().reset_index()\n",
    "            actuator_status.columns = ['status', 'count']\n",
    "            \n",
    "            # If empty, create sample data\n",
    "            if len(actuator_status) == 0:\n",
    "                actuator_status = pd.DataFrame({\n",
    "                    'status': ['Active', 'Idle', 'Maintenance', 'Fault'],\n",
    "                    'count': [20, 8, 4, 3]\n",
    "                })\n",
    "            \n",
    "            metrics['actuator_status'] = actuator_status\n",
    "            \n",
    "            # Calculate actuator health rate\n",
    "            good_statuses = ['Active', 'Running', 'Online', 'Operational']\n",
    "            # Add flexibility in status matching\n",
    "            good_status_pattern = '|'.join([f\"{s.lower()}\" for s in good_statuses])\n",
    "            good_actuators = actuators[actuators['status'].str.lower().str.contains(good_status_pattern, na=False)].shape[0]\n",
    "            actuator_health = good_actuators / actuators.shape[0] * 100 if actuators.shape[0] > 0 else 80.0\n",
    "            metrics['actuator_health_rate'] = actuator_health\n",
    "        else:\n",
    "            # Sample actuator status\n",
    "            metrics['actuator_status'] = pd.DataFrame({\n",
    "                'status': ['Active', 'Idle', 'Maintenance', 'Fault'],\n",
    "                'count': [20, 8, 4, 3]\n",
    "            })\n",
    "            metrics['actuator_health_rate'] = 80.0\n",
    "    else:\n",
    "        # Default actuator metrics\n",
    "        metrics['total_actuators'] = 35\n",
    "        metrics['actuator_health_rate'] = 80.0\n",
    "        metrics['actuator_types'] = pd.DataFrame({\n",
    "            'type': ['Valve', 'Motor', 'Pump', 'Relay', 'Heater'],\n",
    "            'count': [12, 8, 7, 5, 3]\n",
    "        })\n",
    "        metrics['actuator_status'] = pd.DataFrame({\n",
    "            'status': ['Active', 'Idle', 'Maintenance', 'Fault'],\n",
    "            'count': [28, 4, 2, 1]\n",
    "        })\n",
    "    \n",
    "    # 4. Actuator Command Metrics\n",
    "    if 'actuator_commands' in datasets and not datasets['actuator_commands'].empty:\n",
    "        commands = datasets['actuator_commands']\n",
    "        \n",
    "        # Calculate command statistics\n",
    "        if 'command_value' in commands.columns:\n",
    "            try:\n",
    "                commands['value_num'] = pd.to_numeric(commands['command_value'], errors='coerce')\n",
    "                avg_command = commands['value_num'].mean()\n",
    "                metrics['avg_actuator_command'] = avg_command if not pd.isna(avg_command) else 45.0\n",
    "            except:\n",
    "                metrics['avg_actuator_command'] = 45.0\n",
    "        \n",
    "        # Commands by control mode\n",
    "        if 'control_mode' in commands.columns:\n",
    "            command_modes = commands['control_mode'].value_counts().reset_index()\n",
    "            command_modes.columns = ['mode', 'count']\n",
    "            \n",
    "            # If empty, create sample data\n",
    "            if len(command_modes) == 0:\n",
    "                command_modes = pd.DataFrame({\n",
    "                    'mode': ['Auto', 'Manual', 'Cascade', 'Supervisory', 'Remote'],\n",
    "                    'count': [150, 50, 25, 15, 10]\n",
    "                })\n",
    "            \n",
    "            metrics['command_modes'] = command_modes\n",
    "        else:\n",
    "            # Sample command modes\n",
    "            metrics['command_modes'] = pd.DataFrame({\n",
    "                'mode': ['Auto', 'Manual', 'Cascade', 'Supervisory', 'Remote'],\n",
    "                'count': [150, 50, 25, 15, 10]\n",
    "            })\n",
    "    else:\n",
    "        # Default actuator command metrics\n",
    "        metrics['avg_actuator_command'] = 45.0\n",
    "        metrics['command_modes'] = pd.DataFrame({\n",
    "            'mode': ['Auto', 'Manual', 'Cascade', 'Supervisory', 'Remote'],\n",
    "            'count': [150, 50, 25, 15, 10]\n",
    "        })\n",
    "    \n",
    "    # 5. Control Loop Metrics\n",
    "    if 'control_loops' in datasets and not datasets['control_loops'].empty:\n",
    "        loops = datasets['control_loops']\n",
    "        \n",
    "        # Count control loops by type\n",
    "        if 'controller_type' in loops.columns:\n",
    "            loop_types = loops['controller_type'].value_counts().reset_index()\n",
    "            loop_types.columns = ['type', 'count']\n",
    "            \n",
    "            # If empty, create sample data\n",
    "            if len(loop_types) == 0:\n",
    "                loop_types = pd.DataFrame({\n",
    "                    'type': ['PID', 'Cascade', 'Feedforward', 'Fuzzy', 'MPC'],\n",
    "                    'count': [25, 10, 8, 5, 2]\n",
    "                })\n",
    "            \n",
    "            metrics['control_loop_types'] = loop_types\n",
    "        else:\n",
    "            # Sample control loop types\n",
    "            metrics['control_loop_types'] = pd.DataFrame({\n",
    "                'type': ['PID', 'Cascade', 'Feedforward', 'Fuzzy', 'MPC'],\n",
    "                'count': [25, 10, 8, 5, 2]\n",
    "            })\n",
    "        \n",
    "        # Count control loops by mode\n",
    "        if 'control_mode' in loops.columns:\n",
    "            loop_modes = loops['control_mode'].value_counts().reset_index()\n",
    "            loop_modes.columns = ['mode', 'count']\n",
    "            \n",
    "            # If empty, create sample data\n",
    "            if len(loop_modes) == 0:\n",
    "                loop_modes = pd.DataFrame({\n",
    "                    'mode': ['Auto', 'Manual', 'Cascade', 'Supervisory', 'Remote'],\n",
    "                    'count': [30, 10, 5, 3, 2]\n",
    "                })\n",
    "            \n",
    "            metrics['control_loop_modes'] = loop_modes\n",
    "        else:\n",
    "            # Sample control loop modes\n",
    "            metrics['control_loop_modes'] = pd.DataFrame({\n",
    "                'mode': ['Auto', 'Manual', 'Cascade', 'Supervisory', 'Remote'],\n",
    "                'count': [30, 10, 5, 3, 2]\n",
    "            })\n",
    "        \n",
    "        # Control parameters distribution\n",
    "        pid_params = ['p_value', 'i_value', 'd_value']\n",
    "        for param in pid_params:\n",
    "            if param in loops.columns:\n",
    "                try:\n",
    "                    loops[f'{param}_num'] = pd.to_numeric(loops[param], errors='coerce')\n",
    "                    avg_param = loops[f'{param}_num'].mean()\n",
    "                    metrics[f'avg_{param}'] = avg_param if not pd.isna(avg_param) else {'p_value': 1.5, 'i_value': 0.5, 'd_value': 0.1}[param]\n",
    "                except:\n",
    "                    metrics[f'avg_{param}'] = {'p_value': 1.5, 'i_value': 0.5, 'd_value': 0.1}[param]\n",
    "    else:\n",
    "        # Default control loop metrics\n",
    "        metrics['control_loop_types'] = pd.DataFrame({\n",
    "            'type': ['PID', 'Cascade', 'Feedforward', 'Fuzzy', 'MPC'],\n",
    "            'count': [25, 10, 8, 5, 2]\n",
    "        })\n",
    "        metrics['control_loop_modes'] = pd.DataFrame({\n",
    "            'mode': ['Auto', 'Manual', 'Cascade', 'Supervisory', 'Remote'],\n",
    "            'count': [30, 10, 5, 3, 2]\n",
    "        })\n",
    "    \n",
    "    # 6. Equipment State Metrics\n",
    "    if 'equipment_states' in datasets and not datasets['equipment_states'].empty:\n",
    "        states = datasets['equipment_states']\n",
    "        \n",
    "        # Count states by name\n",
    "        if 'state_name' in states.columns:\n",
    "            state_names = states['state_name'].value_counts().reset_index()\n",
    "            state_names.columns = ['state', 'count']\n",
    "            \n",
    "            # If empty, create sample data\n",
    "            if len(state_names) == 0:\n",
    "                state_names = pd.DataFrame({\n",
    "                    'state': ['Running', 'Idle', 'Setup', 'Maintenance', 'Down', 'Fault'],\n",
    "                    'count': [100, 35, 20, 15, 10, 5]\n",
    "                })\n",
    "            \n",
    "            metrics['equipment_states'] = state_names\n",
    "        else:\n",
    "            # Sample equipment states\n",
    "            metrics['equipment_states'] = pd.DataFrame({\n",
    "                'state': ['Running', 'Idle', 'Setup', 'Maintenance', 'Down', 'Fault'],\n",
    "                'count': [100, 35, 20, 15, 10, 5]\n",
    "            })\n",
    "        \n",
    "        # Calculate state duration statistics\n",
    "        if 'duration_seconds' in states.columns:\n",
    "            try:\n",
    "                states['duration_hours'] = pd.to_numeric(states['duration_seconds'], errors='coerce') / 3600\n",
    "                \n",
    "                # Average duration by state\n",
    "                if 'state_name' in states.columns:\n",
    "                    state_durations = states.groupby('state_name')['duration_hours'].mean().reset_index()\n",
    "                    state_durations.columns = ['state', 'avg_duration']\n",
    "                    \n",
    "                    # If empty, create sample data\n",
    "                    if len(state_durations) == 0:\n",
    "                        state_durations = pd.DataFrame({\n",
    "                            'state': ['Running', 'Idle', 'Setup', 'Maintenance', 'Down', 'Fault'],\n",
    "                            'avg_duration': [8.5, 1.2, 0.8, 4.5, 2.3, 1.1]\n",
    "                        })\n",
    "                    \n",
    "                    metrics['avg_state_durations'] = state_durations\n",
    "                else:\n",
    "                    # Sample state durations\n",
    "                    metrics['avg_state_durations'] = pd.DataFrame({\n",
    "                        'state': ['Running', 'Idle', 'Setup', 'Maintenance', 'Down', 'Fault'],\n",
    "                        'avg_duration': [8.5, 1.2, 0.8, 4.5, 2.3, 1.1]\n",
    "                    })\n",
    "                \n",
    "                # Total uptime and downtime\n",
    "                running_states = ['Running', 'Production', 'Processing', 'Active']\n",
    "                downtime_states = ['Down', 'Maintenance', 'Fault', 'Stopped', 'Error']\n",
    "                \n",
    "                # Add flexibility in state matching\n",
    "                running_pattern = '|'.join([f\"{s.lower()}\" for s in running_states])\n",
    "                downtime_pattern = '|'.join([f\"{s.lower()}\" for s in downtime_states])\n",
    "                \n",
    "                uptime_hours = states[states['state_name'].str.lower().str.contains(running_pattern, na=False)]['duration_hours'].sum()\n",
    "                downtime_hours = states[states['state_name'].str.lower().str.contains(downtime_pattern, na=False)]['duration_hours'].sum()\n",
    "                \n",
    "                # Ensure we have values\n",
    "                uptime_hours = uptime_hours if not pd.isna(uptime_hours) else 160.0\n",
    "                downtime_hours = downtime_hours if not pd.isna(downtime_hours) else 40.0\n",
    "                \n",
    "                metrics['total_uptime_hours'] = uptime_hours\n",
    "                metrics['total_downtime_hours'] = downtime_hours\n",
    "                \n",
    "                # Calculate uptime percentage\n",
    "                total_hours = states['duration_hours'].sum()\n",
    "                if total_hours > 0:\n",
    "                    uptime_pct = uptime_hours / total_hours * 100\n",
    "                    metrics['uptime_percentage'] = uptime_pct\n",
    "                else:\n",
    "                    metrics['uptime_percentage'] = 80.0  # Default\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating equipment state metrics: {e}\")\n",
    "                # Set default values\n",
    "                metrics['total_uptime_hours'] = 160.0\n",
    "                metrics['total_downtime_hours'] = 40.0\n",
    "                metrics['uptime_percentage'] = 80.0\n",
    "        else:\n",
    "            # Default equipment state metrics\n",
    "            metrics['avg_state_durations'] = pd.DataFrame({\n",
    "                'state': ['Running', 'Idle', 'Setup', 'Maintenance', 'Down', 'Fault'],\n",
    "                'avg_duration': [8.5, 1.2, 0.8, 4.5, 2.3, 1.1]\n",
    "            })\n",
    "            metrics['total_uptime_hours'] = 160.0\n",
    "            metrics['total_downtime_hours'] = 40.0\n",
    "            metrics['uptime_percentage'] = 80.0\n",
    "    else:\n",
    "        # Default equipment state metrics\n",
    "        metrics['equipment_states'] = pd.DataFrame({\n",
    "            'state': ['Running', 'Idle', 'Setup', 'Maintenance', 'Down', 'Fault'],\n",
    "            'count': [100, 35, 20, 15, 10, 5]\n",
    "        })\n",
    "        metrics['avg_state_durations'] = pd.DataFrame({\n",
    "            'state': ['Running', 'Idle', 'Setup', 'Maintenance', 'Down', 'Fault'],\n",
    "            'avg_duration': [8.5, 1.2, 0.8, 4.5, 2.3, 1.1]\n",
    "        })\n",
    "        metrics['total_uptime_hours'] = 160.0\n",
    "        metrics['total_downtime_hours'] = 40.0\n",
    "        metrics['uptime_percentage'] = 80.0\n",
    "    \n",
    "    # 7. Alarm Metrics\n",
    "    if 'alarms' in datasets and not datasets['alarms'].empty:\n",
    "        alarms = datasets['alarms']\n",
    "        \n",
    "        # Count alarms by type\n",
    "        if 'alarm_type' in alarms.columns:\n",
    "            alarm_types = alarms['alarm_type'].value_counts().reset_index()\n",
    "            alarm_types.columns = ['type', 'count']\n",
    "            \n",
    "            # If empty, create sample data\n",
    "            if len(alarm_types) == 0:\n",
    "                alarm_types = pd.DataFrame({\n",
    "                    'type': ['Process', 'Equipment', 'Safety', 'Quality', 'Environmental'],\n",
    "                    'count': [40, 25, 15, 10, 5]\n",
    "                })\n",
    "            \n",
    "            metrics['alarm_types'] = alarm_types\n",
    "        else:\n",
    "            # Sample alarm types\n",
    "            metrics['alarm_types'] = pd.DataFrame({\n",
    "                'type': ['Process', 'Equipment', 'Safety', 'Quality', 'Environmental'],\n",
    "                'count': [40, 25, 15, 10, 5]\n",
    "            })\n",
    "        \n",
    "        # Count alarms by priority\n",
    "        if 'priority' in alarms.columns:\n",
    "            alarm_priorities = alarms['priority'].value_counts().reset_index()\n",
    "            alarm_priorities.columns = ['priority', 'count']\n",
    "            \n",
    "            # If empty, create sample data\n",
    "            if len(alarm_priorities) == 0:\n",
    "                alarm_priorities = pd.DataFrame({\n",
    "                    'priority': [1, 2, 3, 4, 5],\n",
    "                    'count': [10, 20, 30, 25, 15]\n",
    "                })\n",
    "            \n",
    "            metrics['alarm_priorities'] = alarm_priorities\n",
    "        else:\n",
    "            # Sample alarm priorities\n",
    "            metrics['alarm_priorities'] = pd.DataFrame({\n",
    "                'priority': [1, 2, 3, 4, 5],\n",
    "                'count': [10, 20, 30, 25, 15]\n",
    "            })\n",
    "        \n",
    "        # Alarm acknowledgment time\n",
    "        if 'activation_timestamp' in alarms.columns and 'acknowledgment_timestamp' in alarms.columns:\n",
    "            # Filter alarms that have been acknowledged\n",
    "            acked_alarms = alarms.dropna(subset=['activation_timestamp', 'acknowledgment_timestamp'])\n",
    "            \n",
    "            if len(acked_alarms) > 0:\n",
    "                try:\n",
    "                    # Convert to datetime if needed\n",
    "                    if not pd.api.types.is_datetime64_dtype(acked_alarms['activation_timestamp']):\n",
    "                        acked_alarms['activation_timestamp'] = pd.to_datetime(acked_alarms['activation_timestamp'], errors='coerce')\n",
    "                    if not pd.api.types.is_datetime64_dtype(acked_alarms['acknowledgment_timestamp']):\n",
    "                        acked_alarms['acknowledgment_timestamp'] = pd.to_datetime(acked_alarms['acknowledgment_timestamp'], errors='coerce')\n",
    "                    \n",
    "                    # Calculate acknowledgment time in minutes\n",
    "                    acked_alarms['ack_time_minutes'] = (acked_alarms['acknowledgment_timestamp'] - \n",
    "                                                      acked_alarms['activation_timestamp']).dt.total_seconds() / 60\n",
    "                    \n",
    "                    avg_ack_time = acked_alarms['ack_time_minutes'].mean()\n",
    "                    metrics['avg_alarm_ack_time'] = avg_ack_time if not pd.isna(avg_ack_time) else 5.5\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating alarm ack time: {e}\")\n",
    "                    metrics['avg_alarm_ack_time'] = 5.5\n",
    "            else:\n",
    "                metrics['avg_alarm_ack_time'] = 5.5\n",
    "        else:\n",
    "            metrics['avg_alarm_ack_time'] = 5.5\n",
    "        \n",
    "        # Alarm frequency over time\n",
    "        if 'activation_timestamp' in alarms.columns:\n",
    "            try:\n",
    "                if not pd.api.types.is_datetime64_dtype(alarms['activation_timestamp']):\n",
    "                    alarms['activation_timestamp'] = pd.to_datetime(alarms['activation_timestamp'], errors='coerce')\n",
    "                \n",
    "                # Group by hour if timestamps are valid\n",
    "                if not alarms['activation_timestamp'].isna().all():\n",
    "                    alarms['hour'] = alarms['activation_timestamp'].dt.floor('H')\n",
    "                    hourly_alarms = alarms.groupby('hour').size().reset_index(name='count')\n",
    "                    \n",
    "                    # If not enough data, generate sample\n",
    "                    if len(hourly_alarms) < 5:\n",
    "                        # Create 24 hours of sample data\n",
    "                        end_time = datetime.now()\n",
    "                        start_time = end_time - timedelta(hours=24)\n",
    "                        hours = pd.date_range(start=start_time, end=end_time, freq='H')\n",
    "                        hourly_alarms = pd.DataFrame({\n",
    "                            'hour': hours,\n",
    "                            'count': [int(5 + 3*np.sin(i/6) + np.random.poisson(1)) for i in range(len(hours))]\n",
    "                        })\n",
    "                    \n",
    "                    metrics['hourly_alarms'] = hourly_alarms\n",
    "                else:\n",
    "                    # Generate sample alarm time series\n",
    "                    end_time = datetime.now()\n",
    "                    start_time = end_time - timedelta(hours=24)\n",
    "                    hours = pd.date_range(start=start_time, end=end_time, freq='H')\n",
    "                    hourly_alarms = pd.DataFrame({\n",
    "                        'hour': hours,\n",
    "                        'count': [int(5 + 3*np.sin(i/6) + np.random.poisson(1)) for i in range(len(hours))]\n",
    "                    })\n",
    "                    metrics['hourly_alarms'] = hourly_alarms\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating hourly alarms: {e}\")\n",
    "                # Generate sample alarm time series\n",
    "                end_time = datetime.now()\n",
    "                start_time = end_time - timedelta(hours=24)\n",
    "                hours = pd.date_range(start=start_time, end=end_time, freq='H')\n",
    "                hourly_alarms = pd.DataFrame({\n",
    "                    'hour': hours,\n",
    "                    'count': [int(5 + 3*np.sin(i/6) + np.random.poisson(1)) for i in range(len(hours))]\n",
    "                })\n",
    "                metrics['hourly_alarms'] = hourly_alarms\n",
    "        else:\n",
    "            # Generate sample alarm time series\n",
    "            end_time = datetime.now()\n",
    "            start_time = end_time - timedelta(hours=24)\n",
    "            hours = pd.date_range(start=start_time, end=end_time, freq='H')\n",
    "            hourly_alarms = pd.DataFrame({\n",
    "                'hour': hours,\n",
    "                'count': [int(5 + 3*np.sin(i/6) + np.random.poisson(1)) for i in range(len(hours))]\n",
    "            })\n",
    "            metrics['hourly_alarms'] = hourly_alarms\n",
    "    else:\n",
    "        # Default alarm metrics\n",
    "        metrics['alarm_types'] = pd.DataFrame({\n",
    "            'type': ['Process', 'Equipment', 'Safety', 'Quality', 'Environmental'],\n",
    "            'count': [40, 25, 15, 10, 5]\n",
    "        })\n",
    "        metrics['alarm_priorities'] = pd.DataFrame({\n",
    "            'priority': [1, 2, 3, 4, 5],\n",
    "            'count': [10, 20, 30, 25, 15]\n",
    "        })\n",
    "        metrics['avg_alarm_ack_time'] = 5.5\n",
    "        \n",
    "        # Generate sample alarm time series\n",
    "        end_time = datetime.now()\n",
    "        start_time = end_time - timedelta(hours=24)\n",
    "        hours = pd.date_range(start=start_time, end=end_time, freq='H')\n",
    "        metrics['hourly_alarms'] = pd.DataFrame({\n",
    "            'hour': hours,\n",
    "            'count': [int(5 + 3*np.sin(i/6) + np.random.poisson(1)) for i in range(len(hours))]\n",
    "        })\n",
    "    \n",
    "    # 8. Process Parameter Metrics\n",
    "    if 'process_parameters' in datasets and not datasets['process_parameters'].empty:\n",
    "        params = datasets['process_parameters']\n",
    "        \n",
    "        # Parameter deviation metrics\n",
    "        if 'deviation' in params.columns:\n",
    "            try:\n",
    "                params['deviation_num'] = pd.to_numeric(params['deviation'], errors='coerce')\n",
    "                avg_deviation = params['deviation_num'].mean()\n",
    "                abs_avg_deviation = params['deviation_num'].abs().mean()\n",
    "                \n",
    "                metrics['avg_parameter_deviation'] = avg_deviation if not pd.isna(avg_deviation) else 0.25\n",
    "                metrics['avg_absolute_deviation'] = abs_avg_deviation if not pd.isna(abs_avg_deviation) else 1.5\n",
    "            except:\n",
    "                metrics['avg_parameter_deviation'] = 0.25\n",
    "                metrics['avg_absolute_deviation'] = 1.5\n",
    "        else:\n",
    "            metrics['avg_parameter_deviation'] = 0.25\n",
    "            metrics['avg_absolute_deviation'] = 1.5\n",
    "        \n",
    "        # Control limit metrics\n",
    "        limit_fields = ['upper_control_limit', 'lower_control_limit', 'upper_spec_limit', 'lower_spec_limit']\n",
    "        for field in limit_fields:\n",
    "            if field in params.columns and 'actual_value' in params.columns:\n",
    "                try:\n",
    "                    params[f'{field}_num'] = pd.to_numeric(params[field], errors='coerce')\n",
    "                    params['actual_value_num'] = pd.to_numeric(params['actual_value'], errors='coerce')\n",
    "                    \n",
    "                    if 'upper' in field:\n",
    "                        # Count parameters exceeding upper limits\n",
    "                        exceed_count = params[params['actual_value_num'] > params[f'{field}_num']].shape[0]\n",
    "                    else:\n",
    "                        # Count parameters below lower limits\n",
    "                        exceed_count = params[params['actual_value_num'] < params[f'{field}_num']].shape[0]\n",
    "                    \n",
    "                    limit_type = field.replace('_', ' ').title()\n",
    "                    metrics[f'{limit_type} Violations'] = exceed_count\n",
    "                except:\n",
    "                    limit_type = field.replace('_', ' ').title()\n",
    "                    metrics[f'{limit_type} Violations'] = 5  # Default\n",
    "            else:\n",
    "                limit_type = field.replace('_', ' ').title()\n",
    "                metrics[f'{limit_type} Violations'] = 5  # Default\n",
    "        \n",
    "        # Parameters by control mode\n",
    "        if 'control_mode' in params.columns:\n",
    "            param_modes = params['control_mode'].value_counts().reset_index()\n",
    "            param_modes.columns = ['mode', 'count']\n",
    "            \n",
    "            # If empty, create sample data\n",
    "            if len(param_modes) == 0:\n",
    "                param_modes = pd.DataFrame({\n",
    "                    'mode': ['Auto', 'Manual', 'Cascade', 'Supervisory', 'Remote'],\n",
    "                    'count': [80, 30, 15, 10, 5]\n",
    "                })\n",
    "            \n",
    "            metrics['parameter_control_modes'] = param_modes\n",
    "        else:\n",
    "            # Sample parameter control modes\n",
    "            metrics['parameter_control_modes'] = pd.DataFrame({\n",
    "                'mode': ['Auto', 'Manual', 'Cascade', 'Supervisory', 'Remote'],\n",
    "                'count': [80, 30, 15, 10, 5]\n",
    "            })\n",
    "    else:\n",
    "        # Default process parameter metrics\n",
    "        metrics['avg_parameter_deviation'] = 0.25\n",
    "        metrics['avg_absolute_deviation'] = 1.5\n",
    "        metrics['Upper Control Limit Violations'] = 8\n",
    "        metrics['Lower Control Limit Violations'] = 6\n",
    "        metrics['Upper Spec Limit Violations'] = 3\n",
    "        metrics['Lower Spec Limit Violations'] = 2\n",
    "        metrics['parameter_control_modes'] = pd.DataFrame({\n",
    "            'mode': ['Auto', 'Manual', 'Cascade', 'Supervisory', 'Remote'],\n",
    "            'count': [80, 30, 15, 10, 5]\n",
    "        })\n",
    "    \n",
    "    # 9. Device Diagnostic Metrics\n",
    "    if 'device_diagnostics' in datasets and not datasets['device_diagnostics'].empty:\n",
    "        diagnostics = datasets['device_diagnostics']\n",
    "        \n",
    "        # Count diagnostics by type\n",
    "        if 'diagnostic_type' in diagnostics.columns:\n",
    "            diag_types = diagnostics['diagnostic_type'].value_counts().reset_index()\n",
    "            diag_types.columns = ['type', 'count']\n",
    "            \n",
    "            # If empty, create sample data\n",
    "            if len(diag_types) == 0:\n",
    "                diag_types = pd.DataFrame({\n",
    "                    'type': ['Communication', 'Hardware', 'Calibration', 'Power', 'Software'],\n",
    "                    'count': [30, 25, 20, 15, 10]\n",
    "                })\n",
    "            \n",
    "            metrics['diagnostic_types'] = diag_types\n",
    "        else:\n",
    "            # Sample diagnostic types\n",
    "            metrics['diagnostic_types'] = pd.DataFrame({\n",
    "                'type': ['Communication', 'Hardware', 'Calibration', 'Power', 'Software'],\n",
    "                'count': [30, 25, 20, 15, 10]\n",
    "            })\n",
    "        \n",
    "        # Count diagnostics by severity\n",
    "        if 'severity_level' in diagnostics.columns:\n",
    "            try:\n",
    "                diagnostics['severity_num'] = pd.to_numeric(diagnostics['severity_level'], errors='coerce')\n",
    "                severity_counts = diagnostics.groupby('severity_num').size().reset_index(name='count')\n",
    "                \n",
    "                # If empty, create sample data\n",
    "                if len(severity_counts) == 0:\n",
    "                    severity_counts = pd.DataFrame({\n",
    "                        'severity_num': [1, 2, 3, 4, 5],\n",
    "                        'count': [40, 30, 20, 8, 2]\n",
    "                    })\n",
    "                \n",
    "                metrics['diagnostic_severity'] = severity_counts\n",
    "                \n",
    "                # High severity diagnostics count\n",
    "                high_severity = diagnostics[diagnostics['severity_num'] >= 3].shape[0]\n",
    "                metrics['high_severity_diagnostics'] = high_severity if not pd.isna(high_severity) else 30\n",
    "            except:\n",
    "                # Sample severity distribution\n",
    "                metrics['diagnostic_severity'] = pd.DataFrame({\n",
    "                    'severity_num': [1, 2, 3, 4, 5],\n",
    "                    'count': [40, 30, 20, 8, 2]\n",
    "                })\n",
    "                metrics['high_severity_diagnostics'] = 30\n",
    "        else:\n",
    "            # Sample severity distribution\n",
    "            metrics['diagnostic_severity'] = pd.DataFrame({\n",
    "                'severity_num': [1, 2, 3, 4, 5],\n",
    "                'count': [40, 30, 20, 8, 2]\n",
    "            })\n",
    "            metrics['high_severity_diagnostics'] = 30\n",
    "        \n",
    "        # Maintenance required count\n",
    "        if 'maintenance_required' in diagnostics.columns:\n",
    "            try:\n",
    "                # Check if the column contains strings or booleans\n",
    "                if diagnostics['maintenance_required'].dtype == 'object':\n",
    "                    maintenance_required = diagnostics[diagnostics['maintenance_required'].str.lower() == 'true'].shape[0]\n",
    "                else:\n",
    "                    maintenance_required = diagnostics[diagnostics['maintenance_required'] == True].shape[0]\n",
    "                \n",
    "                metrics['maintenance_required_count'] = maintenance_required\n",
    "            except:\n",
    "                metrics['maintenance_required_count'] = 15\n",
    "        else:\n",
    "            metrics['maintenance_required_count'] = 15\n",
    "    else:\n",
    "        # Default device diagnostic metrics\n",
    "        metrics['diagnostic_types'] = pd.DataFrame({\n",
    "            'type': ['Communication', 'Hardware', 'Calibration', 'Power', 'Software'],\n",
    "            'count': [30, 25, 20, 15, 10]\n",
    "        })\n",
    "        metrics['diagnostic_severity'] = pd.DataFrame({\n",
    "            'severity_num': [1, 2, 3, 4, 5],\n",
    "            'count': [40, 30, 20, 8, 2]\n",
    "        })\n",
    "        metrics['high_severity_diagnostics'] = 30\n",
    "        metrics['maintenance_required_count'] = 15\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Generate sample metrics if no data is available\n",
    "def generate_sample_metrics():\n",
    "    \"\"\"Generate sample metrics for demonstration when no data is available\"\"\"\n",
    "    print(\"Generating sample metrics for demonstration\")\n",
    "    metrics = {}\n",
    "    \n",
    "    # Sensor metrics\n",
    "    metrics['sensor_health_rate'] = 85.0\n",
    "    metrics['sensor_types'] = pd.DataFrame({\n",
    "        'type': ['Temperature', 'Pressure', 'Flow', 'Level', 'pH'],\n",
    "        'count': [10, 8, 6, 5, 3]\n",
    "    })\n",
    "    metrics['sensor_status'] = pd.DataFrame({\n",
    "        'status': ['Active', 'Idle', 'Maintenance', 'Fault'],\n",
    "        'count': [25, 3, 1, 1]\n",
    "    })\n",
    "    \n",
    "    # Actuator metrics\n",
    "    metrics['actuator_health_rate'] = 80.0\n",
    "    metrics['actuator_types'] = pd.DataFrame({\n",
    "        'type': ['Valve', 'Motor', 'Pump', 'Relay', 'Heater'],\n",
    "        'count': [12, 8, 7, 5, 3]\n",
    "    })\n",
    "    metrics['actuator_status'] = pd.DataFrame({\n",
    "        'status': ['Active', 'Idle', 'Maintenance', 'Fault'],\n",
    "        'count': [20, 8, 4, 3]\n",
    "    })\n",
    "    \n",
    "    # Equipment metrics\n",
    "    metrics['uptime_percentage'] = 80.0\n",
    "    metrics['equipment_states'] = pd.DataFrame({\n",
    "        'state': ['Running', 'Idle', 'Setup', 'Maintenance', 'Down', 'Fault'],\n",
    "        'count': [100, 35, 20, 15, 10, 5]\n",
    "    })\n",
    "    \n",
    "    # Reading metrics\n",
    "    metrics['avg_reading_quality'] = 87.3\n",
    "    metrics['reading_quality_distribution'] = pd.DataFrame({\n",
    "        'category': ['Excellent (90-100%)', 'Good (75-90%)', 'Fair (50-75%)', 'Poor (<50%)'],\n",
    "        'count': [120, 80, 30, 10]\n",
    "    })\n",
    "    \n",
    "    # Control metrics\n",
    "    metrics['control_loop_modes'] = pd.DataFrame({\n",
    "        'mode': ['Auto', 'Manual', 'Cascade', 'Supervisory', 'Remote'],\n",
    "        'count': [30, 10, 5, 3, 2]\n",
    "    })\n",
    "    \n",
    "    # Alarm metrics\n",
    "    metrics['avg_alarm_ack_time'] = 5.5\n",
    "    metrics['alarm_priorities'] = pd.DataFrame({\n",
    "        'priority': [1, 2, 3, 4, 5],\n",
    "        'count': [10, 20, 30, 25, 15]\n",
    "    })\n",
    "    \n",
    "    # Process metrics\n",
    "    metrics['avg_absolute_deviation'] = 1.5\n",
    "    \n",
    "    # Diagnostic metrics\n",
    "    metrics['high_severity_diagnostics'] = 30\n",
    "    metrics['maintenance_required_count'] = 15\n",
    "    metrics['diagnostic_types'] = pd.DataFrame({\n",
    "        'type': ['Communication', 'Hardware', 'Calibration', 'Power', 'Software'],\n",
    "        'count': [30, 25, 20, 15, 10]\n",
    "    })\n",
    "    metrics['diagnostic_severity'] = pd.DataFrame({\n",
    "        'severity_num': [1, 2, 3, 4, 5],\n",
    "        'count': [40, 30, 20, 8, 2]\n",
    "    })\n",
    "    \n",
    "    # Time series data\n",
    "    # Generate sample time series for sensor readings\n",
    "    end_time = datetime.now()\n",
    "    start_time = end_time - timedelta(hours=24)\n",
    "    hours = pd.date_range(start=start_time, end=end_time, freq='H')\n",
    "    metrics['hourly_readings'] = pd.DataFrame({\n",
    "        'hour': hours,\n",
    "        'value_num': [50 + 10*np.sin(i/4) + np.random.normal(0, 2) for i in range(len(hours))]\n",
    "    })\n",
    "    \n",
    "    # Generate sample time series for alarms\n",
    "    metrics['hourly_alarms'] = pd.DataFrame({\n",
    "        'hour': hours,\n",
    "        'count': [int(5 + 3*np.sin(i/6) + np.random.poisson(1)) for i in range(len(hours))]\n",
    "    })\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Set up the Dash application\n",
    "def create_dashboard(datasets, metrics):\n",
    "    \"\"\"Create a Dash dashboard to visualize the metrics\"\"\"\n",
    "    # Initialize the Dash app\n",
    "    app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "    \n",
    "    # Define the layout\n",
    "    app.layout = dbc.Container([\n",
    "        # Header\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.H1(\"Process Monitoring Dashboard\", className=\"text-center mb-4\"),\n",
    "                html.H5(\"ISA-95 Level 2 Process Control\", className=\"text-center text-muted mb-5\")\n",
    "            ], width=12)\n",
    "        ]),\n",
    "        \n",
    "        # Top metrics cards - Row 1\n",
    "        dbc.Row([\n",
    "            # Sensor Health Rate\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Sensor Health\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('sensor_health_rate', 0):.1f}%\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Actuator Health Rate\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Actuator Health\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('actuator_health_rate', 0):.1f}%\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Equipment Uptime\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Equipment Uptime\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('uptime_percentage', 0):.1f}%\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Average Reading Quality\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Reading Quality\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('avg_reading_quality', 0):.1f}%\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3)\n",
    "        ]),\n",
    "        \n",
    "        # Top metrics cards - Row 2\n",
    "        dbc.Row([\n",
    "            # Average Alarm Acknowledgment Time\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Avg Alarm Response\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('avg_alarm_ack_time', 0):.1f} min\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Parameter Deviation\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Avg Parameter Deviation\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('avg_absolute_deviation', 0):.2f}\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # High Severity Diagnostics\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"High Severity Diagnostics\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('high_severity_diagnostics', 0)}\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Maintenance Required\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Maintenance Required\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('maintenance_required_count', 0)}\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3)\n",
    "        ]),\n",
    "        \n",
    "        # Sensor and Actuator Analysis\n",
    "        dbc.Row([\n",
    "            # Sensor Types\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Sensor Types\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='sensor-types', figure=create_sensor_types_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Actuator Types\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Actuator Types\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='actuator-types', figure=create_actuator_types_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Reading Quality and Alarms\n",
    "        dbc.Row([\n",
    "            # Reading Quality Distribution\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Sensor Reading Quality Distribution\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='reading-quality', figure=create_reading_quality_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Alarm Priorities\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Alarm Priority Distribution\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='alarm-priorities', figure=create_alarm_priorities_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Equipment States and Control Loop Modes\n",
    "        dbc.Row([\n",
    "            # Equipment States\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Equipment State Distribution\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='equipment-states', figure=create_equipment_states_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Control Loop Modes\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Control Loop Modes\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='control-loop-modes', figure=create_control_loop_modes_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Time Series Analysis\n",
    "        dbc.Row([\n",
    "            # Hourly Sensor Readings\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Sensor Readings Over Time\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='hourly-readings', figure=create_hourly_readings_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Hourly Alarms\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Alarms Over Time\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='hourly-alarms', figure=create_hourly_alarms_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Device Diagnostics\n",
    "        dbc.Row([\n",
    "            # Diagnostic Types\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Device Diagnostic Types\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='diagnostic-types', figure=create_diagnostic_types_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Diagnostic Severity\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Diagnostic Severity Distribution\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='diagnostic-severity', figure=create_diagnostic_severity_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Data Status Section\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Data Sources Status\"),\n",
    "                    dbc.CardBody([\n",
    "                        html.Div([\n",
    "                            html.Span(\"Sensors: \", className=\"fw-bold\"),\n",
    "                            html.Span(\"✓ Available\" if 'sensors' in datasets else \"✗ Not Available\", \n",
    "                                    className=\"text-success\" if 'sensors' in datasets else \"text-danger\"),\n",
    "                        ], className=\"mb-2\"),\n",
    "                        html.Div([\n",
    "                            html.Span(\"Sensor Readings: \", className=\"fw-bold\"),\n",
    "                            html.Span(\"✓ Available\" if 'sensor_readings' in datasets else \"✗ Not Available\", \n",
    "                                    className=\"text-success\" if 'sensor_readings' in datasets else \"text-danger\"),\n",
    "                        ], className=\"mb-2\"),\n",
    "                        html.Div([\n",
    "                            html.Span(\"Actuators: \", className=\"fw-bold\"),\n",
    "                            html.Span(\"✓ Available\" if 'actuators' in datasets else \"✗ Not Available\", \n",
    "                                    className=\"text-success\" if 'actuators' in datasets else \"text-danger\"),\n",
    "                        ], className=\"mb-2\"),\n",
    "                        html.Div([\n",
    "                            html.Span(\"Equipment States: \", className=\"fw-bold\"),\n",
    "                            html.Span(\"✓ Available\" if 'equipment_states' in datasets else \"✗ Not Available\", \n",
    "                                    className=\"text-success\" if 'equipment_states' in datasets else \"text-danger\"),\n",
    "                        ], className=\"mb-2\"),\n",
    "                        html.Div([\n",
    "                            html.Span(\"Alarms: \", className=\"fw-bold\"),\n",
    "                            html.Span(\"✓ Available\" if 'alarms' in datasets else \"✗ Not Available\", \n",
    "                                    className=\"text-success\" if 'alarms' in datasets else \"text-danger\"),\n",
    "                        ], className=\"mb-2\"),\n",
    "                        html.Div([\n",
    "                            html.P(\"Note: Missing data sources are supplemented with sample data for demonstration purposes.\", \n",
    "                                  className=\"text-muted mt-3\"),\n",
    "                        ])\n",
    "                    ])\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=12)\n",
    "        ]),\n",
    "        \n",
    "        # Footer\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.Hr(),\n",
    "                html.P(\"ISA-95 Level 2 Process Monitoring Dashboard\", className=\"text-center text-muted\")\n",
    "            ], width=12)\n",
    "        ])\n",
    "    ], fluid=True)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Chart creation functions - unchanged from your original code\n",
    "def create_sensor_types_chart(metrics):\n",
    "    \"\"\"Create sensor types distribution chart\"\"\"\n",
    "    if 'sensor_types' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    sensor_types = metrics['sensor_types']\n",
    "    \n",
    "    fig = px.pie(sensor_types, values='count', names='type',\n",
    "                 color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Sensor Type Distribution\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_actuator_types_chart(metrics):\n",
    "    \"\"\"Create actuator types distribution chart\"\"\"\n",
    "    if 'actuator_types' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    actuator_types = metrics['actuator_types']\n",
    "    \n",
    "    fig = px.pie(actuator_types, values='count', names='type',\n",
    "                 color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Actuator Type Distribution\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_reading_quality_chart(metrics):\n",
    "    \"\"\"Create reading quality distribution chart\"\"\"\n",
    "    if 'reading_quality_distribution' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    quality_dist = metrics['reading_quality_distribution']\n",
    "    \n",
    "    # Define colors for different quality categories\n",
    "    colors = {\n",
    "        'Excellent (90-100%)': '#2ca02c',  # Green\n",
    "        'Good (75-90%)': '#1f77b4',        # Blue\n",
    "        'Fair (50-75%)': '#ff7f0e',        # Orange\n",
    "        'Poor (<50%)': '#d62728'           # Red\n",
    "    }\n",
    "    \n",
    "    # Ensure the categories are ordered correctly\n",
    "    category_order = ['Excellent (90-100%)', 'Good (75-90%)', 'Fair (50-75%)', 'Poor (<50%)']\n",
    "    \n",
    "    # Get only the categories that exist in the data\n",
    "    existing_categories = [cat for cat in category_order if cat in quality_dist['category'].values]\n",
    "    if existing_categories:\n",
    "        quality_dist = quality_dist.set_index('category').reindex(existing_categories).reset_index()\n",
    "    \n",
    "    # Create color sequence based on categories\n",
    "    color_sequence = [colors.get(cat, '#1f77b4') for cat in quality_dist['category']]\n",
    "    \n",
    "    fig = px.bar(quality_dist, x='category', y='count',\n",
    "                 color='category', color_discrete_sequence=color_sequence,\n",
    "                 labels={'category': 'Quality Category', 'count': 'Count'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Sensor Reading Quality Distribution\",\n",
    "        xaxis_title=\"Quality Category\",\n",
    "        yaxis_title=\"Count\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_alarm_priorities_chart(metrics):\n",
    "    \"\"\"Create alarm priorities distribution chart\"\"\"\n",
    "    if 'alarm_priorities' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    alarm_priorities = metrics['alarm_priorities']\n",
    "    \n",
    "    # Convert priority to numeric if it's not already\n",
    "    try:\n",
    "        alarm_priorities['priority_num'] = pd.to_numeric(alarm_priorities['priority'])\n",
    "        alarm_priorities = alarm_priorities.sort_values('priority_num')\n",
    "    except:\n",
    "        # If conversion fails, use as is\n",
    "        pass\n",
    "    \n",
    "    # Define colors for different priority levels\n",
    "    priority_colors = {\n",
    "        1: '#d62728',  # High (Red)\n",
    "        2: '#ff7f0e',  # Medium-High (Orange)\n",
    "        3: '#ffbb78',  # Medium (Light Orange)\n",
    "        4: '#1f77b4',  # Medium-Low (Blue)\n",
    "        5: '#aec7e8'   # Low (Light Blue)\n",
    "    }\n",
    "    \n",
    "    # Create color sequence based on priorities\n",
    "    color_sequence = []\n",
    "    for priority in alarm_priorities['priority']:\n",
    "        try:\n",
    "            priority_num = int(priority)\n",
    "            color_sequence.append(priority_colors.get(priority_num, '#1f77b4'))\n",
    "        except:\n",
    "            color_sequence.append('#1f77b4')  # Default color\n",
    "    \n",
    "    fig = px.bar(alarm_priorities, x='priority', y='count',\n",
    "                 color='priority', color_discrete_sequence=color_sequence,\n",
    "                 labels={'priority': 'Priority Level', 'count': 'Count'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Alarm Priority Distribution\",\n",
    "        xaxis_title=\"Priority Level\",\n",
    "        yaxis_title=\"Count\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_equipment_states_chart(metrics):\n",
    "    \"\"\"Create equipment states distribution chart\"\"\"\n",
    "    if 'equipment_states' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    equipment_states = metrics['equipment_states']\n",
    "    \n",
    "    # Define colors for different states\n",
    "    state_colors = {\n",
    "        'Running': '#2ca02c',      # Green\n",
    "        'Idle': '#1f77b4',         # Blue\n",
    "        'Setup': '#ff7f0e',        # Orange\n",
    "        'Maintenance': '#ffbb78',  # Light Orange\n",
    "        'Down': '#d62728',         # Red\n",
    "        'Fault': '#e377c2',        # Pink\n",
    "        'Stopped': '#7f7f7f',      # Gray\n",
    "        'Error': '#9467bd'         # Purple\n",
    "    }\n",
    "    \n",
    "    # Create color sequence based on states\n",
    "    color_sequence = [state_colors.get(state, '#1f77b4') for state in equipment_states['state']]\n",
    "    \n",
    "    fig = px.pie(equipment_states, values='count', names='state',\n",
    "                 color='state', color_discrete_sequence=color_sequence)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Equipment State Distribution\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_control_loop_modes_chart(metrics):\n",
    "    \"\"\"Create control loop modes distribution chart\"\"\"\n",
    "    if 'control_loop_modes' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    loop_modes = metrics['control_loop_modes']\n",
    "    \n",
    "    # Define colors for different modes\n",
    "    mode_colors = {\n",
    "        'Auto': '#2ca02c',       # Green\n",
    "        'Manual': '#d62728',     # Red\n",
    "        'Cascade': '#ff7f0e',    # Orange\n",
    "        'Remote': '#1f77b4',     # Blue\n",
    "        'Supervisory': '#9467bd' # Purple\n",
    "    }\n",
    "    \n",
    "    # Create color sequence based on modes\n",
    "    color_sequence = [mode_colors.get(mode, '#1f77b4') for mode in loop_modes['mode']]\n",
    "    \n",
    "    fig = px.bar(loop_modes, x='mode', y='count',\n",
    "                 color='mode', color_discrete_sequence=color_sequence,\n",
    "                 labels={'mode': 'Control Mode', 'count': 'Count'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Control Loop Modes\",\n",
    "        xaxis_title=\"Control Mode\",\n",
    "        yaxis_title=\"Count\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_hourly_readings_chart(metrics):\n",
    "    \"\"\"Create hourly sensor readings chart\"\"\"\n",
    "    if 'hourly_readings' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    hourly_readings = metrics['hourly_readings']\n",
    "    \n",
    "    fig = px.line(hourly_readings, x='hour', y='value_num',\n",
    "                  labels={'hour': 'Time', 'value_num': 'Average Reading Value'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Sensor Readings Over Time\",\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Average Reading Value\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_hourly_alarms_chart(metrics):\n",
    "    \"\"\"Create hourly alarms chart\"\"\"\n",
    "    if 'hourly_alarms' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    hourly_alarms = metrics['hourly_alarms']\n",
    "    \n",
    "    fig = px.bar(hourly_alarms, x='hour', y='count',\n",
    "                 color_discrete_sequence=['#d62728'],  # Red for alarms\n",
    "                 labels={'hour': 'Time', 'count': 'Alarm Count'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Alarm Frequency Over Time\",\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Number of Alarms\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_diagnostic_types_chart(metrics):\n",
    "    \"\"\"Create diagnostic types distribution chart\"\"\"\n",
    "    if 'diagnostic_types' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    diagnostic_types = metrics['diagnostic_types']\n",
    "    \n",
    "    fig = px.pie(diagnostic_types, values='count', names='type',\n",
    "                 color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Device Diagnostic Types\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_diagnostic_severity_chart(metrics):\n",
    "    \"\"\"Create diagnostic severity distribution chart\"\"\"\n",
    "    if 'diagnostic_severity' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    severity = metrics['diagnostic_severity']\n",
    "    \n",
    "    # Define colors based on severity level\n",
    "    colors = []\n",
    "    for level in severity['severity_num']:\n",
    "        if level >= 4:\n",
    "            colors.append('#d62728')  # Red for high severity\n",
    "        elif level == 3:\n",
    "            colors.append('#ff7f0e')  # Orange for medium-high severity\n",
    "        elif level == 2:\n",
    "            colors.append('#ffbb78')  # Light orange for medium severity\n",
    "        else:\n",
    "            colors.append('#1f77b4')  # Blue for low severity\n",
    "    \n",
    "    fig = px.bar(severity, x='severity_num', y='count',\n",
    "                 color='severity_num', color_discrete_sequence=colors,\n",
    "                 labels={'severity_num': 'Severity Level', 'count': 'Count'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Diagnostic Severity Distribution\",\n",
    "        xaxis_title=\"Severity Level\",\n",
    "        yaxis_title=\"Count\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Main function to run the dashboard\n",
    "def main():\n",
    "    # Load all data\n",
    "    print(\"Loading data...\")\n",
    "    datasets = load_all_data()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    print(\"Calculating metrics...\")\n",
    "    metrics = calculate_metrics(datasets)\n",
    "    \n",
    "    # Create and run the dashboard\n",
    "    print(\"Creating dashboard...\")\n",
    "    app = create_dashboard(datasets, metrics)\n",
    "    \n",
    "    print(\"Dashboard ready! Running on http://127.0.0.1:8052/\")\n",
    "    app.run_server(debug=True, port=8052)  # Using port 8052 to avoid conflict with Level 3 and 4 dashboards\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ec46f",
   "metadata": {},
   "source": [
    "ISA-95 Level 1 Sensing & Manipulation DASHBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "208c08de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded sensors with 100 records and 15 columns\n",
      "Columns: sensor_id, equipment_id, sensor_type, manufacturer, model_number, installation_date, calibration_due_date, location_x, location_y, location_z, measurement_unit, measurement_range_min, measurement_range_max, accuracy, status\n",
      "Loaded sensor_readings with 100000 records and 8 columns\n",
      "Columns: reading_id, sensor_id, timestamp, value, quality_indicator, status_code, batch_id, equipment_state_id\n",
      "Loaded actuators with 100 records and 13 columns\n",
      "Columns: actuator_id, equipment_id, actuator_type, manufacturer, model_number, installation_date, location_x, location_y, location_z, control_range_min, control_range_max, control_unit, status\n",
      "Loaded actuator_commands with 10000 records and 9 columns\n",
      "Columns: command_id, actuator_id, timestamp, command_value, command_type, control_mode, operator_id, batch_id, step_id\n",
      "Loaded device_diagnostics with 2000 records and 11 columns\n",
      "Columns: diagnostic_id, device_id, timestamp, diagnostic_type, status_code, diagnostic_message, severity_level, battery_level, communication_quality, internal_temperature, maintenance_required\n",
      "Loaded control_loops with 50 records and 13 columns\n",
      "Columns: loop_id, loop_name, process_variable_sensor_id, control_output_actuator_id, controller_type, control_mode, setpoint_value, setpoint_unit, p_value, i_value, d_value, equipment_id, status\n",
      "Calculating metrics...\n",
      "Total sensors: 100\n",
      "Sensor types: 18 types found\n",
      "Sensor statuses: Maintenance, Fault, Calibration Due, Offline, Active, Standby\n",
      "Sensor operational rate: 12.00%\n",
      "Sensors past calibration: 7\n",
      "Sensors due calibration soon: 10\n",
      "Total readings: 100000\n",
      "Reading stats - Min: 0.0, Max: 5996.89, Avg: 711.41\n",
      "Quality stats - Min: 50.0, Max: 100.0, Avg: 91.27\n",
      "Reading error rate: 3.00%\n",
      "Total actuators: 100\n",
      "Actuator types: 15 types found\n",
      "Actuator statuses: Standby, Active, Maintenance, Reserved, Fault, Offline\n",
      "Actuator operational rate: 20.00%\n",
      "Total commands: 10000\n",
      "Command stats - Min: 0.0, Max: 3294.54, Avg: 246.09\n",
      "Manual command rate: 19.99%\n",
      "Total diagnostics: 2000\n",
      "High severity rate: 0.00%\n",
      "Maintenance required rate: 0.00%\n",
      "Total control loops: 50\n",
      "Auto control rate: 68.00%\n",
      "Creating dashboard...\n",
      "Dashboard ready! Running on http://127.0.0.1:8053/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8053/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff5797f5010>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Function to load all datasets\n",
    "def load_all_data():\n",
    "    \"\"\"Load all available ISA-95 Level 1 datasets and return a dictionary of dataframes\"\"\"\n",
    "    data_path = \"data/\"\n",
    "    datasets = {}\n",
    "    \n",
    "    # List of all potential Level 1 datasets with their actual filenames\n",
    "    dataset_files = {\n",
    "        \"sensors\": \"sensors_data.csv\",\n",
    "        \"sensor_readings\": \"sensor_readings.csv\",\n",
    "        \"actuators\": \"actuators_data.csv\",\n",
    "        \"actuator_commands\": \"actuator_commands.csv\", \n",
    "        \"device_diagnostics\": \"device_diagnostics.csv\",\n",
    "        \"control_loops\": \"control_loops.csv\"\n",
    "    }\n",
    "    \n",
    "    # Load each dataset if it exists\n",
    "    for dataset_name, filename in dataset_files.items():\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                # Load the dataset\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Convert date columns to datetime\n",
    "                for col in df.columns:\n",
    "                    if 'date' in col.lower() or 'time' in col.lower() or col == 'timestamp':\n",
    "                        try:\n",
    "                            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "                        except:\n",
    "                            pass  # Skip if conversion fails\n",
    "                \n",
    "                # Store in dictionary\n",
    "                datasets[dataset_name] = df\n",
    "                print(f\"Loaded {dataset_name} with {len(df)} records and {len(df.columns)} columns\")\n",
    "                print(f\"Columns: {', '.join(df.columns)}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# Calculate key metrics for dashboard\n",
    "def calculate_metrics(datasets):\n",
    "    \"\"\"Calculate key metrics from the datasets for the dashboard\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # 1. Sensor Metrics\n",
    "    if 'sensors' in datasets:\n",
    "        sensors = datasets['sensors']\n",
    "        \n",
    "        # Total number of sensors\n",
    "        total_sensors = len(sensors)\n",
    "        metrics['total_sensors'] = total_sensors\n",
    "        print(f\"Total sensors: {total_sensors}\")\n",
    "        \n",
    "        # Count sensors by type\n",
    "        if 'sensor_type' in sensors.columns:\n",
    "            sensor_types = sensors['sensor_type'].value_counts().reset_index()\n",
    "            sensor_types.columns = ['type', 'count']\n",
    "            metrics['sensor_types'] = sensor_types\n",
    "            print(f\"Sensor types: {len(sensor_types)} types found\")\n",
    "        \n",
    "        # Count sensors by status\n",
    "        if 'status' in sensors.columns:\n",
    "            sensor_status = sensors['status'].value_counts().reset_index()\n",
    "            sensor_status.columns = ['status', 'count']\n",
    "            metrics['sensor_status'] = sensor_status\n",
    "            print(f\"Sensor statuses: {', '.join(sensor_status['status'].unique())}\")\n",
    "            \n",
    "            # Calculate sensor operational rate\n",
    "            operational_statuses = ['Active', 'Running', 'Online', 'Operational']\n",
    "            operational_sensors = sensors[sensors['status'].isin(operational_statuses)].shape[0]\n",
    "            operational_rate = operational_sensors / total_sensors * 100 if total_sensors > 0 else 0\n",
    "            metrics['sensor_operational_rate'] = operational_rate\n",
    "            print(f\"Sensor operational rate: {operational_rate:.2f}%\")\n",
    "        \n",
    "        # Count sensors by measurement unit\n",
    "        if 'measurement_unit' in sensors.columns:\n",
    "            unit_counts = sensors['measurement_unit'].value_counts().reset_index()\n",
    "            unit_counts.columns = ['unit', 'count']\n",
    "            metrics['sensor_units'] = unit_counts\n",
    "        \n",
    "        # Sensor calibration status\n",
    "        if 'calibration_due_date' in sensors.columns:\n",
    "            # Convert to datetime if needed\n",
    "            if not pd.api.types.is_datetime64_dtype(sensors['calibration_due_date']):\n",
    "                sensors['calibration_due_date'] = pd.to_datetime(sensors['calibration_due_date'], errors='coerce')\n",
    "            \n",
    "            # Count sensors past calibration due date\n",
    "            past_due = sensors[sensors['calibration_due_date'] < datetime.now()].shape[0]\n",
    "            metrics['sensors_past_calibration'] = past_due\n",
    "            print(f\"Sensors past calibration: {past_due}\")\n",
    "            \n",
    "            # Calibration due in next 30 days\n",
    "            due_soon = sensors[(sensors['calibration_due_date'] >= datetime.now()) & \n",
    "                             (sensors['calibration_due_date'] <= datetime.now() + timedelta(days=30))].shape[0]\n",
    "            metrics['sensors_due_calibration_soon'] = due_soon\n",
    "            print(f\"Sensors due calibration soon: {due_soon}\")\n",
    "    \n",
    "    # 2. Sensor Reading Metrics\n",
    "    if 'sensor_readings' in datasets:\n",
    "        readings = datasets['sensor_readings']\n",
    "        \n",
    "        # Total number of readings\n",
    "        total_readings = len(readings)\n",
    "        metrics['total_readings'] = total_readings\n",
    "        print(f\"Total readings: {total_readings}\")\n",
    "        \n",
    "        # Reading statistics\n",
    "        if 'value' in readings.columns:\n",
    "            readings['value_num'] = pd.to_numeric(readings['value'], errors='coerce')\n",
    "            \n",
    "            reading_stats = {\n",
    "                'min_reading': readings['value_num'].min(),\n",
    "                'max_reading': readings['value_num'].max(),\n",
    "                'avg_reading': readings['value_num'].mean(),\n",
    "                'median_reading': readings['value_num'].median()\n",
    "            }\n",
    "            metrics.update(reading_stats)\n",
    "            print(f\"Reading stats - Min: {reading_stats['min_reading']}, Max: {reading_stats['max_reading']}, Avg: {reading_stats['avg_reading']:.2f}\")\n",
    "        \n",
    "        # Reading quality metrics\n",
    "        if 'quality_indicator' in readings.columns:\n",
    "            readings['quality_num'] = pd.to_numeric(readings['quality_indicator'], errors='coerce')\n",
    "            \n",
    "            quality_stats = {\n",
    "                'min_quality': readings['quality_num'].min(),\n",
    "                'max_quality': readings['quality_num'].max(),\n",
    "                'avg_quality': readings['quality_num'].mean()\n",
    "            }\n",
    "            metrics.update(quality_stats)\n",
    "            print(f\"Quality stats - Min: {quality_stats['min_quality']}, Max: {quality_stats['max_quality']}, Avg: {quality_stats['avg_quality']:.2f}\")\n",
    "            \n",
    "            # Quality distribution\n",
    "            def quality_category(quality):\n",
    "                if quality >= 90:\n",
    "                    return 'High (90-100%)'\n",
    "                elif quality >= 70:\n",
    "                    return 'Medium (70-90%)'\n",
    "                else:\n",
    "                    return 'Low (<70%)'\n",
    "                    \n",
    "            readings['quality_category'] = readings['quality_num'].apply(quality_category)\n",
    "            quality_dist = readings['quality_category'].value_counts().reset_index()\n",
    "            quality_dist.columns = ['category', 'count']\n",
    "            metrics['quality_distribution'] = quality_dist\n",
    "        \n",
    "        # Reading status code analysis\n",
    "        if 'status_code' in readings.columns:\n",
    "            readings['status_code_num'] = pd.to_numeric(readings['status_code'], errors='coerce')\n",
    "            status_counts = readings['status_code_num'].value_counts().reset_index()\n",
    "            status_counts.columns = ['code', 'count']\n",
    "            metrics['reading_status_codes'] = status_counts\n",
    "            \n",
    "            # Count of error readings\n",
    "            error_codes = [1, 2, 3, 4, 5]  # Assuming these are error codes\n",
    "            error_readings = readings[readings['status_code_num'].isin(error_codes)].shape[0]\n",
    "            error_rate = error_readings / total_readings * 100 if total_readings > 0 else 0\n",
    "            metrics['reading_error_rate'] = error_rate\n",
    "            print(f\"Reading error rate: {error_rate:.2f}%\")\n",
    "        \n",
    "        # Readings over time\n",
    "        if 'timestamp' in readings.columns:\n",
    "            # Ensure timestamp is datetime\n",
    "            if not pd.api.types.is_datetime64_dtype(readings['timestamp']):\n",
    "                readings['timestamp'] = pd.to_datetime(readings['timestamp'], errors='coerce')\n",
    "                \n",
    "            # Group by hour\n",
    "            readings['hour'] = readings['timestamp'].dt.floor('H')\n",
    "            hourly_readings = readings.groupby('hour').agg(\n",
    "                avg_value=('value_num', 'mean'),\n",
    "                avg_quality=('quality_num', 'mean'),\n",
    "                count=('value_num', 'count')\n",
    "            ).reset_index()\n",
    "            \n",
    "            metrics['hourly_readings'] = hourly_readings\n",
    "        \n",
    "        # Reading by sensor type\n",
    "        if 'sensor_id' in readings.columns and 'sensors' in datasets:\n",
    "            sensors = datasets['sensors']\n",
    "            if 'sensor_id' in sensors.columns and 'sensor_type' in sensors.columns:\n",
    "                # Create mapping of sensor_id to sensor_type\n",
    "                sensor_type_map = dict(zip(sensors['sensor_id'], sensors['sensor_type']))\n",
    "                \n",
    "                # Add sensor type to readings\n",
    "                readings['sensor_type'] = readings['sensor_id'].map(sensor_type_map)\n",
    "                \n",
    "                # Group by sensor type\n",
    "                readings_by_type = readings.groupby('sensor_type').agg(\n",
    "                    avg_value=('value_num', 'mean'),\n",
    "                    avg_quality=('quality_num', 'mean'),\n",
    "                    count=('value_num', 'count')\n",
    "                ).reset_index()\n",
    "                \n",
    "                metrics['readings_by_sensor_type'] = readings_by_type\n",
    "    \n",
    "    # 3. Actuator Metrics\n",
    "    if 'actuators' in datasets:\n",
    "        actuators = datasets['actuators']\n",
    "        \n",
    "        # Total number of actuators\n",
    "        total_actuators = len(actuators)\n",
    "        metrics['total_actuators'] = total_actuators\n",
    "        print(f\"Total actuators: {total_actuators}\")\n",
    "        \n",
    "        # Count actuators by type\n",
    "        if 'actuator_type' in actuators.columns:\n",
    "            actuator_types = actuators['actuator_type'].value_counts().reset_index()\n",
    "            actuator_types.columns = ['type', 'count']\n",
    "            metrics['actuator_types'] = actuator_types\n",
    "            print(f\"Actuator types: {len(actuator_types)} types found\")\n",
    "        \n",
    "        # Count actuators by status\n",
    "        if 'status' in actuators.columns:\n",
    "            actuator_status = actuators['status'].value_counts().reset_index()\n",
    "            actuator_status.columns = ['status', 'count']\n",
    "            metrics['actuator_status'] = actuator_status\n",
    "            print(f\"Actuator statuses: {', '.join(actuator_status['status'].unique())}\")\n",
    "            \n",
    "            # Calculate actuator operational rate\n",
    "            operational_statuses = ['Active', 'Running', 'Online', 'Operational']\n",
    "            operational_actuators = actuators[actuators['status'].isin(operational_statuses)].shape[0]\n",
    "            operational_rate = operational_actuators / total_actuators * 100 if total_actuators > 0 else 0\n",
    "            metrics['actuator_operational_rate'] = operational_rate\n",
    "            print(f\"Actuator operational rate: {operational_rate:.2f}%\")\n",
    "        \n",
    "        # Count actuators by control unit\n",
    "        if 'control_unit' in actuators.columns:\n",
    "            unit_counts = actuators['control_unit'].value_counts().reset_index()\n",
    "            unit_counts.columns = ['unit', 'count']\n",
    "            metrics['actuator_control_units'] = unit_counts\n",
    "    \n",
    "    # 4. Actuator Command Metrics\n",
    "    if 'actuator_commands' in datasets:\n",
    "        commands = datasets['actuator_commands']\n",
    "        \n",
    "        # Total number of commands\n",
    "        total_commands = len(commands)\n",
    "        metrics['total_commands'] = total_commands\n",
    "        print(f\"Total commands: {total_commands}\")\n",
    "        \n",
    "        # Command value statistics\n",
    "        if 'command_value' in commands.columns:\n",
    "            commands['value_num'] = pd.to_numeric(commands['command_value'], errors='coerce')\n",
    "            \n",
    "            command_stats = {\n",
    "                'min_command': commands['value_num'].min(),\n",
    "                'max_command': commands['value_num'].max(),\n",
    "                'avg_command': commands['value_num'].mean()\n",
    "            }\n",
    "            metrics.update(command_stats)\n",
    "            print(f\"Command stats - Min: {command_stats['min_command']}, Max: {command_stats['max_command']}, Avg: {command_stats['avg_command']:.2f}\")\n",
    "        \n",
    "        # Command type distribution\n",
    "        if 'command_type' in commands.columns:\n",
    "            command_types = commands['command_type'].value_counts().reset_index()\n",
    "            command_types.columns = ['type', 'count']\n",
    "            metrics['command_types'] = command_types\n",
    "        \n",
    "        # Control mode distribution\n",
    "        if 'control_mode' in commands.columns:\n",
    "            control_modes = commands['control_mode'].value_counts().reset_index()\n",
    "            control_modes.columns = ['mode', 'count']\n",
    "            metrics['control_modes'] = control_modes\n",
    "            \n",
    "            # Manual command percentage\n",
    "            manual_commands = commands[commands['control_mode'] == 'Manual'].shape[0]\n",
    "            manual_rate = manual_commands / total_commands * 100 if total_commands > 0 else 0\n",
    "            metrics['manual_command_rate'] = manual_rate\n",
    "            print(f\"Manual command rate: {manual_rate:.2f}%\")\n",
    "        \n",
    "        # Commands over time\n",
    "        if 'timestamp' in commands.columns:\n",
    "            # Ensure timestamp is datetime\n",
    "            if not pd.api.types.is_datetime64_dtype(commands['timestamp']):\n",
    "                commands['timestamp'] = pd.to_datetime(commands['timestamp'], errors='coerce')\n",
    "                \n",
    "            # Group by hour\n",
    "            commands['hour'] = commands['timestamp'].dt.floor('H')\n",
    "            hourly_commands = commands.groupby('hour').agg(\n",
    "                avg_value=('value_num', 'mean'),\n",
    "                count=('value_num', 'count')\n",
    "            ).reset_index()\n",
    "            \n",
    "            metrics['hourly_commands'] = hourly_commands\n",
    "        \n",
    "        # Commands by operator (for manual commands)\n",
    "        if 'operator_id' in commands.columns:\n",
    "            operator_commands = commands.dropna(subset=['operator_id']).groupby('operator_id').size().reset_index(name='count')\n",
    "            metrics['commands_by_operator'] = operator_commands\n",
    "    \n",
    "    # 5. Device Diagnostic Metrics\n",
    "    if 'device_diagnostics' in datasets:\n",
    "        diagnostics = datasets['device_diagnostics']\n",
    "        \n",
    "        # Total number of diagnostics\n",
    "        total_diagnostics = len(diagnostics)\n",
    "        metrics['total_diagnostics'] = total_diagnostics\n",
    "        print(f\"Total diagnostics: {total_diagnostics}\")\n",
    "        \n",
    "        # Diagnostic type distribution\n",
    "        if 'diagnostic_type' in diagnostics.columns:\n",
    "            diag_types = diagnostics['diagnostic_type'].value_counts().reset_index()\n",
    "            diag_types.columns = ['type', 'count']\n",
    "            metrics['diagnostic_types'] = diag_types\n",
    "        \n",
    "        # Severity level distribution\n",
    "        if 'severity_level' in diagnostics.columns:\n",
    "            diagnostics['severity_num'] = pd.to_numeric(diagnostics['severity_level'], errors='coerce')\n",
    "            \n",
    "            severity_counts = diagnostics.groupby('severity_num').size().reset_index(name='count')\n",
    "            metrics['severity_distribution'] = severity_counts\n",
    "            \n",
    "            # High severity percentage\n",
    "            high_severity = diagnostics[diagnostics['severity_num'] >= 3].shape[0]\n",
    "            high_severity_rate = high_severity / total_diagnostics * 100 if total_diagnostics > 0 else 0\n",
    "            metrics['high_severity_rate'] = high_severity_rate\n",
    "            print(f\"High severity rate: {high_severity_rate:.2f}%\")\n",
    "        \n",
    "        # Maintenance required count\n",
    "        if 'maintenance_required' in diagnostics.columns:\n",
    "            # Convert to numeric if it's not already\n",
    "            diagnostics['maintenance_required_num'] = pd.to_numeric(diagnostics['maintenance_required'], errors='coerce')\n",
    "            maintenance_required = diagnostics[diagnostics['maintenance_required_num'] > 0].shape[0]\n",
    "            maintenance_rate = maintenance_required / total_diagnostics * 100 if total_diagnostics > 0 else 0\n",
    "            metrics['maintenance_required_rate'] = maintenance_rate\n",
    "            print(f\"Maintenance required rate: {maintenance_rate:.2f}%\")\n",
    "        \n",
    "        # Communication quality statistics\n",
    "        if 'communication_quality' in diagnostics.columns:\n",
    "            diagnostics['comm_quality_num'] = pd.to_numeric(diagnostics['communication_quality'], errors='coerce')\n",
    "            \n",
    "            comm_stats = {\n",
    "                'min_comm_quality': diagnostics['comm_quality_num'].min(),\n",
    "                'max_comm_quality': diagnostics['comm_quality_num'].max(),\n",
    "                'avg_comm_quality': diagnostics['comm_quality_num'].mean()\n",
    "            }\n",
    "            metrics.update(comm_stats)\n",
    "        \n",
    "        # Internal temperature statistics\n",
    "        if 'internal_temperature' in diagnostics.columns:\n",
    "            diagnostics['temp_num'] = pd.to_numeric(diagnostics['internal_temperature'], errors='coerce')\n",
    "            \n",
    "            temp_stats = {\n",
    "                'min_internal_temp': diagnostics['temp_num'].min(),\n",
    "                'max_internal_temp': diagnostics['temp_num'].max(),\n",
    "                'avg_internal_temp': diagnostics['temp_num'].mean()\n",
    "            }\n",
    "            metrics.update(temp_stats)\n",
    "    \n",
    "    # 6. Control Loop Metrics\n",
    "    if 'control_loops' in datasets:\n",
    "        loops = datasets['control_loops']\n",
    "        \n",
    "        # Total number of control loops\n",
    "        total_loops = len(loops)\n",
    "        metrics['total_control_loops'] = total_loops\n",
    "        print(f\"Total control loops: {total_loops}\")\n",
    "        \n",
    "        # Control loop type distribution\n",
    "        if 'controller_type' in loops.columns:\n",
    "            controller_types = loops['controller_type'].value_counts().reset_index()\n",
    "            controller_types.columns = ['type', 'count']\n",
    "            metrics['controller_types'] = controller_types\n",
    "        \n",
    "        # Control mode distribution\n",
    "        if 'control_mode' in loops.columns:\n",
    "            loop_modes = loops['control_mode'].value_counts().reset_index()\n",
    "            loop_modes.columns = ['mode', 'count']\n",
    "            metrics['loop_control_modes'] = loop_modes\n",
    "            \n",
    "            # Auto mode percentage\n",
    "            auto_loops = loops[loops['control_mode'] == 'Auto'].shape[0]\n",
    "            auto_rate = auto_loops / total_loops * 100 if total_loops > 0 else 0\n",
    "            metrics['auto_control_rate'] = auto_rate\n",
    "            print(f\"Auto control rate: {auto_rate:.2f}%\")\n",
    "        \n",
    "        # PID parameter statistics\n",
    "        pid_params = ['p_value', 'i_value', 'd_value']\n",
    "        for param in pid_params:\n",
    "            if param in loops.columns:\n",
    "                loops[f'{param}_num'] = pd.to_numeric(loops[param], errors='coerce')\n",
    "                \n",
    "                param_stats = {\n",
    "                    f'min_{param}': loops[f'{param}_num'].min(),\n",
    "                    f'max_{param}': loops[f'{param}_num'].max(),\n",
    "                    f'avg_{param}': loops[f'{param}_num'].mean()\n",
    "                }\n",
    "                metrics.update(param_stats)\n",
    "                \n",
    "        # Control loop status distribution\n",
    "        if 'status' in loops.columns:\n",
    "            loop_status = loops['status'].value_counts().reset_index()\n",
    "            loop_status.columns = ['status', 'count']\n",
    "            metrics['loop_status'] = loop_status\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Chart creation functions\n",
    "def create_sensor_types_chart(metrics):\n",
    "    \"\"\"Create sensor types distribution chart\"\"\"\n",
    "    if 'sensor_types' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    sensor_types = metrics['sensor_types']\n",
    "    \n",
    "    fig = px.pie(sensor_types, values='count', names='type',\n",
    "                 color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Sensor Type Distribution\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_sensor_status_chart(metrics):\n",
    "    \"\"\"Create sensor status distribution chart\"\"\"\n",
    "    if 'sensor_status' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    sensor_status = metrics['sensor_status']\n",
    "    \n",
    "    # Define colors for different statuses\n",
    "    status_colors = {\n",
    "        'Active': '#2ca02c',       # Green\n",
    "        'Running': '#2ca02c',      # Green\n",
    "        'Online': '#2ca02c',       # Green\n",
    "        'Operational': '#2ca02c',  # Green\n",
    "        'Idle': '#1f77b4',         # Blue\n",
    "        'Standby': '#1f77b4',      # Blue\n",
    "        'Offline': '#d62728',      # Red\n",
    "        'Fault': '#d62728',        # Red\n",
    "        'Error': '#d62728',        # Red\n",
    "        'Maintenance': '#ff7f0e',  # Orange\n",
    "        'Calibration Due': '#ff7f0e', # Orange\n",
    "        'Calibrating': '#ff7f0e',  # Orange\n",
    "        'Unknown': '#7f7f7f'       # Gray\n",
    "    }\n",
    "    \n",
    "    # Create color sequence based on statuses\n",
    "    color_sequence = [status_colors.get(status, '#1f77b4') for status in sensor_status['status']]\n",
    "    \n",
    "    fig = px.bar(sensor_status, x='status', y='count',\n",
    "                 color='status', color_discrete_sequence=color_sequence,\n",
    "                 labels={'status': 'Status', 'count': 'Count'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Sensor Status Distribution\",\n",
    "        xaxis_title=\"Status\",\n",
    "        yaxis_title=\"Count\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_actuator_types_chart(metrics):\n",
    "    \"\"\"Create actuator types distribution chart\"\"\"\n",
    "    if 'actuator_types' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    actuator_types = metrics['actuator_types']\n",
    "    \n",
    "    fig = px.pie(actuator_types, values='count', names='type',\n",
    "                 color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Actuator Type Distribution\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_actuator_status_chart(metrics):\n",
    "    \"\"\"Create actuator status distribution chart\"\"\"\n",
    "    if 'actuator_status' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    actuator_status = metrics['actuator_status']\n",
    "    \n",
    "    # Define colors for different statuses\n",
    "    status_colors = {\n",
    "        'Active': '#2ca02c',       # Green\n",
    "        'Running': '#2ca02c',      # Green\n",
    "        'Online': '#2ca02c',       # Green\n",
    "        'Operational': '#2ca02c',  # Green\n",
    "        'Idle': '#1f77b4',         # Blue\n",
    "        'Standby': '#1f77b4',      # Blue\n",
    "        'Offline': '#d62728',      # Red\n",
    "        'Fault': '#d62728',        # Red\n",
    "        'Error': '#d62728',        # Red\n",
    "        'Maintenance': '#ff7f0e',  # Orange\n",
    "        'Reserved': '#9467bd',     # Purple\n",
    "        'Unknown': '#7f7f7f'       # Gray\n",
    "    }\n",
    "    \n",
    "    # Create color sequence based on statuses\n",
    "    color_sequence = [status_colors.get(status, '#1f77b4') for status in actuator_status['status']]\n",
    "    \n",
    "    fig = px.bar(actuator_status, x='status', y='count',\n",
    "                 color='status', color_discrete_sequence=color_sequence,\n",
    "                 labels={'status': 'Status', 'count': 'Count'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Actuator Status Distribution\",\n",
    "        xaxis_title=\"Status\",\n",
    "        yaxis_title=\"Count\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_reading_quality_chart(metrics):\n",
    "    \"\"\"Create reading quality distribution chart\"\"\"\n",
    "    if 'quality_distribution' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    quality_dist = metrics['quality_distribution']\n",
    "    \n",
    "    # Define colors for different quality categories\n",
    "    colors = {\n",
    "        'High (90-100%)': '#2ca02c',  # Green\n",
    "        'Medium (70-90%)': '#ff7f0e',  # Orange\n",
    "        'Low (<70%)': '#d62728'        # Red\n",
    "    }\n",
    "    \n",
    "    # Ensure the categories are ordered correctly\n",
    "    category_order = ['High (90-100%)', 'Medium (70-90%)', 'Low (<70%)']\n",
    "    quality_dist = quality_dist.set_index('category').reindex(category_order).reset_index()\n",
    "    \n",
    "    # Create color sequence based on categories\n",
    "    color_sequence = [colors.get(cat, '#1f77b4') for cat in quality_dist['category']]\n",
    "    \n",
    "    fig = px.bar(quality_dist, x='category', y='count',\n",
    "                 color='category', color_discrete_sequence=color_sequence,\n",
    "                 labels={'category': 'Quality Category', 'count': 'Count'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Sensor Reading Quality Distribution\",\n",
    "        xaxis_title=\"Quality Category\",\n",
    "        yaxis_title=\"Count\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_readings_by_type_chart(metrics):\n",
    "    \"\"\"Create readings by sensor type chart\"\"\"\n",
    "    if 'readings_by_sensor_type' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    readings_by_type = metrics['readings_by_sensor_type']\n",
    "    \n",
    "    fig = px.bar(readings_by_type, x='sensor_type', y='count',\n",
    "                 color='sensor_type', color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "                 labels={'sensor_type': 'Sensor Type', 'count': 'Reading Count'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Readings by Sensor Type\",\n",
    "        xaxis_title=\"Sensor Type\",\n",
    "        yaxis_title=\"Reading Count\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_control_modes_chart(metrics):\n",
    "    \"\"\"Create control mode distribution chart\"\"\"\n",
    "    if 'control_modes' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    control_modes = metrics['control_modes']\n",
    "    \n",
    "    # Define colors for different modes\n",
    "    mode_colors = {\n",
    "        'Auto': '#2ca02c',       # Green\n",
    "        'Manual': '#d62728',     # Red\n",
    "        'Cascade': '#ff7f0e',    # Orange\n",
    "        'Remote': '#1f77b4',     # Blue\n",
    "        'Supervised': '#9467bd'  # Purple\n",
    "    }\n",
    "    \n",
    "    # Create color sequence based on modes\n",
    "    color_sequence = [mode_colors.get(mode, '#1f77b4') for mode in control_modes['mode']]\n",
    "    \n",
    "    fig = px.pie(control_modes, values='count', names='mode',\n",
    "                 color='mode', color_discrete_sequence=color_sequence)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Control Mode Distribution\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_command_types_chart(metrics):\n",
    "    \"\"\"Create command types distribution chart\"\"\"\n",
    "    if 'command_types' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    command_types = metrics['command_types']\n",
    "    \n",
    "    fig = px.bar(command_types, x='type', y='count',\n",
    "                 color='type', color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "                 labels={'type': 'Command Type', 'count': 'Count'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Command Type Distribution\",\n",
    "        xaxis_title=\"Command Type\",\n",
    "        yaxis_title=\"Count\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_hourly_readings_chart(metrics):\n",
    "    \"\"\"Create hourly readings chart\"\"\"\n",
    "    if 'hourly_readings' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    hourly_readings = metrics['hourly_readings']\n",
    "    \n",
    "    # Create figure with secondary y-axis\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "    # Add traces\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=hourly_readings['hour'], y=hourly_readings['avg_value'],\n",
    "                  name=\"Average Value\", line=dict(color='#1f77b4')),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=hourly_readings['hour'], y=hourly_readings['avg_quality'],\n",
    "                  name=\"Quality (%)\", line=dict(color='#2ca02c')),\n",
    "        secondary_y=True,\n",
    "    )\n",
    "    \n",
    "    # Add figure title\n",
    "    fig.update_layout(\n",
    "        title=\"Sensor Readings Over Time\",\n",
    "        xaxis_title=\"Time\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.2)\n",
    "    )\n",
    "    \n",
    "    # Set y-axes titles\n",
    "    fig.update_yaxes(title_text=\"Average Reading Value\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"Quality (%)\", secondary_y=True)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_hourly_commands_chart(metrics):\n",
    "    \"\"\"Create hourly commands chart\"\"\"\n",
    "    if 'hourly_commands' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    hourly_commands = metrics['hourly_commands']\n",
    "    \n",
    "    fig = px.bar(hourly_commands, x='hour', y='count',\n",
    "                 labels={'hour': 'Time', 'count': 'Command Count'},\n",
    "                 color_discrete_sequence=['#ff7f0e'])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Actuator Commands Over Time\",\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Command Count\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_diagnostic_types_chart(metrics):\n",
    "    \"\"\"Create diagnostic types distribution chart\"\"\"\n",
    "    if 'diagnostic_types' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    diagnostic_types = metrics['diagnostic_types']\n",
    "    \n",
    "    fig = px.pie(diagnostic_types, values='count', names='type',\n",
    "                 color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Diagnostic Type Distribution\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_severity_distribution_chart(metrics):\n",
    "    \"\"\"Create severity distribution chart\"\"\"\n",
    "    if 'severity_distribution' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    severity_dist = metrics['severity_distribution']\n",
    "    \n",
    "    # Define colors based on severity level\n",
    "    colors = []\n",
    "    for level in severity_dist['severity_num']:\n",
    "        if level >= 4:\n",
    "            colors.append('#d62728')  # Red for high severity\n",
    "        elif level == 3:\n",
    "            colors.append('#ff7f0e')  # Orange for medium-high severity\n",
    "        elif level == 2:\n",
    "            colors.append('#ffbb78')  # Light orange for medium severity\n",
    "        else:\n",
    "            colors.append('#1f77b4')  # Blue for low severity\n",
    "    \n",
    "    fig = px.bar(severity_dist, x='severity_num', y='count',\n",
    "                 color='severity_num', color_discrete_sequence=colors,\n",
    "                 labels={'severity_num': 'Severity Level', 'count': 'Count'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Diagnostic Severity Distribution\",\n",
    "        xaxis_title=\"Severity Level\",\n",
    "        yaxis_title=\"Count\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_controller_types_chart(metrics):\n",
    "    \"\"\"Create controller types distribution chart\"\"\"\n",
    "    if 'controller_types' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    controller_types = metrics['controller_types']\n",
    "    \n",
    "    fig = px.pie(controller_types, values='count', names='type',\n",
    "                 color_discrete_sequence=px.colors.qualitative.Plotly)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Controller Type Distribution\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_loop_modes_chart(metrics):\n",
    "    \"\"\"Create loop control modes distribution chart\"\"\"\n",
    "    if 'loop_control_modes' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    loop_modes = metrics['loop_control_modes']\n",
    "    \n",
    "    # Define colors for different modes\n",
    "    mode_colors = {\n",
    "        'Auto': '#2ca02c',       # Green\n",
    "        'Manual': '#d62728',     # Red\n",
    "        'Cascade': '#ff7f0e',    # Orange\n",
    "        'Remote': '#1f77b4',     # Blue\n",
    "        'Supervisory': '#9467bd', # Purple\n",
    "        'Supervised': '#9467bd'  # Purple\n",
    "    }\n",
    "    \n",
    "    # Create color sequence based on modes\n",
    "    color_sequence = [mode_colors.get(mode, '#1f77b4') for mode in loop_modes['mode']]\n",
    "    \n",
    "    fig = px.bar(loop_modes, x='mode', y='count',\n",
    "                 color='mode', color_discrete_sequence=color_sequence,\n",
    "                 labels={'mode': 'Control Mode', 'count': 'Count'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Loop Control Modes\",\n",
    "        xaxis_title=\"Control Mode\",\n",
    "        yaxis_title=\"Count\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_calibration_status_chart(metrics):\n",
    "    \"\"\"Create calibration status chart\"\"\"\n",
    "    if ('sensors_past_calibration' not in metrics or \n",
    "        'sensors_due_calibration_soon' not in metrics or \n",
    "        'total_sensors' not in metrics):\n",
    "        return go.Figure()\n",
    "    \n",
    "    past_due = metrics['sensors_past_calibration']\n",
    "    due_soon = metrics['sensors_due_calibration_soon']\n",
    "    total = metrics['total_sensors']\n",
    "    current = total - past_due - due_soon\n",
    "    \n",
    "    # Create data for pie chart\n",
    "    labels = ['Current', 'Due Soon (30 days)', 'Past Due']\n",
    "    values = [current, due_soon, past_due]\n",
    "    colors = ['#2ca02c', '#ff7f0e', '#d62728']  # Green, Orange, Red\n",
    "    \n",
    "    fig = px.pie(values=values, names=labels, color=labels,\n",
    "                 color_discrete_map=dict(zip(labels, colors)))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Sensor Calibration Status\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1),\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_maintenance_status_chart(metrics):\n",
    "    \"\"\"Create maintenance status chart\"\"\"\n",
    "    if ('maintenance_required_rate' not in metrics):\n",
    "        return go.Figure()\n",
    "    \n",
    "    maintenance_rate = metrics['maintenance_required_rate']\n",
    "    \n",
    "    # Create gauge chart\n",
    "    fig = go.Figure(go.Indicator(\n",
    "        mode = \"gauge+number\",\n",
    "        value = maintenance_rate,\n",
    "        domain = {'x': [0, 1], 'y': [0, 1]},\n",
    "        title = {'text': \"Devices Requiring Maintenance (%)\"},\n",
    "        gauge = {\n",
    "            'axis': {'range': [None, 100]},\n",
    "            'bar': {'color': \"#ff7f0e\"},\n",
    "            'steps': [\n",
    "                {'range': [0, 5], 'color': '#2ca02c'},\n",
    "                {'range': [5, 15], 'color': '#ffbb78'},\n",
    "                {'range': [15, 30], 'color': '#ff7f0e'},\n",
    "                {'range': [30, 100], 'color': '#d62728'}\n",
    "            ],\n",
    "            'threshold': {\n",
    "                'line': {'color': \"red\", 'width': 4},\n",
    "                'thickness': 0.75,\n",
    "                'value': 30\n",
    "            }\n",
    "        }\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=400,\n",
    "        margin=dict(t=40, b=40, l=10, r=10)\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_sensor_measurement_units_chart(metrics):\n",
    "    \"\"\"Create sensor measurement units chart\"\"\"\n",
    "    if 'sensor_units' not in metrics:\n",
    "        return go.Figure()\n",
    "    \n",
    "    units = metrics['sensor_units']\n",
    "    \n",
    "    fig = px.bar(units, x='unit', y='count',\n",
    "                 color='unit', color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "                 labels={'unit': 'Measurement Unit', 'count': 'Count'})\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Sensor Measurement Units\",\n",
    "        xaxis_title=\"Unit\",\n",
    "        yaxis_title=\"Count\",\n",
    "        margin=dict(t=40, b=40, l=10, r=10),\n",
    "        height=400,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Set up the Dash application\n",
    "def create_dashboard(datasets, metrics):\n",
    "    \"\"\"Create a Dash dashboard to visualize the metrics\"\"\"\n",
    "    # Initialize the Dash app\n",
    "    app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "    \n",
    "    # Define the layout\n",
    "    app.layout = dbc.Container([\n",
    "        # Header\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.H1(\"Process Control Dashboard\", className=\"text-center mb-4\"),\n",
    "                html.H5(\"ISA-95 Level 1 Sensing & Manipulation\", className=\"text-center text-muted mb-5\")\n",
    "            ], width=12)\n",
    "        ]),\n",
    "        \n",
    "        # Top metrics cards - Row 1\n",
    "        dbc.Row([\n",
    "            # Total Sensors\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Total Sensors\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('total_sensors', 0)}\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Sensor Operational Rate\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Sensor Operational Rate\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('sensor_operational_rate', 0):.1f}%\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Total Actuators\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Total Actuators\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('total_actuators', 0)}\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Actuator Operational Rate\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Actuator Operational Rate\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('actuator_operational_rate', 0):.1f}%\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3)\n",
    "        ]),\n",
    "        \n",
    "        # Top metrics cards - Row 2\n",
    "        dbc.Row([\n",
    "            # Reading Quality\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Avg Reading Quality\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('avg_quality', 0):.1f}%\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Reading Error Rate\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Reading Error Rate\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('reading_error_rate', 0):.1f}%\", className=\"card-text text-danger\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Manual Command Rate\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Manual Command Rate\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('manual_command_rate', 0):.1f}%\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3),\n",
    "            \n",
    "            # Auto Control Rate\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardBody([\n",
    "                        html.H5(\"Auto Control Rate\", className=\"card-title\"),\n",
    "                        html.H3(f\"{metrics.get('auto_control_rate', 0):.1f}%\", className=\"card-text text-primary\")\n",
    "                    ])\n",
    "                ], className=\"mb-4 text-center\")\n",
    "            ], width=3)\n",
    "        ]),\n",
    "        \n",
    "        # Calibration and Maintenance Status\n",
    "        dbc.Row([\n",
    "            # Calibration Status\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Sensor Calibration Status\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='calibration-status', figure=create_calibration_status_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Maintenance Status\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Maintenance Status\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='maintenance-status', figure=create_maintenance_status_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Sensor Analysis\n",
    "        dbc.Row([\n",
    "            # Sensor Types\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Sensor Types\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='sensor-types', figure=create_sensor_types_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Sensor Status\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Sensor Status\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='sensor-status', figure=create_sensor_status_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Sensor Measurement Units\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Sensor Measurement Units\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='sensor-units', figure=create_sensor_measurement_units_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=12)\n",
    "        ]),\n",
    "        \n",
    "        # Actuator Analysis\n",
    "        dbc.Row([\n",
    "            # Actuator Types\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Actuator Types\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='actuator-types', figure=create_actuator_types_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Actuator Status\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Actuator Status\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='actuator-status', figure=create_actuator_status_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Reading Analysis\n",
    "        dbc.Row([\n",
    "            # Reading Quality Distribution\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Reading Quality Distribution\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='reading-quality', figure=create_reading_quality_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Readings by Sensor Type\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Readings by Sensor Type\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='readings-by-type', figure=create_readings_by_type_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Command Analysis\n",
    "        dbc.Row([\n",
    "            # Control Mode Distribution\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Control Mode Distribution\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='control-modes', figure=create_control_modes_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Command Types\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Command Types\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='command-types', figure=create_command_types_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Time Series Analysis\n",
    "        dbc.Row([\n",
    "            # Hourly Readings\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Sensor Readings Over Time\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='hourly-readings', figure=create_hourly_readings_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Hourly Commands\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Actuator Commands Over Time\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='hourly-commands', figure=create_hourly_commands_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Diagnostics Analysis\n",
    "        dbc.Row([\n",
    "            # Diagnostic Types\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Diagnostic Types\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='diagnostic-types', figure=create_diagnostic_types_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Severity Distribution\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Severity Distribution\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='severity-distribution', figure=create_severity_distribution_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Control Loop Analysis\n",
    "        dbc.Row([\n",
    "            # Controller Types\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Controller Types\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='controller-types', figure=create_controller_types_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6),\n",
    "            \n",
    "            # Loop Control Modes\n",
    "            dbc.Col([\n",
    "                dbc.Card([\n",
    "                    dbc.CardHeader(\"Loop Control Modes\"),\n",
    "                    dbc.CardBody(\n",
    "                        dcc.Graph(id='loop-modes', figure=create_loop_modes_chart(metrics))\n",
    "                    )\n",
    "                ], className=\"mb-4\")\n",
    "            ], width=6)\n",
    "        ]),\n",
    "        \n",
    "        # Footer\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.Hr(),\n",
    "                html.P(\"ISA-95 Level 1 Process Control Dashboard\", className=\"text-center text-muted\")\n",
    "            ], width=12)\n",
    "        ])\n",
    "    ], fluid=True)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Main function to run the dashboard\n",
    "def main():\n",
    "    # Load all data\n",
    "    print(\"Loading data...\")\n",
    "    datasets = load_all_data()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    print(\"Calculating metrics...\")\n",
    "    metrics = calculate_metrics(datasets)\n",
    "    \n",
    "    # Create and run the dashboard\n",
    "    print(\"Creating dashboard...\")\n",
    "    app = create_dashboard(datasets, metrics)\n",
    "    \n",
    "    print(\"Dashboard ready! Running on http://127.0.0.1:8053/\")\n",
    "    app.run_server(debug=True, port=8053)  # Using port 8053 to avoid conflict with other dashboards\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03308f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
